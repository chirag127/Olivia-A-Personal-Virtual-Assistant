# Olivia-A-Personal-Virtual-Assistant
- [Olivia-A-Personal-Virtual-Assistant](#olivia-a-personal-virtual-assistant)
    - [Features](#features)
    - [Assistant skills](#assistant-skills)
    - [In progress features](#in-progress-features)
  - [Installation instruction](#installation-instruction)
    - [If You Get `No Module Named pyaudio` Error!](#if-you-get-no-module-named-pyaudio-error)
  - [How to use the application](#how-to-use-the-application)
- [Precautions while using the software in the application](#precautions-while-using-the-software-in-the-application)
- [Libraries used in the software](#libraries-used-in-the-software)
### Features

  
  1.  Fully customizable
  2.  A lot of features
  3.  Built-in voice recognition
  4.  Dynamic voice recognition
  5.  Easy to use
  6.  Great UI
  7.  Intuitive
  8.  Just a bit of magic
  9.  Keyboard-controlled
  10. Lightweight
  11. Minimal
  12. No need for a database
  13. Open source
  14. Powerful
  15. Quick
  16. Simple
  17. Transparent
  18. User-friendly
  19. Voice-controlled
  20. Speech synthesis
  21. Speech recognition
  22. Natural language processing
  23. Intuitive interface
  24. Customizable
  25. Open source
  26. Free to use
  27. Free to modify
  28. Free to redistribute
### Assistant skills 

1. Give description of anything according to Wikipedia just say "what is (the name of the thing) according to Wikipedia".
2. Give the CPU usage of the computer just say "CPU usage" or "CPU usage of the computer" or "usage of the CPU".
3. Present with the RAM usage of the computer just say "RAM usage" or "RAM usage of the computer" or "RAM usage of the computer".
4. Give the disk usage of the computer just say "disk usage" or "disk usage of the computer" or "disk usage of the computer".
6. Give the battery usage of the computer just say "battery usage" or "battery usage of the computer" or "battery usage of the computer".
7. Search in chrome just say "search in chrome".
8. Tell you the time by saying "time" or "what time is it" or "what is the time" or "tell me the time".
9. Tell you the date by saying "date" or "what date is it" or "what is the date" or "tell me the date".
10. Generate a random password by saying "generate a password" or "generate a random password".
11. Generate a random number by saying "generate a number" or "generate a random number".
12. Change your name by saying "change my name to (your name)" or "call me (your name)".
13. Send a mail by saying "send a mail to (your mail ID)" or "send a mail to (your mail ID) with (your message)".
14. Lock the screen by saying "lock the screen" or "lock window" or "lock screen".
15. Shutdown the computer by saying "shutdown the computer" or "shutdown the computer now" or "shutdown system".
16. Empty the recycle bin by saying "empty the recycle bin" or "empty recycle bin".
17. Stop listening by saying "stop listening" or "stop listening now" or "don't listen" or "don't listen now".
18. Tell you the location of a place by saying "where is (the name of the place)".
19. Restart the computer by saying "restart the computer" or "restart the computer now" or "restart system" or "reboot the computer" or "reboot the computer now" or "reboot system".
20. Hibernate the computer system by saying "hibernate the computer" or "hibernate the computer now" or "hibernate system" .
21. Logout the computer by saying "logout the computer" or "logout the computer now" or "logout system" or "sign out the computer" or "sign out the computer now" or "sign out system".
22. Write a note by saying "write a note" or "write note" or "write a note now" or "write note now" with further of including the time and date by saying yes or no.
23. Read a note by saying "read a note" or "read note" or "read a note now" or "read note now".
24. Delete a note by saying "delete a note" or "delete note" or "delete a note now" or "delete note now".
25. Show all notes by saying "show all notes" or "show all notes now" or "show all notes now".
26. Send WhatsApp message by saying "send WhatsApp message to (your number)" or "send message".
27. Tell location of a place by saying "where is (the name of the place)" or "where is (the name of the place) now" or "where is (the name of the place) now" etc. Example "where is Ghaziabad" will tell you the location of Ghaziabad by open the location of Ghaziabad in Google Maps.
28. Open word by saying "open word" or "open word now" and then type your document by saying "yes" or "no" when asked if "do you want me to type" and stop typing by saying "stop typing".
29. Launch an application by saying "launch (the name of the application)" or "launch (the name of the application) now" or "launch (the name of the application) now" 
    1. Launch chrome just say "launch chrome" or "launch chrome now".
    2. Launch notepad just say "launch notepad" or "launch notepad now".
    3. Open word just say "launch word" or "launch word now".
    4. Launch PowerPoint just say "launch PowerPoint" or "launch PowerPoint now".
    5. Launch Microsoft Excel just say "launch excel" or "launch excel now".
    6. Open outlook just say "launch outlook" or "launch outlook now".
    7. Launch Spotify just say "launch Spotify" or "launch Spotify now".
    8. Launch control panel just say "launch control panel" or "launch control panel now".
    9. Open task manager just say "launch task manager" or "launch task manager now".
    10. Launch paint just say "launch paint" or "launch paint now".

30. Play a song by saying "play a song" or "play song" or "play a song now".
31. Play any a video on a specific topic by saying "play a video on (the name of the topic)" or "play (the name of the topic) video" or "play (the name of the topic)". Example are as following:

    1. Play a video on cricket just say "play a video on cricket" or "play cricket video" or "play cricket".
    2. Play a video on football just say "play a video on football" or "play football video" or "play football".
    3. Play a video on hockey just say "play a video on hockey" or "play hockey video" or "play hockey".
    4. Start a video on sensors just say "play a video on sensors" or "play sensors video" or "play sensors".
    5. Play a video on artificial intelligence just say "play a video on artificial intelligence" or "play artificial intelligence video" or "play artificial intelligence".
    6. Play a video on robotics just say "play a video on robotics" or "play robotics video" or "play robotics".
    7. Start a video on how to make a cake just say "play a video on how to make a cake" or "play how to make a cake video" or "play how to make a cake".
    8. Play a video on python just say "play a video on python" or "play python video" or "play python".


32.  Play any song of your choice by saying "play (name of the song(maybe with the name of the singer if there are two or more song by the same name there will be no confusion.)) Examples are as follows:

    - Play lonely by the Beatles just say "play lonely by the Beatles" or "play the song lonely by the Beatles".
    - Play lonely by Justin Bieber just say "play lonely by Justin Bieber" or "play the song lonely by Justin Bieber".
    - Likewise, Play love yourself just say "play love yourself" or "play the song love yourself".
    - Open peaches just say "play peaches" or "play the song peaches".
    - I hope you understand now.

33. You can control the video by saying "pause", "play","volume up", "volume down", "next". Saying "pause" pauses the video in the web browser, Saying "play" plays the video in        


34. Open any website just say "open (the name of the website)" or "open (the name of the website) now" or "open (the name of the website) now" e.g.
     1. Open the Amazon website by saying "open Amazon" or "open Amazon website".
     2. Open the Bing website by saying "open Bing" or "open Bing website".
     3. Likewise, Open the code forces website by saying "open code forces" or "open code forces website".
     4. Furthermore, Open the code wars website by saying "open code wars" or "open code wars website".
     5. Open the DuckDuckGo website by saying "open DuckDuckGo" or "open DuckDuckGo website".
     6. Open the Facebook website by saying "open Facebook" or "open Facebook website".
     7. Likewise, Open the Flipkart website by saying "open Flipkart" or "open Flipkart website".
     8. Open the freeCodeCamp website by saying "open freeCodeCamp" or "open freeCodeCamp website".
     9. Open the GitHub website by saying "open GitHub" or "open GitHub website".
     10. Likewise, Open the Gmail website by saying "open Gmail" or "open Gmail website".
     11. Open the Google Maps website by saying "open Google Maps" or "open Google Maps website".
     12. Open the Google website by saying "open google" or "open google website".
     13. Likewise, Open the hacker earth website by saying "open hacker earth" or "open hacker earth website".
     14. Open the hacker rank website by saying "open hacker rank" or "open hacker rank website".
     15. Open the Instagram website by saying "open Instagram" or "open Instagram website".
     16. Likewise, Open the gaggle website by saying "open gaggle" or "open gaggle website".
     17. Open the LinkedIn website by saying "open LinkedIn" or "open LinkedIn website".
     18. Open the outlook express website by saying "open outlook express" or "open outlook express website".
     19. Likewise, Open the Outlook web app website by saying "open Outlook web app" or "open Outlook web app website"
     20. Open the Outlook website by saying "open outlook" or "open Outlook website".
     21. Open the Pinterest website by saying "open Pinterest" or "open Pinterest website".
     22. Open the Quora website by saying "open Quora" or "open Quora website".
     23. Likewise, Open the Reddit website by saying "open Reddit" or "open Reddit website".
     24. Open the Skype website by saying "open skype" or "open skype website".
     25. Open the snap deal website by saying "open snap deal" or "open snap deal website".
     26. Likewise, Open the stack overflow website by saying "open stack overflow" or "open stack overflow website".
     27. Open the telegram website by saying "open telegram" or "open telegram website".
     28. Open the tinder website by saying "open tinder" or "open tinder website".
     29. Likewise, Open the Twitter website by saying "open twitter" or "open Twitter website".
     30. Open the WhatsApp website by saying "open WhatsApp" or "open WhatsApp website".
     31. Open the yahoo website by saying "open yahoo" or "open yahoo website".
     32. Likewise, Open the YouTube website by saying "open YouTube" or "open YouTube website".
     33. Open the Zomato website by saying "open Zomato" or "open Zomato website".
     34. Open the Wikipedia website by saying "open Wikipedia" or "open Wikipedia website".
     35. Likewise, Open the YouTube Music website by saying "open YouTube Music" or "open YouTube Music website".
     36. Open the Tmall website by saying "open Tmall" or "open Tmall website".
     37. Open the Amazon Prime website by saying "open Amazon Prime" or "open Amazon Prime website".
     38. Likewise, Open the Baidu website by saying "open Baidu" or "open Baidu website".
     39. Open The New York Times website by saying "open The New York Times" or "open The New York Times website".
     40. Open the Facebook Messenger website by saying "open Facebook Messenger" or "open Facebook Messenger website".
     41. Likewise, Open the Google Drive website by saying "open Google Drive" or "open Google Drive website".
     42. Open the Google Photos website by saying "open Google Photos" or "open Google Photos website".
     43. Open the Google Photos Sync website by saying "open Google Photos Sync" or "open Google Photos Sync website".
     44. Likewise, Open the QQ website by saying "open QQ" or "open QQ website".
     45. Open the Shutterstock website by saying "open Shutterstock" or "open Shutterstock website".
     46. Open the TaoBao website by saying "open TaoBao" or "open TaoBao website".
     47. Likewise, Open 360.cn website by saying "open 360.cn" or "open 360.cn website".
     48. Open jingdong.com website by saying "open jingdong.com" or "open jingdong.com website".
     49. Open the Amazon.in website by saying "open Amazon.in" or "open Amazon.in website".
     50. Likewise, Open the Alibaba website by saying "open Alibaba" or "open Alibaba website".
     51. Open the Alibaba.com website by saying "open Alibaba.com" or "open Alibaba.com website".
     52. Open the zhihu.com website by saying "open zhihu.com" or "open zhihu.com website".
     53. Likewise, Open the weibo.com website by saying "open weibo.com" or "open weibo.com website".
     54. Open the Douban.com website by saying "open Douban.com" or "open Douban.com website".
     55. Open the Amazon.co.uk website by saying "open Amazon.co.uk" or "open Amazon.co.uk website".
     56. Likewise, Open the zoom website by saying "open zoom" or "open zoom website".
     57. Open the Google.com.hk website by saying "open Google.com.hk" or "open Google.com.hk website".
     58. Open the sina website by saying "open sina" or "open sina website".
     59. Likewise, Open Xinhua website by saying "open xinhua" or "open xinhua website".
     60. Open the Amazon.de website by saying "open Amazon.de" or "open Amazon.de website".
     61. Open the Amazon.fr website by saying "open Amazon.fr" or "open Amazon.fr website".
     62. Likewise, Open the Amazon.es website by saying "open Amazon.es" or "open Amazon.es website".
     63. Open the Amazon.it website by saying "open Amazon.it" or "open Amazon.it website".
     64. Open the Amazon.co.jp website by saying "open Amazon.co.jp" or "open Amazon.co.jp website".
     65. Likewise, Open the Amazon.ca website by saying "open Amazon.ca" or "open Amazon.ca website".
     66. Open the Amazon.com.mx website by saying "open Amazon.com.mx" or "open Amazon.com.mx website".
     67. Open the Amazon.com.br website by saying "open Amazon.com.br" or "open Amazon.com.br website".
     68. Likewise, Open the Amazon.com.au website by saying "open Amazon.com.au" or "open Amazon.com.au website".

35. Search many websites like YouTube, Google (with Google Images, Google News etc.), Bing, Yahoo, DuckDuckGo, Wikipedia, Wiktionary, and many more just by saying "search (the name of the website) on (the thing you want to search on the website.). For example,
    - If you want to search for "Python" on YouTube, you can say "search Python on YouTube".
    - If you want to search for "Python" on Google, you can say "search Python on Google".
    - If you want to search for "Python" on Google Images, you can say "search Python on Google Images".
    - Weather you want to search for "Python" on Google News, you can say "search Python on Google News".
    - If you want to search for "Python" on Google Maps, you can say "search Python on Google Maps".
    - If you want to search for "Python" on Google Scholar, you can say "search Python on Google Scholar".



36.  Translate the English to many other languages just saying "translate (the sentence you want to translate) to (the language to which you want to translate the sentence)" example "translate hello to Spanish" will translate the English sentence "hello" to Spanish. The supported languages are :
        - Arabic
        - Bengali
        - Bulgarian
        - Catalan
        - Chinese
        - Croatian
        - Czech
        - Danish
        - Dutch
        - ESPAÑOL
        - ESTONIAN
        - FINNISH
        - Greek
        - Hebrew
        - Hindi
        - Hungarian
        - Indonesian
        - Italian
        - Japanese
        - Korean
        - Latvian
        - Lithuanian
        - Malay
        - Norwegian
        - Persian
        - Polish
        - Portuguese
        - Romanian
        - Russian
        - Serbian
        - Slovak
        - Spanish
        - Swedish
        - And many more.

37. Answer to many questions like :- 
    1. What is your name?
    2. What is your age?
    3. Who is your favorite animal?
    4. What is your job?
    5. What is your favorite color?   
    6. How is your favorite food?
    7. Who is your favorite actress?
    8. What is your favorite movie?
    9. What is your favorite sport?
    10. Who is your favorite singer?
    11. What is your favorite game?
    12. What is your favorite book?
    13. Who is your favorite songwriter? 
    14. Who is your favorite cartoon?
    15. What is your favorite cartoon character?
    16. Who is your favorite actor?
    17. And many more...


38.  Type by saying "start typing" and then start typing by the instruction given.
39.  Press many key by saying "press (the key you want to press) key" example "press space key" will press the space key on your keyboard or "press enter key" will press the enter key on your keyboard, "press tab key" will press the tab key on your keyboard and so on.
   
40. Exit the application just by saying "exit the application" or "exit" or "goodbye" or "bye".
41. If the Virtual assistant Don't know the answer to any of your questions, Olivia will ask you if he or she wants to search the query in google or YouTube or Wikipedia. If you say yes, then it will ask in which of these websites you want to search the query like if you YouTube it will search the query on YouTube. In last, If you say no, then it will do nothing and just say 'ok. Anything else sir?'


### In progress features

1. Tell you your operating system by saying "my operating system" or "my operating system is" or "my operating system is" or "my operating system is". 
1. Give you a random fact by saying "fact" or "tell me a fact" or "tell me a random fact".
1. Give a list of all the commands by saying "commands" or "help" or "what are the commands".
1. Tell you the temperature by saying "temperature" or "what is the temperature" or "tell me the temperature" or "tell me the weather forecast".
1. Tell you the current location by saying "location" or "what is the location" or "tell me the location" or "tell me the weather forecast".
1. Turn on and off Wi-Fi.
1. Stop music.
1. Change color.
1. Do calculation.

> Please tell me the features you want me to add by creating an issue.

## Installation instruction

1. Install Python.
1. To start open CMD in the directory then run the code below!

`pip install -r requirements.txt`<br>

1. Run the .py file in any IDE.

### If You Get `No Module Named pyaudio` Error!

Open CMD in the directory then run the code below!

```
pip install pipwin
pipwin install pyaudio
```

- Be sure to change the application paths on script.py otherwise it won't open Google Chrome and other Apps. <br>


## How to use the application

1. The recognition can be delayed if there is some background noise in the environment.
2. Just open the software.
3. Here the software is the best for some with disability.


# Precautions while using the software in the application

1. Do not use the software in the application if you are not in the comfort of your own.
2. Please do not forget to say "close" after playing a video on YouTube.
3. Do not use it for bad purposes.
  
# Libraries used in the software  

/* comment start 
from bs4 import BeautifulSoup   #   BeautifulSoup is used for web scraping
from googletrans import Translator  # googletrans is used for translation and google translate is used for language detection
from tkinter import *
import clipboard  # clipboard is used to read the text from the clipboard
import ctypes   #   ctypes is used maniplulate the data types
import datetime  #  date and time module is for timezones
import json  #  json library is used for reading and writing json files obtained by apis
import math  #  math library provides math fuctions .
import numpy as np
import os  # os library is used to open the system and open the specified file
import psutil  # pip install psutil # psutil is used to get the cpu usage and ram usage and disk usage and battery usage
import pyautogui  # pyaoautogui is used for mouse and keyboard control
import pyttsx3  # pyttx3 is used for text to speech
import pywhatkit  # pywhatkit is used for playing the youtube videos
import random  # random library is used for random number generation
import re  # regular expression library is used for regular expressions
import requests  # requests library is used to make http requests to apis
import shutil  # shutil is used to copy files and folders from one location to another location or for archiving files and folders
import smtplib  # smtplib is used for sending emails
import speech_recognition as sr # spech_recognition library is used for speech recognition and google translate is used for language detection
import subprocess  # subprocess is used to run the command line commands for screen capture
import sys  # sys library is used to exit the program
import time  # time library is used for timezones
import tkinter as tk
import urlopen  # used to open url
import webbrowser  # webbrowser is used to open the url in the default browser
import wikipedia  # get article from wikipedia
import win32com.client as wincl
import winshell
*/ comment end */


Clipboard library: [Clipboard](https://pypi.python.org/pypi/clipboard)
Ctypes library: [ctypes](https://pypi.python.org/pypi/ctypes)
Date and time library: [datetime](https://pypi.python.org/pypi/datetime)
Json library: [json](https://pypi.python.org/pypi/json)
Math library: [math](https://pypi.python.org/pypi/math)
Numpy library: [numpy](https://pypi.python.org/pypi/numpy)
Os library: [os](https://pypi.python.org/pypi/os)
Psutil library: [psutil](https://pypi.python.org/pypi/psutil)
Pyautogui library: [pyautogui](https://pypi.python.org/pypi/pyautogui)
Pyttsx3 library: [pyttsx3](https://pypi.python.org/pypi/pyttsx3)
Pywhatkit library: [pywhatkit](https://pypi.python.org/pypi/pywhatkit)
Random library: [random](https://pypi.python.org/pypi/random)
Regular expression library: [re](https://pypi.python.org/pypi/re)
Requests library: [requests](https://pypi.python.org/pypi/requests)
Shutil library: [shutil](https://pypi.python.org/pypi/shutil)
Smtplib library: [smtplib](https://pypi.python.org/pypi/smtplib)
Speech recognition library: [speech_recognition](https://pypi.python.org/pypi/speech_recognition)
Subprocess library: [subprocess](https://pypi.python.org/pypi/subprocess)
Sys library: [sys](https://pypi.python.org/pypi/sys)
Time library: [time](https://pypi.python.org/pypi/time)
Tkinter library: [tkinter](https://pypi.python.org/pypi/tkinter)
Urlopen library: [urlopen](https://pypi.python.org/pypi/urlopen)
Webbrowser library: [webbrowser](https://pypi.python.org/pypi/webbrowser)
Wikipedia library: [wikipedia](https://pypi.python.org/pypi/wikipedia)
Win32com library: [win32com](https://pypi.python.org/pypi/win32com)
Winshell library: [winshell](https://pypi.python.org/pypi/winshell)



# Technologies used in the software


INTELLIGENT VOICE ASSISTANT
Intelligent Voice Assistant
Bachelor Thesis
Spring 2012
School of Health and Society
Department Computer Science
Computer Software Development
Writer
Shen Hui
Song Qunying
Instructor
Andreas Nilsson
Examiner
Christian Andersson
INTELLIGENT VOICE ASSISTANT
I
School of Health and Society
Department Computer Science
Kristianstad University
SE-291 88 Kristianstad
Sweden
Author, Program and Year:
Song Qunying, Bachelor in Computer Software Development 2012
Shen Hui, Bachelor in Computer Software Development 2012
Instructor:
Andreas Nilsson, School of Health and Society, HKr
Examination:
This graduation work on 15 higher education credits is a part of the requirements for a
Degree of Bachelor in Computer Software Development (as specified in the English translation)
Title:
Intelligent Voice Assistant
Abstract:
This project includes an implementation of an intelligent voice recognition assistant for Android
where functionality on current existing applications on other platforms is compared. Until this day,
there has not been any good alternative for Android, so this project aims to implement a voice
assistant for the Android platform while describing the difficulties and challenges that lies in this
task.
Language:
English
Approved by:
_____________________________________
Christian Andersson Date
Examiner
INTELLIGENT VOICE ASSISTANT
II
Table of Contents Page
Document page I
Abstract I
Table of Contents II
1 Introduction 1
1.1 Context 1
1.2 Aim and Purpose 2
1.3 Method and Resources 3
1.4 Project Work Organization 7
1.5 Acknowledgements 8
2 Analysis 9
2.1 Information Retrieval 9
2.2 Theory Model 11
2.3 Alternative Models/solution 15
2.4 Environmental Consequences 20
3 Realization 21
3.1 Choice of Solution 21
3.2 Equipment/ Choice of Materials 30
INTELLIGENT VOICE ASSISTANT
III
3.3 Problems and Solutions 31
4 Results 34
4.1 Design 34
4.2 Functioning 36
4.3 Operation and Maintenance 39
5 Conclusions 45
6 Recommendations for Further Work 47
6.1 Design Improvements 47
6.2 Additional Functions 47
6.3 Database Capacity 47
6.4 Humanized Voice Recognition 48
6.5 Improved Interface 48
7 References 49
8 Appendix A Figure 50
9 Appendix B Code 52
INTELLIGENT VOICE ASSISTANT
1
1 Introduction
1.1 Context
This project is based on Android application development and provide personal assistant using voice
recognition or text mode operation. This program includes the functions and services of: calling
services, text message transformation, mail exchange, alarm, event handler, location services, music
player service, checking weather, Google searching engine, Wikipedia searching engine, robot chat,
camera, Bing translator, Bluetooth headset support, help menu and Windows azure cloud computing.
As it integrates most of the mobile phone services for daily use, it could be useful for getting a more
convenient life and it will be helpful for those people who have disabilities for manual operations.
This is also part of the reason why it has been chosen as the degree project.
This project is originated from a popular application from Apple called “Siri” [1]. This application
was released on the date when the iPhone4S was published. This application is very interesting, easy
going and convenient, with wide real world usage and large developing potential. This application is
not limited by different generations and occupations, and can be applied to many industries that we
have in the real world. For instance, the voice assistance is very useful for personal assistants,
direction guides or driving, helps among the disabled community, and so on.
This is a short description about “Siri” from Wikipedia to illustrate the voice product: “Siri”
an intelligent personal assistant and knowledge navigator which works as an application for Apple's
iOS. The application uses a natural language user interface to answer questions, make
recommendations, and perform actions by delegating requests to a set of web services. Apple claims
that the software adapts to the user's individual preferences over time and personalizes results, and
performing tasks such as finding recommendations for nearby restaurants or getting directions. 
INTELLIGENT VOICE ASSISTANT
2
1.2 Aim and Purpose
According to the overall description in the context, the purpose of the project is to develop an
Android application that provides an intelligent voice assistant with the functionalities as calling
services, message transformation, mail exchange, alarm, event handler, location services, music play
service, checking weather, searching engine (Google, Wikipedia), camera, Bing translator, Bluetooth
headset support, help menu and Windows azure cloud computing.
Many years ago, software programs were developed and run on the computer. Nowadays, smart
phones are widely used by all people. About 35 percent of the Americans have some sort of
Smartphone. This shows that the market is increasing fast and there are also more capabilities for
Smartphone because of this wide use. [2]
Therefore, the software development on the Smartphone is very promising. The operation modes on
the Smartphone are by working with gestures and through the keyboard. It is not a convenient way
for users with completely manually input. The common way of communication used by people in
daily life is through the speech. If the mobile phone can listen to the user for the request or handle
the daily affairs, then give the right response, it will be much easier for users to communicate with
their phone, and the mobile phone will be much more “Smart” as a human assistant.
This project is focusing on the Android development over the voice control (recognition, generate
and analyze corresponding commands, intelligent responses automatically), Google products and
relevant APIs (Google map, Google weather, Google search and etc), Wikipedia API and mobile
device references ranging from Speech-To-Text, Text-To-Speech technology, Bluetooth headset
support and camera; advanced techniques of Cloud computing, Multi-threading, Adobe Photoshop
image editing skills. As all those functionalities and services for the project have been explained, the
main structure and construction of the project has been basically illustrated with its goals. 
INTELLIGENT VOICE ASSISTANT
3
1.3 Method and Resources
This project mainly concerns the work on Android application development; request calling between
different Android applications, human-mobile phone interaction, database creation and management,
the program will reference a lot of APIs from Google, Wikipedia, and Android development skills.
Apart from the project itself, there is also some investigation works on the existed products in this
area and the tendency of voice product, personal assistant developing. Two products were mainly
investigated that are popular and representative, the English product of “Siri” and the Chinese
product of “iFly” [Chinese name: 讯飞语点 [3]]. The investigation focus on how those ideas
originated; what functionalities and services they have; how they provide these services to the
customers; test the product and related functions to get the architect, structure, logical algorithms of
those products; how they spread and promote the product in marketing; and how they refine and
upgrade the products from different versions. Table-1 shows the comparison about some basic
functions between “Siri” and “iFly”.
Function Siri iFly
Call Service Yes Yes
SMS Message Service Yes Yes
Open Application No Yes
Web Search Service Google Search Engine Baidu Search Engine
Reminder 24h Unlimited
Music Play Local Library Local + Remote Library
Command Text Modify Yes No
Language
English & French & German
& Japanese
Chinese
Table-1
In addition, it has been investigated that the developing tendency in this area based on the internet
information and online video of conference from Apple, Android and some other Chinese products. 
INTELLIGENT VOICE ASSISTANT
4
To learn how they are going to develop the products in this area from all possible aspects and the
potential developing factors.
For a better and efficient development, the project is carried out over the XP (Extreme Programming)
model. Extreme programming (XP) is a software development methodology which is intended to
improve software quality and responsiveness to changing customer requirements. As a type of agile
software development, it advocates frequent "releases" in short development cycles (timeboxing),
which is intended to improve productivity and introduce checkpoints where new customer
requirements can be adopted. [4]
The developments will on the small cycle model repeatedly, every cycle will have analysis, design,
implementation and test. Figure-1 somehow shows how to follow the XP develop model.
Figure-1
The total work have been defined in one hundred percentages, the list show how many percentages
developers finished in each week; totally it has been worked for eight weeks to complete the project.
In addition, the chart also shows how much that has been completed for the different part of the
development from the requirement to the test. Figure-2 figures out the process and the progress that
has been finished in each phase to complete the project. 
INTELLIGENT VOICE ASSISTANT
5
Figure-2
Figure-3 shows the process of the completion percentages with the timeline for each perspective
includes requirement, design, implementation and test. Figure-3 presents the efficiency and
completion of the project from all aspects.
Figure-3
0
5
10
15
20
25
30
35
40
45
50
week 1 week 2 week 3 week 4 week 5 week 6 week 7 week 8
Requriment
Design
Implementation
Test
0
10
20
30
40
50
60
70
80
90
100
week 1 week 2 week 3 week 4 week 5 week 6 week 7 week 8
Requriment
Design
Implementation
Test
INTELLIGENT VOICE ASSISTANT
6
Figure-3 also indicates the tendency and expected working process of the project work. In addition,
the efficiency and evaluation speed of the project can be seen from it. And most important is the
diagram points out how the project will be completed in time.
INTELLIGENT VOICE ASSISTANT
7
1.4 Project Work Organization
The project work is organized based on the actual task for the designing, implementation, test and
optimization. As it has been primary planned, each of the developers worked 5 days a week; 3 days
for implementation, and 2 days for testing and summarizing the work, totally it is 8 weeks’ work.
Apart from the designing, implementation and testing, developers also defined the work plan every
time before the implementation and improve the project after the accomplishment of each individual
section.
Developers communicate though the MSN, Facebook and Skype for sharing the ideas and discuss the
project. Data statistics and relative materials is collected and shared through Dropbox. Mostly the
work was done by pairing programming, that is, every time developers made a meeting and set
together for designing, figure out a valid solution and doing the implementation together.
The high-level designing and the framework was done together, and the individual implementation of
functions was assigned to different developers, but the developer was not only caring his own part, but
also considering the whole program. 
INTELLIGENT VOICE ASSISTANT
8
1.5 Acknowledgements
As it requires an Android phone testing and running the program, the Android phone is quite
necessary. The school provided a Sony Ericsson phone with the Android operating system, but the
phone was in a 2.0 version which is too low to implement the project. Thanks to WANG LINLIN for
lending the phone and it can be frequently used for the project development. 
INTELLIGENT VOICE ASSISTANT
9
2 Analysis
2.1 Information Retrieval
As this program includes the functions and services of: calling services, text message transformation,
mail exchange, alarm, event handler, location services, music player service, checking weather, Google
searching engine, Wikipedia searching engine, robot chat, camera, Bing translator, Bluetooth headset
support and help menu. The list below indicates the information and the requirements of each individual
function.
The program has two modes to well fetch the services and functions. The program will start with voice
mode as its primary mode to provide the voice assistant, but the user can select switching to the text
mode if he or she is not well working with the voice mode or the surrounds don’t support the voice
recognition well.
 Calling service, the application should allow the users to give a call to the person in the contacts.
By giving a correct command with the calling request to a stored person, the Android phone
should successfully direct to the number of the person requested.
 Text Message transformation, customers are able to send the SMS to a specific person in the
contacts. By giving a correct command contains the messaging request keyword together with
the destination person, the message should be sent to the destination immediately.
 Mail exchange, customers are able to send the mail to the person with mail address in the
contacts. By giving a correct command contains the mail request keyword together with the
destination person; the mail should be received by the recipient after it has been sent.
 Alarm, as a basic function on the mobile phone, it is frequently that users need to set the alarm
to a specific time. The user could set the alarm through the request with the given time.
 Event handler, the application should allow the user to set as many events as they want.
Customers with the event content should be stored and available for the user to check, modify
and delete.
 Location services, location services provide the functions for the user to check the current
location or find the direction to a destination. The user should get an easy to understand map
with the locations or routes depending on the category of the request.
INTELLIGENT VOICE ASSISTANT
10
 Music player service, the music player offers the services to the user to play a named or a
randomly picked song in the pre-stored song list on the mobile phone. And it could be stopped
when the user wants to terminate it.
 Checking weather, the user could check the weather in any place. In addition, the weather is
returned with the temperature and humidity; the user could also check the weather for current
day, tomorrow or in next four days.
 Google searching engine, the search engine enable the user to search anything on Google. The
search engine will give result list back and displayed on the browser.
 Wikipedia searching engine, the search engine enable the user to search anything on Wikipedia.
The result is given back on the web browser with the searched content on Wikipedia.
 Robot chat, this is the robot chat which provides fun to the user. After enter the chat mode, a text
response will given by the mobile phone whenever the user speaks to it.
 Camera, the camera function will call the camera on the mobile phone to take a picture of the
current view, the picture will be stored in the Gallery for later viewing and operation.
 Bing translator, the translator will translate the original text in the object language the user wants.
There have been 25 object languages stored and the original text should be English.
 Bluetooth headset support, since it is not possible to do the voice recognition while the music
player is playing or the surroundings are noisy; the Bluetooth headset support makes it possible
to speak to the headset rather than the mobile phone if the user enables it.
 Help menu, the user can choose the help menu if the user doesn’t know how to work with the
functions. The help menu gives the list of functions with the examples and explanation of how to
work with different functions as well. 
INTELLIGENT VOICE ASSISTANT
11
2.2 Theory Model
The project is based on the theories related to various aspects of software engineering principles and
software development model; Java programming skills and Android tutorials, Database management
and network communication technologies.
The database and the web service in this project are put on the windows azure cloud; developers will
never be required to run the web service and database locally. The cloud platform will handle the
execution and maintenance. Hence, cloud computing is an important concept and theory guide the
development.
• Cloud computing: Cloud computing refers to the delivery of computing and storage
capacity as a service to a heterogeneous community of end-recipients. The name comes
from the use of clouds as an abstraction for the complex infrastructure it contains in system
diagrams. Cloud computing entrusts services with a user's data, software and computation
over a network. It has considerable overlap with software as a service (SaaS). [5]
• Software engineering principles
Extreme programming will direct the development process of the project, it focus on the
development cycle of defining the requirement, corresponding design and test, integration
and simplicity; during the development, there should always be working in pair
programming, as well as doing the revision control, calculate the velocity and efficiency.
Extreme programming (XP) is a software development methodology which is intended to i
mprove software quality and responsiveness to changing customer requirements. As a type o
f agile software development, it advocates frequent "releases" in short development cycles (t
imeboxing), which is intended to improve productivity and introduce checkpoints where ne
w customer requirements can be adopted. [6]

• Java programming: java API and reference, which is helpful in guide programming in
eclipse and construction of the framework, and the completion of the functions.
Java is a programming language originally developed by James Gosling at Sun
Microsystems (which has since merged into Oracle Corporation) and released in 1995 as a
core component of Sun Microsystems' Java platform. The language derives much of its
syntax from C and C++ but has a simpler object model and fewer low-level facilities. Java
applications are typically compiled to bytecode (class file) that can run on any Java Virtual
Machine (JVM) regardless of computer architecture. Java is a general-purpose, concurrent,
class-based, object-oriented language that is specifically designed to have as few
implementation dependencies as possible. It is intended to let application developers "write 
INTELLIGENT VOICE ASSISTANT
12
once, run anywhere" (WORA), meaning that code that runs on one platform does not need
to be recompiled to run on another. Java is currently one of the most popular programming
languages in use, particularly for client-server web applications, with a reported 10 million
users. [7] [8]
• Android: this project is mainly focus on the Android development to enable most of the
Android functions for daily use ranging from check the weather to check location, and
weather services and etc, Android reference will be the theory promote the development of
the project and related applications, [9] [10] [11]
• Database management: The program will always work with different databases like
Microsoft SQL Server and MySQL Server. Cloud database to handle the data storing,
updating, and retrieving. The following chapters indicate the usage and information of each
database. Through this information, it can be obtained of the advantages and disadvantages
of each database.
The data stored in this project is not so much and complicated as in a corporation; therefore,
each of the databases mentioned can well meet the requirement of the data storage, updating
or be dropped as well. However, the choice of the databases still depends upon the
convenience while considering the advantage and disadvantage. As the commands are
received by the program, the command should be analyzed with the database, MS SQL
Server has been the best choice since it provides the method to search in the content which
is convenient to identify the keyword, keyword category and keyword content, this
advantage is contributed by the method CHARINDEX.
Microsoft SQL Server 2012 is a cloud-ready information platform that will help
organizations unlock breakthrough insights across the organization and quickly build
solutions to extend data across on-premises and public cloud, backed by mission critical
confidence [12]
The MySQL database has become the world's most popular open source database because of
its high performance, high reliability and ease of use. It is also the database of choice for a
new generation of applications built on the LAMP stack (Linux, Apache, MySQL, PHP /
Perl / Python.) Many of the world's largest and fastest-growing organizations including
Facebook, Google, Adobe, Alcatel Lucent and Zappos rely on MySQL to save time and
money powering their high-volume Web sites, business-critical systems and packaged
software.
MySQL runs on more than 20 platforms including Linux, Windows, Mac OS, Solaris, IBM
AIX, giving you the kind of flexibility that puts you in control. Whether you're new to
database technology or an experienced developer or DBA, MySQL offers a comprehensive
range of database tools, support, training and consulting services to make you successful.
[13]
INTELLIGENT VOICE ASSISTANT
13
SQL Azure is a highly available and scalable cloud database service built on SQL Server
technologies. With SQL Azure, developers do not have to install setup or manage any
database. High availability and fault tolerance is built-in and no physical administration is
required. SQL Azure is a managed service that is operated by Microsoft and has a 99.9%
monthly SLA. [14]
• Network communication technologies
The communication in this program is based on the predefined protocol, the communication
within the program is implemented in following the pre-defined protocol, the other main
part of the communication is between the Android program in eclipse and the cloud
platform, this will be done by working with URL, WSDL file. Figure-4 shows some
knowledge of cloud platform, URL and WSDL. [15]
Figure 4
The WSDL describes services as collections of network endpoints, or ports. The WSDL
specification provides an XML format for documents for this purpose. The abstract
definitions of ports and messages are separated from their concrete use or instance,
allowing the reuse of these definitions. A port is defined by associating a network address
with a reusable binding, and a collection of ports defines a service. Messages are abstract
descriptions of the data being exchanged, and port types are abstract collections of
supported operations. The concrete protocol and data format specifications for a 
INTELLIGENT VOICE ASSISTANT
14
particular port type constitutes a reusable binding, where the operations and messages are
then bound to a concrete network protocol and message format. In this way, WSDL
describes the public interface to the Web service. [16]
INTELLIGENT VOICE ASSISTANT
15
2.3 Alternative Models/solution
Figure-5
The architecture (see figure-5) is depending on the developing simulation. The architecture diagram
is not only directed the development of the project, but also figure out the main fields and technique
references related to implementing the project with expected functions.
- The voice input will be firstly recorded by the Android phone.
- The voice will be recognized by the Android applications by using the Android API and Java
API. A recorded text will be generated and send to the cloud server or Android applications
depending on the command.
- The cloud server will decode the received text with the Java API, references, and predefined
database, then decide the following procedures that should be executed.
- A command will be generated into a URL by the cloud server and sent to the specific server
(Google server, Wikipedia server).
- The server which receives the request will using the specific API of Wikipedia API, Google
API to generate the response in XML or JSON format.
- Cloud server will obtain the XML/ JSON response file and transform to a specific response
which will be led to the Android application.
- The Android application will generate the audio output to the customers with the mobile
speaker.
INTELLIGENT VOICE ASSISTANT
16
Figure-6
The configuration diagram (see figure-6) explains all the develop methods, the real strategies and
development process with the core techniques that are used in the project work. Most of the
applications and useful mechanisms are included.
- When the Android application received the audio input, the speech recognition will record
the voice with acoustic model and language model/Grammar, a string reflects the audio input
will be delivered to the java server.
- Whenever the string input is received by the cloud server, it will be passed down to the web
service, further decoded with the cloud database which includes all the possible commands.
- While the meaning of the string has been detected, the corresponding command is
transmitted to the specific application/ server program depending on the command.
- The application/server program generates the result and response back with an object to the
Android phone according to the command and relevant data.
INTELLIGENT VOICE ASSISTANT
17
- The Android phone generates the response into the audio output that delivered to the
customer, or the operations that should be carried out to complete the expected result.
List below indicates the solutions to each of the functions in this program.
• Calling service, when the application receive the command for making phone calls to
someone, with the name it will first check the contacts and find the phone number of the
person that contain the given name, then make the phone call by directing to that number.
By checking through the contact list and find the phone number, the calling can be dialled
out by calling the system call action intent in Android.
• Text Message, when the application receives the command for sending a SMS message to
someone, it will first check the contacts and find the phone number of the person contain the
given name, and then send the message successfully. By checking through the contact list
and find the phone number, the message can be sent out by calling the system message send
action intent in Android. There are two alternative solutions to complete it:
 By capturing the content and name, directly send the message content to the number
of the person’s name.
 By capturing the content and name, switch to the message sending function interface
on the mobile phone with the person and content, the user can decide if send it or not
depend on the captured content is correct or not.
• Mail exchange, when the application receives the command for sending email to someone, it
will first check the contacts and find the email address of the person which contains the
given name, and then send the email successfully to the destination. By checking through
the contact list and find the email address, the email can be sent out by calling the system
email send intent in Android. There are two alternative solutions to complete it:
 By capturing the content and name, directly send the email content to the address of
the person’s name.
 By capturing the content and name, switch to the email interface on the mobile phone
with the person and content, the user can decide if send it or not depend on the
captured content is correct or not.
• Alarm, when the application receives the request of setting the alarm to a valid time, the
program will get the time with dedicated hour and minute, the set the alarm to that specific
time. The alarm can be set by the system alarm manager with the time. There are two forms
to get alarm work:
INTELLIGENT VOICE ASSISTANT
18
• Set the alarm to the given time and alarm will be activated when the time comes up.
• Set the alarm to the given time and alter appears when the time comes up, the user
decide to stop the alarm or not.
• Event handler, when the application receives the command of setting an event to a valid
time, the event will be stored and can be viewed later. The user can check one/all events and
choose to modify, delete the event, this function can be achieved by starting the sub event
application in the program with the title, content, and time from the user’s input.
• Location service, the location service can be categorized in two forms depend on the request,
the service will either return the current location or the route from the current location to the
destination depending on what is required by the user.
• If the user wants to check the current location, the program will get and display the
location through mobile phone GPS module in a map.
• If the user wants to get the route from the current location to other city, the program
will first check the GEO information for the destination, then send current and
destination position to the Google map server and get the route info then display it in
a map with highlighted route.
• Music player service, when the program receive a command of play a song, it will firstly
check whether the command contains the song’s name or not, if the name appeared in the
command, it will get the path of the song and play the song, otherwise the program will
randomly pick a song from the media library and play it. Every time when the program is
loaded, it will called the system to collection all the media files on the mobile then save then
into the library, if the user wants to play the song, it will start the music play service and
play the music in background.
• Checking weather, when the program receives the request of checking weather, it will firstly
check whether the command contains the location information or not, if the command
contain to a location name, then it will check if the command have a date value included or
not. The Google weather service is used to accomplish the weather checking.
 If today is detected, the weather for today in the specified location will be presented
with the temperature, condition, humidity, wind direction.
 If no today is detected, the weather for next four days in the specified location will be
presented with the highest and lowest temperature, condition.
INTELLIGENT VOICE ASSISTANT
19
• Google searching engine, when the command is detected with the action to use the Google
search engine. The program will generate the URL of the Google search link with the given
search content and then start the system’s internet browser with this link, finally gives the
result back on the web browser.
• Wikipedia searching engine, when the command is detected with the action to use the
Wikipedia engine. The program will generate the URL of the Wikipedia link with the given
search content and then start the system’s internet browser with this link, finally gives the
result back on the web browser.
• Robot chat, if the command contains the words can be understood to enable chat, the
program will enter the chat mode and give the user a predefined response to each sentence
give by the user. The chat mode continues work until the chat is finished by the correct
command.
• Camera, when the application receives the command to start the camera, the program will
start the intent to enable the camera preview, after the photo has been captured, it will be
saved in to the SD card memory and notify to the gallery for updating.
• Bing translator, the program will firstly detect the command with the destination language
code and the content; generate a URL that contains the original language, the destination
language and content. Then the URL will be opened and receive the result from the Bing
translator for presenting to the user.
• Bluetooth headset support, the Bluetooth mode can be automatically activated by the user
plug in the Bluetooth headset to the mobile phone. The program will enable the Bluetooth
button when it receives a broadcast from the system. When the connection is enabled
between the mobile phone and the Bluetooth headset, the audio manager of the mobile
phone can be set to the Bluetooth headset mode and use the Microphone and speaker on the
headset.
• Help menu, the user can open the help menu by selecting on the main option menu or given
the help command, the help menu is designed by a main help menu and a list of sub menus,
each sub menu is corresponded to one function with the explanation and examples to show
how it works, each menu is designed in an individual activity.
INTELLIGENT VOICE ASSISTANT
20
2.4 Environmental Consequences
This program is green to the environment and no pollution will be generated by the software or
hardware. During the development, the process will not do any harm to the surrounding
environment since it is software development on the computer. The following list contains all the
software, hardware, develop platform, developing process we use in this project. Hence it can
prove that no pollution is created by these rephrases.
Develop platform: Microsoft Windows 7, Windows Azure Platform.
Develop tools and environment: Java ™, JDK, Eclipse IDE, Android SDK, ADT Plug-in, ADV,
and Plug-in for Eclipse, MySQL query browser, DB-Designer, SQL Server Management Studio,
and Microsoft Visual Web Developer 2010 Express.
API and reference: Java API, Android API, Google API (Google Map, Google Weather),
Wikipedia API, SQL tutorial, UML reference, JSON, XML, Cloud computing, multi-threading
techniques, .net framework 4.0.
Software application on Android phone: Android Internet explorer, Google voice recognize, TTS
Service Extended, Alarm, Mobile phone calling services, text message services.
Support application: Adobe Photoshop CS5, Meitu (Chinese).
Hardware support: Android phone [HTC/Samsung], PC.
Developing model: XP (Extreme programming)
INTELLIGENT VOICE ASSISTANT
21
3 Realization
3.1 Choice of Solution
This chapter explains the actual solution to construct of the whole program. The functions include:
Calling services, message transformation, mail exchange, alarm, event handler, location services,
music play service, checking weather, searching engine (Google, Wikipedia), camera, Bing
translator, Bluetooth headset support, help menu and Windows azure cloud computing.
As it has been illustrated in 2.3, the whole construction of the program mainly cover Android
application development, the database design, web service and cloud computing.
The Android application, which implements and presents all the functions, is constructed in Eclipse
with Android development references. The program implements voice recognition to capture the
incoming requests. Creating the main activity and building each of the functions, implementing the
logic to construct the whole program. Further by fetching the web service on the Windows Azure
Cloud, the command can be analyzed with the storage on the database; corresponding responses will
be directed to specific function in the program. Figure-7 shows the overall design of the program
through UML.
INTELLIGENT VOICE ASSISTANT
22
Figure-7
The database is designed with MS SQL server. By creating different tables to store the data in
different category, the data can be well stored, retrieved, updated or deleted. To well support the data
process in web service, the database is uploaded on the Windows Azure Cloud.
Web service, the web service is implemented in C# since it is placed on the Windows Cloud. The
web service takes the incoming request as the parameter; analyze it by check the keyword contained
in the request, and give correct response to the program. The same with the database, the web service
is uploaded on the Windows Azure Cloud.
Cloud computing, Windows Azure has been chosen as the cloud platform since it provide a three
months’ free use with a registered account. By establishing the database and creating the web
services for intended use, the database and the web service are uploaded on the Cloud and, the data
processing are going as cloud computing.
The following indicate the design for each individual function in this program.
• The programs start with the voice recognition, by implementing the RecognitionListener, it
will capture the text every time the speaker speaks to it, then the generated text and send to
the cloud (see Figure-8).
Figure-8
• The azure cloud which is an open cloud platform, where the software, database, web service
can be placed there for future use. In this program, the web service and database are uploaded
on the azure cloud for executing and maintenance (see Figure-9).

Speech
Recognizer
Weather today “Weather today”
“Weather today”
Internet
WS
Database
Cloud
“3|1|0”
INTELLIGENT VOICE ASSISTANT
23
Figure-9
 The web service is written in C# and connects to the cloud database, the captured text
will firstly be sent to the cloud as a parameter to call the analysis method and the method
will check the keywords from the database keyword library. When the keyword is
identified, it will implement different operations depending on the keyword category and
give corresponding response that follows the protocol. (See Table-2 from Appendix A)
 The database was created in MS SQL server and uploaded on windows azure cloud
through windows azure database manager, it defines the different keyword categories
depending on the functions, the keywords for each category and response for different
keywords category. (see Figure-10)
Figure-10
The database has been designed into eight tables, each table contain different information
for each category, the “Keywords”, “Language”, “Map”, “Weather”, “Weatherlocation”
tables is used for the application to identify the different command, “RobotCategories”,
“RobotKeywords”, “RobotResponse” table are used for the robot chat. The following
chapters describe each of the table and what is intended usage.
“Keywords” table: (see Figure-11)
Figure-11
INTELLIGENT VOICE ASSISTANT
24
The “keywords” table contains three columns to present the data, the “KeywordsID”
column is used to specify the different keyword in its unique ID, “KeywordsContent”
column is used to save the keyword info and the “KeywordsCategory” classify the
content into different category.
“Language” table: (see Figure-12)
Figure-12
The “Language” table is used to discern the language and translate it to objective
language code, the “languageID” column is used to specify the different language in its
unique ID, “languageDescription” is used to describe the language and the
“languageCode” is used to change the text-based language in to language code.
“Map” table: (see Figure-13)
Figure-13
The “Map” table is used to discern the user’s navigation proposes. The “MapID” is used
to specify the different info in its unique ID and the “Info” table is used to specify the
content.
“RobotCategories” table: (see Figure-14)
Figure-14
The “RobotCategories” table is used to discern the robot response category. The
“CategoryID” is used to specify the different category name in its unique ID and the
“CategoryName” column is used to specify the content in different case. 
INTELLIGENT VOICE ASSISTANT
25
“RobotKeywords” table: (see Figure-15)
Figure-15
The “RobotKeywords” table is used to discern the robot response category. The
“KeywordID” is used to specify the different keyword in its unique ID, the
“KeywordContent” column is used to give the response to the user in different case and
the “CategoryID” column is used to specify the content in different case based on the
“RobotCategories” table.
“RobotResponse” table: (see Figure-16)

Figure-16
The “RobotResponse” table is used to given the robot response depending on the request
category. The “ResponseID” is used to specify the different response in its unique ID,
the “CategoryID” column is used to give the response to the user into different case and
the “Response content” column is used to give the response content.
“Weather” table: (see Figure-17)

Figure-17
The “Weather” table is used to discern the robot response category. The
“KeywordCategory” is used to define the category of this content, the “TimeID” column
is used to give the unique number to each “Time” content and the “Time” column is
used to specify the time content.
INTELLIGENT VOICE ASSISTANT
26
“Weatherlocation” table: (see Figure-18)

Figure-18
• Detailed solutions and implementation for each function depend on the request categories.
0. Chat Mode: The program will get the captured text and send it to the cloud web
service, the cloud will loop over the robot chat keywords and identify the
keyword category; the response will be randomly accessed through the response
pool according to the keyword category, finally the program init the TextToSpeech
engine from the Android system and generate the audio output with the response.
[Code-0-1]
1. Chat Mode Switcher: the program will have a Boolean variable initiated to false.
If the chat mode is enabled, the variable will be assigned as true and anything
captured will be in the chat mode until the chat mode is finished. While the chat
mode is exited, it gets back to the normal mode and analyzes the requested
commands. [Code-1-1]
2. Location Service: The program will firstly distinguish the command in two
different ways; one is to find the current location, another one is find the routes
between the current location and the destination location. To find the current
location, the program will check the location information from the device GPS
Module and get the current Longitude and Latitude values, then start the
MapActivity by assign the pair values and the mode “current”, present the maps
for the user. To find the route to a specific destination, the program will also
check the current location and get the GEO values, generate the target location
name to an URL, read the GEO Information from the link [Code-2-1], with the GEO
info for both the origination and destination, the program will start the
MapActivity by assign the current location geo value and the remote location geo
value with mode “Remote”. The map activity will generate that information to an
URL and send to the Google map server, then get the route XML. And draw the
route on the map.
3. Weather: the program will firstly check the command whether it has the specific
city name, if the city name is obtained in the command, the program will send the
city name to the Google map server and get the corresponding geo information
with the longitude and latitude and set as a location to get the weather condition; 
INTELLIGENT VOICE ASSISTANT
27
otherwise the location will be the current location information from the mobile
GPS Module, if no city name is given, the program will generate an URL by the
location’s geo info, and get the corresponding weather condition XML from the
Google weather Server. The program will also check the data info from the cloud
response, if the user requires the weather for today, the program will present the
first weather condition from the XML, otherwise, it will get the next four days
conditions.[Code-3-1]
4. Wikipedia search: the program will replace the space in the search content to “+”
and formalize the searching URL, and then switch to the search activity by calling
ACTION_VIEW and give back the result as navigate to the previous obtained URL.
[Code-4-1]
5. Calling service: the program will extract the name section from the response
accessed from the cloud web service, then check through the contact list and get
all the stored contacts [Code-5-1], further fetch all the details of the person with
name, email, phone number [Code-5-2]. Identifying the person and get the first
phone number, and the system will make the phone call by calling the system
ACTION_CALL intent and start the calling activity. [Code-5-3]
6. SMS: the program will extract the name section and the message content from the
response accessed from the cloud web service, then check through the contact list
and get all the stored contacts [Code-5-1], further fetch all the details of the
person with name, email, phone number [Code-5-2]. Identifying the person and
get the first phone number, and the system will send the message by calling the
system ACTION_SENDTO intent and start the sending message activity. [Code-6-1]
7. Email: the program will extract the name section and the email content from the
response obtained from the cloud web service, then check through the contact list
and get all the stored contacts [Code-51], further fetch all the details of the person
with name, email, phone number [Code-52]. Identifying the person and get the
first email address, and the system will send the email by calling the system
ACTION_SEND intent and start the sending email activity. [Code-7-1]
8. Google Search: the program will replace the space in the search content to “+”
and formalize the searching URL, and then switch to the search activity by calling
ACTION_VIEW and give back the result as navigate to the previously obtained URL.
[Code-8-1]
9. Alarm: the program will extract the Hour and Minute parts from the response
obtained from the cloud web service, set a calendar with the requested time of
hour, minute and second. Then start the Alarm manager by calling the system 
INTELLIGENT VOICE ASSISTANT
28
ALARM_SERVICE with the settled calendar and broadcast. In addition, the broadcast
is a trigger to activated an alert and the alarm music will by played when the
alarm is activated by system action RTC_WAKEUP. [Code-9-1]
10. Music Player: When the program is loaded and initialized, it will call the system
ACTION_MEDIA_SCANNER_FINISHED to scan all the media files on the SD card
memory and save the file’s path, id, title, and put all these attributes into a
list[Code-10-1], the program will first extract the action command from the
response obtained from the cloud web service, if the command requires to playing
music, it will further check whether the response contain with the song’s name or
not, if the request does not have a specified name of the song, the program will
randomly pick a song from the list and start the music play service by given the
path of the requested song, otherwise, the song’s path will be obtained from the
list by the song’s name and start the music with start command[Code-10-2]. If the
response contains the pause command, the program will set the music service at a
pause state. As it is the same with pause, the stop command also will be sent in
this way and the music player will stop playing the music. [Code-10-3].
11. Event handler, the program will firstly extract the command part to decide if the
user wants to add or view or delete events. The event program will navigate to the
event activity with the requested command. The layout of the event activity is
designed through the XML file and different operations “Add/View/Delete” are
set on the interface. By extending SQLiteOpenHelper and SQLiteDatabase, the
events can be stored, and updated or deleted.
12. Camera: when the program receives the start camera command, it will start the
Camera activity, then init the Speech Recognizer on that activity. After the user
take photo by recognize the “Cheese” command and save the image into the SD
card memory, a broadcast will be triggered to notify the system’s gallery to
refresh the photos. After the photo has been taken and stored, the camera activity
is finished and give the image path back to main activity, and the main activity
will present the image to the user based on the image path from the given path,
the user also can touch on the preview image to view the image detail by start the
ImageViewActivity.
13. Help: the program will navigate from the current activity to the help activity while
the help menu is activated from the main option menu or by the detected
command. The help activity contains a list of items correspond to each different
function; they share the same outline with an icon, text explanation [Figure 13]. If
any image button is clicked, it will switch to the help content activity with the
corresponding name of the function. By getting the name of the function, the
content activity will fill its content with the icon, title, and the examples to tell 
INTELLIGENT VOICE ASSISTANT
29
how to work with the function. The layout of the activity mainly been constructed
with the TextView, ImageView, and ListView. [Code-13]
14. Translate: the program will get the target language code and the content text, then
generate the original language code, target language code and the content text to a
URL; start the URL and get the translate result from Bing, finally present the
result with the original text and the translated text for user.[Code-14]
15. Bluetooth headset support: when the user plug-in the Bluetooth headset the
system will send a broadcast to the program, the program will use a Bluetooth
receiver to receive this broadcast then enable the button for user to select if use
the Bluetooth or not.
INTELLIGENT VOICE ASSISTANT
30
3.2 Equipment/ Choice of Materials
This chapter indicates all the equipments of the hardware, software and developing platforms.
Apart from the equipments, the materials that used in developing the program are also showed in
API and reference.
Develop tools and environment: Java ™, JDK, Eclipse IDE, Android SDK, ADT Plugin, ADV,
and Plug-in for Eclipse, MySQL query browser, DB-Designer, Microsoft Visual Web Developer
2010 Express and Windows Azure Cloud Platform.
API and reference: Java API, Android API, Google API (Google Map, Google Weather),
Wikipedia API, SQL tutorial, UML reference, JSON, XML, WSDL, Cloud computing, multithreading techniques.
Software application on Android phone: Android Internet explorer, Google voice recognize, TTS
Service Extended, Alarm, Mobile phone calling services, text message serivces.
Support application: Adobe Photoshop CS5, StarUML, Meitu (Chinese).
Hardware support: Android phone [HTC/Samsung], PC, Bluetooth Headset.
Developing model: XP (Extreme programming) (specify model)
- Requirement Card (Requirement analysis and identification)
- Design Card (Implementation and construction of modules)
- Test Card (Black & White Box test on modules)
- Pair-programming (Code modification, optimization and Communication)
- Integration and Simplicity (Integrated modules)
- High-Level Test (Black & White Box test on system)
- System debug (Potential errors and possible bugs)
- Build Product & Revision control (Evaluation and developing history)
- Calculate velocity and efficiency
INTELLIGENT VOICE ASSISTANT
31
3.3 Problems and Solutions
During development (see Figure-6) we have encountered many problems while implementing
those functions. Selected core problems with their solutions are listed by the following section:
• Chat Mode VS Command Mode: When the user wants to chat with the robot, the program
will not distinguish the keyword in the statements, because the chat is random and every
sentence have higher possibility to contain a keyword that Mapping to a command, that will
cause the program confuse about the words and may give a false response.
Solution: The program has been designed in two modes: Chat Mode and Command Mode.
Both modes has different databases(explain), if the user want to chat with the robot, he or she
can say ”Chat mode enable” or “Let us chat” , that will lead the program enter the chat mode.
After entering the chat mode, every statement will be a chat request and a response will be
given until the user says “finish chat” or “end chat”. During the chat mode, the program will
give chat response for the command statements like “weather today” or “where am I”
instead of giving response to the weather/location functions, that will be much easier for the
program to distinguish the keywords.
• Location: there have been problems in getting the GEO info according to the given city name
when implementing the location service. Except getting the current location where the user is,
there should also be allowed to get the location by a city name. The direction must be
precisely given from the current location to the destination according to the given name.
Google Map Service is the solution to get the GEO info based on the city name. By
implementing the Google Map Service which is a free API, the GEO info and the route trace
from the current location to the destination can be accessed and clearly presented on the map.
• Weather data retrieving: When trying to design the keyword functions about the weather data
part, it was discovered that in the sentences “tomorrow” and “the day after tomorrow” it was
hard for the program to distinguish the actual data info in the statement. Since the statement
“the day after tomorrow” also contains the word “tomorrow”, the program may only capture
the word “tomorrow” and skip “the day after”. To solve this problem, the weather condition
will display the next 4 days’ weather in to an entity. When the program captures the word
“today”, it will only show the current weather condition, otherwise, the program will show
the forecast for next 4 days in an entity for all the other cases.
• Calling service: There has been a very fundamental problem when implementing the calling
service. The program cannot run properly with the expected function after finishing the
implementation of the coding. And it was always the same runtime problem when it was
tested and it was modified lots of times without any solutions.
INTELLIGENT VOICE ASSISTANT
32
The solution is found after the CONCAT explorer is opened, and developers can access each
entity of the running message and identify the problem. There has been found no calling
permission is allowed in this program and that is reason why the program gets crash while
trying to revoke the calling service. Access the manifest.xml file of the program and add
calling permission, then the program works as expected and calling service can be
successfully made.
• Alarm: The alarm was firstly implemented with a broadcast which will be trigged when the
time comes up, but after a carefully concern on the user-friendly design, the broadcast should
also have a alert as well to stop the alarm music which is implemented on other class [main
activity – since the system music player must be implemented in the activity which the
broadcast is not an activity] rather than the broadcast. Therefore, the problem was how to
trigger an event in another class.
Different solution has been tried as define the music player a static/ final static object which
can be directly fetched from the other classes, define methods as to get and set the different
variables between classes, and etc; all those solutions failed because the mismatch between
two classes, hence, the object might be null while they were sent to another class which
generated NULLPOINTEXCEPTION. The final solution which solved this problem was
using message handler. Send the message handler info to stop the alarm while the time is up
and the message handler will trigger the alert and actually stop the music.
• Music player: there have been problems of how to get the get, load and update the list of
music when doing the music player. Since the user might update the list of the music any
time as he/ she wants, the program should load the song list with updated info.
The solution is to implement a broadcast, while loading the list of the songs every time the
program is started, the broadcast will inform the broadcast receiver to scan and filter the
mobile phone SD card, then access all the music available and store with the info of each
song into a list for later use.
• Camera: The Android mobile may have the two cameras: front camera and the back camera.
The front camera is always used for self-shooting or video chat, this camera does not have
the autofocus function and that it is a low-definition device, the back camera always use for
shooting the landscapes, or Portraits. The program needs to be designed to have a function
for the use choose to switch the cameras. For this function required, the program has to use
the API in Android library but the front camera method only implement since API 10
(Android 2.3), and the program has build on API 8 (Android 2.2), in that API, the switch
camera method cannot be implement since we use API 8, so we decide to update the whole
program on API 10 to solve this problem.
INTELLIGENT VOICE ASSISTANT
33
Another part of the camera is about the voice record. At the beginning, this function was
designed to take a long range self-shooting, during the camera listening mode, it can
automatically record the speech about every3-5 seconds and then distinguish the statement
whether contain the keywords, after the word has been captured, the camera will
automatically capture the photo or do anther listening to the user. But during the testing, the
voice recognizer was not be able to enable the microphone to start a new listening after the
first recognition, so a button has been put on the screen to let the user to start a new listening
by pushing the button on the screen manually instead of automatically start a new listening
after each time.
After the photo has been taken, the photo will be saved into the SD-card memory, but the
Android’s system will not automatically update the photos into the galley. The system’s
galley only refreshes its source when the system starts. So there have to design a method to
broadcast a message to notify the system gallery to refresh its library on the SD-card when
the photo has been captured.
• Owning no equipment: it has been a long time problem for the development since having no
Android phone. Even the program can be write in Eclipse and test with the emulator, the
physical phone is needed for real-time test on the real phone; having no mobile phone, the
voice recognition cannot be test and there can only be text input manually if the program
need to be test. In addition, the school provided a Sony Ericsson phone with Android
operating system, but that phone was too old with a 2.0 Version which cannot implement this
program.
Thanks to WANG LINLIN who lends her HTC to the developers and the program was well
finished and test on the real phone. The mobile phone will be available to use until the
program is fully finished.
INTELLIGENT VOICE ASSISTANT
34
4 Results
4.1 Design
Figure-19
The Model and Flow Chart (see Figure-19) describes the develop process that include all the phases
in the software development life cycle. This chart is well illustrating how the project is carried out
and how the development was managed. The project started with the motivation and brain storm,
repeatedly implement in the developing life cycle until the system has been fully constructed.
- Brain storm, the project start with the ideas from the brain storm. Here the basic ideas and
design the primary concepts, prototype of the program have been obtained.
- While the ideas has been obtained, it has been analyzed which of them can be accomplished
and make sure the structure of the project.
- According to the requirements that had been identified, collected all the resources and useful
references from any channel, together with the programming skills and experiences, the
design items were pointed out.
- Implement each individual design item based on the planning, structure and references.
- Test each single module that has been implemented and fix the possible bugs appear in the
code implementation and make sure the functions are well constructed.
- Integrate all the individual sections to contribute to a complete system.
- Try the black and white box testing strategies to test the system, both the functional and nonfunctional logic and implementation should be verified.
INTELLIGENT VOICE ASSISTANT
35
- Debug the system and optimize the project from the possible aspects.
- Build the product and pack all the stuffs as a whole.
INTELLIGENT VOICE ASSISTANT
36
4.2 Functioning
The program should firstly be started on the Android phone; the initial mode of the program is Voice
mode since this program aims at making a voice assistant program. However, if there are users who
prefer to operate in text mode by inputting the text manually, the text mode is also available.
After the program has been started, the user should have correct voice input “command/request” to make
those functions work properly. And this program includes the functions and services of: calling services,
text message transformation, mail exchange, alarm, event handler, location services, music player
service, checking weather, Google searching engine, Wikipedia searching engine, robot chat, camera,
Bing translator, Bluetooth headset support, help menu. The details below explain how those functions
work and different possibilities while facing different commands.
 Calling service, the calling function allows the users to give a call to the person in the contacts.
By giving a correct command with the calling request to a stored person, the Android phone will
check the contact list and get the phone number of the person, then successfully direct to the
phone number found in the contacts.
 Text Message transformation, the text message transformation enable customers able to send the
SMS to the person in the contacts. By giving a correct command contains the request keyword to
send SMS together with the destination person; the program will navigate to the sending message
function on the mobile phone with the phone number, message content. The message will be sent
to the destination immediately if the user selects to send it with the correct content.
 Mail exchange, customers are able to send the mail to the person with mail address in the
contacts. By giving a correct command contains the mail request keyword together with the
destination person; the program will switch to the sending mail function on the mobile phone
with the mail address and mail content. If the content is correctly detected, the mail will be
received by the recipient after the user selects to send the mail, otherwise the user can modify the
mail content if the voice recognition is not well detect the mail content.
 Alarm, as a basic function on the mobile phone, the user could simply set the alarm through the
command with the setting alarm keyword and a specific valid time. When the alarm request and
time are detected, the program will set the alarm to the given time with dedicated hour, minute
and second; when the time comes up, the alarm will be trigged with a alarm bell and an alert
notification which the user can choose to stop the alarm, otherwise the alarm will keep working
and the song will always be playing.
 Event handler, the application allows the user to set as many events as they want. Customers set
the events with the content and title, the program switch to the event handler interface with the
content and the title, and the event will be stored immediately if the user ensure the event. With 
INTELLIGENT VOICE ASSISTANT
37
the stored events, the event handler makes the events available for the user to check all events,
check one event, modify the selected event and delete all events.
 Location services, location services works in two categories depending on the request.
If it has been required to present the current location of the user, the location services check the
GEO info by using the Google Map Service and give back the result as a map with the current
location.
If it has been required to provide the route trace from the current position to a specific city, the
location service check the GEO info of both the origination and the destination, and provides the
direction on the map with a route indicating how to get to the destination from the origination.
 Music player service, the music player offers the services to the user to play a named or random
song in the pre-stored song list depending on the request.
The music player service will play the specific song according to the name given by the user, the
music player check the music list and identify the song, then presenting to the user.
The music player service will play a randomly picked song through the list if the user doesn’t
provide the song that he or she wants. The music player traces through the music list and get one
from it for playing to the user.
The music player could be also be stopped or paused while it is playing a song. By giving the
correct commands, the working music player will be paused or stop playing.
 Checking weather, weather service provides the user the weather condition in different city on
different dates. This service works in the same logic and gives back different result depending
on the requested date and city.
The weather service return the current date weather condition of the current location with the
humidity, wind speed, temperature scope and display in a formalized entity which can be easily
read by the user if the local weather for current date weather is required.
The weather service return the next four days' weather condition of the current location with the
date, wind speed, temperature scope and display in a formalized entity which can be easily read
by the user if local weather for other dates except today’s weather is required.
The weather service return the current date weather condition of the given city with the humidity,
wind speed, temperature scope and display in a formalized entity which can be easily read by the
user if weather for current date weather for the given city is required.
The weather service return the next four days’ weather condition of the given city with the date,
wind speed, temperature scope and display in a formalized entity which can be easily read by the
user if weather for next for days of the given city is required.
INTELLIGENT VOICE ASSISTANT
38
 Google searching engine, the search engine enable the use to search anything on Google. By
detecting the search keyword and search request, the Google search engine will returns the result
list displayed on the browser on the mobile phone.
 Wikipedia searching engine, the search engine enable the use to search anything on Wikipedia.
By detecting the search keyword and search request, the Wikipedia search engine will returns the
Wikipedia result displayed on the browser on the mobile phone.
 Robot chat, the robot chat enables the user to chat with the Android phone to have fun. The chat
mode is initially closed and will be required to activate it with the corresponding command.
After entering the chat mode, a text response will given by the mobile phone whenever the user
speaks to it; the response, however, were predefined and stored in the database. For each request,
the program will define the request category and randomly pick a response from the response
pool depending on the request category.
 Camera, the camera function enables the user to capture the current view with the camera on the
mobile phone. When the camera is activated by the user, the user can selects to use the front or
back camera on the mobile phone manually, and the picture will be taken by the camera if the
user selects to photograph the current view, an instant picture for previously taken will be
displayed in the program for viewing as a entity, and the picture will be stored in the Gallery for
later checking.
 Bing translator, the translator will provide the user both the original text and the translated text
depending on the objective language the user given. The user gives the original text and the
object language the he wants; then the translator will give the result back of a translated text
based on the original text and required language. Meanwhile, there have been 25 object
languages stored in the database which the user can enjoy and the original text should be in
English to use the translate function.
 Bluetooth headset support, the Bluetooth headset support makes the program well work
especially the phone is playing music or the surrounding is noise which affect the voice
recognition. Since it is not possible to do the voice recognition while the music player is playing,
the Bluetooth will be loaded and available to the user, the user can select to turn on or turn off
the Bluetooth function, and the Bluetooth headset support makes it possible to speak to the
headset rather than the mobile phone if the Bluetooth is enabled.
 Help menu, the help menu provides the user a help list to each function in this program. The user
can choose the help menu manually or over the voice if the user doesn’t know how to work with
the functions. While the help menu is opened, the help menu gives the examples and explanation
of how to work with different functions, the examples clearly show how to work with the
function and the user can simply imitate the example to work with different functions. 
INTELLIGENT VOICE ASSISTANT
39
4.3 Operation and Maintenance
Operation
 Calling Service: If the user wants to consume the calling service, he or she must have a
command contains a valid name the calling keyword like “call”, ”make a phone”, then the call
will be made if the person is found in the contacts. There are different ways to make a phone call,
the list below shows the correct command to use the calling service.
“Call Tom”, make a phone call to tom. The program will first capture the key words “call”, and
then the program will continue to capture the person’s name “Tom” after the word “call”, then
get all the contacts on the mobile and compare them one by one, if “Tom” is equal to the name
that the user is give in the command, the phone call will be made to “Tom”.
“I want to give a call to Lucy”, make a phone call to Lucy. The program will capture the
command keyword “call” and the name “Lucy” and make a phone call to Lucy.
 Text Message Transfer: If the user wants to use the application to send the text message, he or
she must have a command with the SMS message keyword and a valid name, then the message
will be send if the person is found in the contacts. They are different forms to send the message;
the list below shows the correct command can do the message sending.
“Send a message to LiLei Let's dinner together”, send a message to LiLei with the content “Let’s
dinner together”, the program will capture the keyword “message” and the content “let’s dinner
together”, then the program will check the mobile contacts and get the first phone number
corresponding to “LiLei” and send the message to LiLei.
“SMS Hui Nihao”, send a message to Hui with the content “Nihao”.
 Mail exchange: The user can send an email to the person in his contacts and with person’s email
address. He or she must have a command with the email keyword like “Mail”, “Post” and a valid
name; the email will be send if the person is found in the contacts. They are different forms to
send the message; the list below shows the correct command can do the email sending.
“Mail Bellis it will rain today”, send an email to Bellis the content “it will rain today”, the
program will capture the keyword “Mail” and the content “it will rain today”, and then the
program will check the mobile contacts and get the email address corresponding to “Bellis” and
send the message to “Bellis”.
“Post Mimy a boy is waiting for you” send an email to “Mimy” with the content “a boy is
waiting for you”
INTELLIGENT VOICE ASSISTANT
40
 Alarm: The user can use the set alarm command to set an alarm at the corresponding time. When
the time is up, the alarm will be activated and play the sound; meanwhile, an alert will be
presented for the user to stop the alarm.
“"Set alarm to 10” the alarm will be set at 10 o’clock. The program will capture the setting
command “Set alarm” and get the time command “10” and then the alarm will be active at
10AM.
“Make time to 11:50” the alarm will be set at 11:50. The program will capture the command
“Make time” and the time “11:50”, the alarm will be wake up at 11:50.
 Event handler: The application can allow the user set many events. He or she can set many
events and be saved into the application’s database by using the add event command, also he or
she can view the event or delete the event by corresponding keywords like “Set up”, “make up”,
“View one/all event(s)”, “Delete”. The list below shows the correct command can do the
operation.
 Add Event:
“Set up a meeting at 10”, the Program will first capture the keyword “set up” then the title of the
event “a meeting” and the content “a meeting at 10”, then the event activity will be start with the
add event dialog, automatically fill with the title “a meeting” and content “a meeting at 10”.
Then the user should to choose the date time and add the event.
 View Event(s)
“View all/one event(s)” / “Find event”, the Program will start the event activity and present the
event(s) based on the user choose to show the all events or one event. If the user chooses to show
one event, the data picker will be shows up and the user can choose the event that he or she
wants to present based on the date, otherwise, the application will show up all the events if the
user wants to check all.
Delete Events
“Delete all events”, the Program will delete all the events that in the application’s database.
 Location services: The user can use this service to locate the user’s position or get the routes to
the destination by giving the city name. There are different ways to locate the position or
navigate to a specific city. The use must use the keywords “where” and “I” or “my location” to
let the application to know he or she wants to locate the current position. And the keywords “go
to” and the name of the place to get the route to the destination.
INTELLIGENT VOICE ASSISTANT
41
Locate position
“Where am I” / “Show my current location”, the program will present the current location of the
user on the map.
Navigation
“How can I go to Lund” / “Navigation to Lund”, the program will present the routes to “Lund”
on the map with the highlighted route from the current location to Lund.
 Music player service, the user can use this application to play songs, his or her command must
contain keyword “play”. If the user wants to play the specific song, he or she should also say the
name of the song after “play”, and the song should be exist in the SD-card memory. Or if the
user wants to play a random song, he or she just needs to say “a song” instead of the song’s name.
During the playing, the user can pause or stop the song by giving the command “pause” or “stop”.
 Play
“Play Canon”, the program will play the song “Canon”
“Play a song for me”, the program will randomly pick a song from the library and play it.
 Pause
“Pause playing music”, the song will be paused immediately.
 Stop
“Stop music player”, the song will be stopped immediately.
 Checking weather: the user can use the application to check the weather for recent days in local
place or specific location. He or she should say the keyword “weather”, then the user should
notify the date that should be presented as “today/tomorrow/the day after tomorrow” if he or she
wants to get the information about the other days otherwise the application will default set the
date as today, and the user can also can choose to tell about the place name “in Malmo”, the
application will check the weather belong to that place, otherwise the place will be set as locally.
 Weather check today:
“What's the weather for today”, the current weather condition for local place will be show.
“What's the weather in Malmo”, the current weather condition for Malmo will be show.
 Weather check other days:
“What's the weather next few days”, the forecast in next 4 days will be show. 
INTELLIGENT VOICE ASSISTANT
42
“What's the weather next few days in Malmo”, the forecast for Malmo in next 4 days will be
show.
 Google searching engine, the Google search engine is activated by the user commands which
contain ‘Google’ or ‘Search’. By detecting the search keyword and search request, the Google
search engine will returns the search result displayed on the browser on the mobile phone.
“Google China”, the keyword ‘Google’ is detected and the result will be presented on the web
browser by searching ‘China’ on Google.
“Try to Google Java API”, the user can have the keyword Google in the middle of a request and
the result of searching ‘Java API’ on Google will be displayed on the web browser.
“Search for apple”, the user can also use the keyword ‘search’ to do the Google search, this
command will have the result of searching ‘apple’ on Google.
 Wikipedia searching engine, whenever the user wants to search any content in Wikipedia, it is
possible to do in this program by having a command contain the keyword ‘define’. If ‘define’ is
detected by the program, the program will automatically give the result by search the content
after ‘define’ in Wikipedia.
“Define Android”, the keyword ‘define’ is detected, and the program will return the result by
searching ‘Android’ on Wikipedia.
“Define true love”, the keyword ‘define’ is detected, and the program will return the result by
search the content after ‘define’, which is ‘true love’ on Wikipedia.
 Robot chat, the robot chat will work only after the chat mode is enabled which can be done with
a command that contains keyword ‘chat’. After the chat mode is enabled, a response will be
given every time when the user gives a request. The chat can be finished by the user commands
contain the keywords of ‘finish/ disable/ end/ complete chat’.
“Enable chat”, the keyword ‘chat’ will be detected and the chat mode will be enabled. Now the
user can enjoy the chat by inputting any text he /she wants.
“Let’s chat”, the keyword ‘chat’ will be detected and the chat mode will be enabled. Now the
user can enjoy the chat by inputting any text he /she wants.
“Finish chat”, the keyword ‘finish chat’ is detected and the chat mode will be disabled. When
the user exits the chat mode, the program gets back the normal mode to receive and analyze the
commands, and give correct response.
INTELLIGENT VOICE ASSISTANT
43
 Camera, the camera is started while the keyword ‘camera’ is detected. Therefore, the user who
wants to operate with the camera will have to give a command with camera inside. After camera
is started by the correct command, the camera itself will guide the user how to take photograph.
“Open the camera”, as the keyword ‘camera’ is detected, the camera is started. And the user can
work with the camera by clicking the different selection on the mobile phone.
“Start the camera”, as the keyword ‘camera’ is detected, the camera is started. And the user can
work with the camera by clicking the different selection on the mobile phone.
“I want to use the camera”, as the keyword ‘camera’ is detected, the camera is started. And the
user can work with the camera by clicking the different selection on the mobile phone.
 Bing translator, the user should have the keyword ‘translate’ / ‘how to say’ as the keywords to
define this is a translate request, and ‘in’ as keyword to indicate the objective language. As the
user have the command contains these keywords, the translator will return the result with the text
in the objective language.
“Translate I love you in Chinese”, as ‘translate’ and ‘in’ are detected by the program, the
program will call the translator with ‘I love you’ as the original text and Chinese as the objective
language, the result will be the Chinese words of ‘I love you’.
“How to say hello in Swedish”, as ‘how to say’ and ‘in’ are detected by the program, the
program will activate the translator with ‘hello’ as the original text and Swedish as the objective
language, the result will be the Swedish text of ‘hello’.
 Bluetooth headset support, the Bluetooth headset support will be enabled when the program is
loaded. The user should firstly turn on the Bluetooth in the setting of the mobile phone, and the
Bluetooth icon will be valid in the program after executing the program. The user will be
required to plug in the Bluetooth headset and turn on /off it manually by clicking on the
Bluetooth icon.
 Help menu, the help menu can be activated by manually select on the option menu or through the
command. The commands should have ‘help’ as the keyword contained, then the help menu will
be activated and the help menu provides the list of all functions with their explanation and
examples to use it.
“I want to check the help menu”, if the users have the keyword ‘help’ contained in the command,
it will be detected as a keyword and the help menu will be returned with a list of the functions,
the functions are presented in two pages and user can scroll the pages by slipping the touch pad
of the mobile phone; by selecting on each of the functions, the user can enjoy the details of the
explanation and the examples of each function. 
INTELLIGENT VOICE ASSISTANT
44
Maintenance
After the program is completed, the program still needs long term maintenance to make it
available and stable to execute. The program will be test after a certain period of time and debug
each of the function and possible bugs, whenever a potential bug is detected; the program needs
to be refined to a better design. Meanwhile, there will update and add more data to the database
to increase the database capacity. Depending on the new keywords, responses, relevant data
found that could be applied in this program; the database will always be improved and can
handle more and more cases.
INTELLIGENT VOICE ASSISTANT
45
5 Conclusions
- Project development and implementation
As it has been previous stated, the program is mainly concerns with the techniques of Android
development, Java programming, Database management, Cloud computing, different APIs for
Google products, Bing translate and etc. The program is developed by two developers and
follows the extreme programming model. During the eight weeks development, the developers
did the same cycle in each phase of analyze requirements, construct design, implement the
solutions in pair programming mode and test the result. The development is carried out as its
primary planning which guide the work process of how to work with the program, how much
time should the each of the developers spent in every week, the rescores needed for developing
and how to handle the problems while it came up. The project was efficiently completed under
the development model and the resources we found in early time were really useful when
implementing the program.
- Project usage & prospect, potential
The project is very useful and owns a large potential use in different industries. Although the
program primary concerns more about how to do the personal assistant on Android phone using
the voice, the concept of voice recognition can be applied in different industries as in many
situations it will be more convenient, save a lot of time and helpful especially for those who have
difficulty in working with manual operations. Thus, the concept is only for programming the
Android application.
For the program itself, it is a collection of 15 functions that are frequently used on a mobile
phone. The user can enjoy different services within this platform. Therefore, it is easy to use with
simple operation compared with the traditional working strategies which the user should well
know how to work with the mobile phone.
In addition, the program which works using the voice is helpful for those who prefer voice
operation and those who have difficulty /disability with the manual operations. The primary
objective of the program is to provide services using the voice, and it enables more people who
can enjoy this program.
The prospect of the program can be more applications or products developed using the voice
control, and it could in some sense change the working forms that is totally different from the
traditional form. As people can easily operate and have a lot of fun from it, it owns an
enlightened prospect as SIRI succeed in attracting people in the market.
INTELLIGENT VOICE ASSISTANT
46
INTELLIGENT VOICE ASSISTANT
47
- Project experience & teamwork
Apart from the program, we as the developers have improved a lot from the degree project. It is
quite different from what we previously experienced in the working model, volume of tasks, and
the problems we have encountered. In conclusion, we have been improved a lot from the project
development, and gained development experience as well as programming skills; the most
important is work as a team for a long term, challenge development.
INTELLIGENT VOICE ASSISTANT
48
6 Recommendations for Further Work
6.1 Design Improvements
No program has a perfect design without any flaws; it is the same here in this program. Even
though the program is completed with all the primary functions implemented and work properly,
there are still many things that can be done with this program. As the future improvement, the
potential work that can be implemented ranging from adding more functions to offering the user
a more comprehensive, convenient program, refining the logic to make the program more
humanized and easy to use, increase the database capacity and add more possible keywords,
responses and data in this program, interface optimization and etc.
6.2 Additional Functions
Add more functions: although there have been 15 normal functions that are used really often
with the mobile phone, there can be more functions which simplify our daily life and make it
convenient to use. Functions as playing movies, checking stocks, exchange rate, downloading
and uploading, installing APPs and etc, these can be the potential functions that make the
program more comprehensive and people can enjoy more services in this program.
6.3 Database Capacity
Add database capacity and more humanized logical design; the program has a predefined logic to
make it work with the corresponding commands. Thus, the user need to follow the structure of
the commands, contain the dedicated keywords and well formalize the commands to work with
each of the functions. In other words, the program is limited by the database capacity and no
solution will be found if the user gives commands that are not readable by the program. Even if
two commands have the same meaning and should get exactly same result set, the result might
be that of one is working and the other one fails. Hence, the program is to some extent limited by
the vocabulary and can be further optimized. 
INTELLIGENT VOICE ASSISTANT
49
6.4 Humanized Voice Recognition
The more humanized the program is, more easier the user can use it. People should accept that
even if developers constantly try to add more predefined commands, more responses to it,
analyze and respond to the command more intelligently, the program will never be completely
comprehensive and contain all the possible circumstances that the users meets. Nevertheless, the
program will certainly be improved and be more user-friendly if there can be more readable
commands, more humanized structure and more intelligent response.
6.5 Improved Interface
Interface optimization, the interface can be further improved to make it nice to the users.
Currently the interface design meets the basic requirement to present everything for this program,
and the users are able to interact with the program through this interface, but the interface can
always be optimized and more suitable constructed.
INTELLIGENT VOICE ASSISTANT
50
7 References
7.1 List of References
 [1] http://en.wikipedia.org/wiki/Siri_(software)
 [2] http://en.wikipedia.org/wiki/Smartphone
 [3] http://yudian.voicecloud.cn/
 [4] http://en.wikipedia.org/wiki/Extreme_programming
 [5] http://en.wikipedia.org/wiki/Cloud_computing
 [6] http://en.wikipedia.org/wiki/Extreme_programming
 [7] http://en.wikipedia.org/wiki/Java_programming
 [8] http://docs.oracle.com/javase/6/docs/api/
 [9] http://developer.Android.com/index.html
 [10] http://developer.Android.com/reference/packages.html
 [11] http://developer.Android.com/guide/index.html
 [12] http://www.microsoft.com/sqlserver/en/us/product-info/overview-capabilities.aspx
 [13] http://www.mysql.com/why-mysql/
 [14] http://www.windowsazure.com/en-us/home/features/sql-azure/
 [15] https://www.windowsazure.com/en-us/develop/net/fundamentals/intro-to-windowsazure/#cloud
 [16] http://en.wikipedia.org/wiki/Web_Services_Description_Language
INTELLIGENT VOICE ASSISTANT
51
8 Appendix A Figure
Request Request
category Response Response code
Chat
0
Chat “0|1|Content”
Disable “0|0”
1
Enable “1|1”
Disable “1|0”
Location Service 2
Location “2|1”
Direction “2|2|Destination City Name”
Weather 3
Local & today “3|1|0”
Local & other day “3|2|0”
Remote & today “3|1|1|City Name”
Remote & other day “3|2|1|City Name”
Wikipedia 4 Definition “4|Content”
Calling Service 5 Make phone call “5|Receiver’s name”
SMS 6 Send message “6|Receiver’s name| Content”
Email 7 Send email “7|Receiver’s name| Content”
Google 8 Search engine “8|Content”
Alarm 9 Set alarm “9|Hour|Minute”
Music player 10
Start & Random Song “10|1|000”
Start & Given Song “10|1|Song name”
Pause “10|2”
Stop “10|3”
INTELLIGENT VOICE ASSISTANT
52
Event 11
Add an event “11|1|title|Content”
View one event “11|2”
View all events “11|3”
Delete all events “11|4”
Camera 12 Start camera “12|1”
Help 13 Help Menu “13|1”
Translate 14 Translate content “14| target language code|
Content”
Table-2
INTELLIGENT VOICE ASSISTANT
53
9 Appendix B Code
Code-0-1
case 0:
int state = Integer.parseInt(getSecondInfo(response));
switch (state) {
case 1:
chat = true;
persendInfo("he", getThirdInfo(response));
break;
case 0:
chat = false;
persendInfo("he", DefaultResponse.getChatFinishSpeak());
break;
}
break;
Code-1-1
case 1:// robot
switch (Integer.parseInt(getSecondInfo(response))) {
case 1:
chat = true;
persendInfo("he", DefaultResponse.getChatSuccessSpeak());
break;
case 0:
chat = false;
persendInfo("he",DefaultResponse.getChatFinishSpeak());
break;
}
break;
Code-2-1
public Geo(String location)
 {
 String url = "http://maps.google.com/maps/geo?q="+location+"&output=csv";
 try
 {
 DefaultHttpClient client = new DefaultHttpClient();
 HttpUriRequest request = new HttpGet(url);
 HttpResponse Response = client.execute(request);
 HttpEntity Entity = Response.getEntity();
 InputStream stream = Entity.getContent();
 DataInputStream ds = new DataInputStream(stream);

 String toLine= ds.readLine();
 String geos[] = toLine.split(",");
 this._latitude = geos[2];
INTELLIGENT VOICE ASSISTANT
54
 this._longtitude = geos[3];
 Log.v("Message", toLine);
 }
 catch (Exception ex)
 {
 System.out.println(ex.toString());
 }
}
Code-3-1
case 3:// weather
if (getThirdInfo(response).equals("0")) {// local
gw = new GoogleWeather(getLatitude(), getLongtitude());
}
if (getThirdInfo(response).equals("1")) {// other place
String cityName = getFourthInfo(response);
geo = new Geo(cityName);
gw = new GoogleWeather(Double.parseDouble(geo
.get_latitude()), Double.parseDouble(geo
.get_longtitude()));
}
switch (Integer.parseInt(getSecondInfo(response))) {
default: // local today weather
persendInfo("he","Here's the forecast for recent days:");
ww = gw.getWeatherWeek();
DetailEntity d2 = ww;
list.add(d2);
break;
case 1: // local weather for recent days
persendInfo("he", "Here's the weather for today:");
dw=gw.getWeatherDetail(String.valueOf(getSecondInfo(response)));
DetailEntity d3 = dw;
list.add(d3);
break;
}
break;
Code-4-1
case 4:// WikiPedia
String wikiWords = getSecondInfo(response);
persendInfo("he", "Searching for wikipedia");
Uri myBlogUri = Uri.parse("http://www.wikipedia.org/searchredirect.php?search="+wikiWords+"&language=en&go=++→ "+ "++&go=Go");
Intent returnwikiIt = new Intent(Intent.ACTION_VIEW, myBlogUri);
startActivity(returnwikiIt);
break;
Code-5-1
INTELLIGENT VOICE ASSISTANT
55
public List<Person> getPerson(Context context)
{
Uri uri=ContactsContract.Data.CONTENT_URI;
Cursor cursor=context.getContentResolver().query(uri, null, null, null,
"display_name");
cursor.moveToFirst();
 List<Person> list=new ArrayList<Person>();
 int Index_CONTACT_ID = cursor.getColumnIndex(ContactsContract.Data.CONTACT_ID);
 int Index_DATA1 = cursor.getColumnIndex(ContactsContract.Data.DATA1);
 int Index_MIMETYPE = cursor.getColumnIndex(ContactsContract.Data.MIMETYPE);
 while(cursor.getCount()>cursor.getPosition())
 {
 Person person = null;
 String id=cursor.getString(Index_CONTACT_ID);
 String info=cursor.getString(Index_DATA1);
 String mimeType=cursor.getString(Index_MIMETYPE);

 for(int n = 0; n<list.size(); n++)
 {
 if(list.get(n).getID() != null)
 {
 if(list.get(n).getID().equals(id))
 {
 person = list.get(n);
 break;
 }
 }
 }
Code-5-2
 if(person == null)
 {
 person=new Person();
 person.setID(id);
 list.add(person);
 }
 if(mimeType.equals("vnd.Android.cursor.item/email_v2"))
 {
 person.setEmail(info);
 }
 else if(mimeType.equals("vnd.Android.cursor.item/postal-address_v2"))
 {
 person.setAddress(info);
 }
 else if(mimeType.equals("vnd.Android.cursor.item/phone_v2"))
 {
 person.addPhone(info);
 }
 else if(mimeType.equals("vnd.Android.cursor.item/name"))
 {
 person.setName(info);
 }
 cursor.moveToNext();
 }
INTELLIGENT VOICE ASSISTANT
56
return list;
}
Code-5-3
case 5:// call
personList = getContacts.getPerson(MainActivity.this);
String callName = getName(response);
if (isNameFound(callName, personList)) {
String tele = getTele(callName, personList);
if (!tele.equals("0")) {
persendInfo("he", "Calling to " + callName + ".");
Intent myIntentDial = new Intent(Intent.ACTION_CALL,
Uri.parse("tel:" + tele));
startActivity(myIntentDial);
} else {
persendInfo("he", "Sorry, no telephone exist!");
}
} else {
persendInfo("he",
"Sorry, no person is found by the given name!");
}
break;
Code-6-1
case 6:// send SMS
String smsName = getSecondInfo(response);
String smsContent = getThirdInfo(response);
if (smsName != null) {
personList = getContacts.getPerson(MainActivity.this);
if (isNameFound(smsName, personList)) {
String tele = getTele(smsName, personList);
if (!tele.equals("0")) {
persendInfo("he", "Sending message to " + smsName);
Log.v("tele", tele);
Intent smsreturnIt = new Intent();
smsreturnIt.setAction(Intent.ACTION_SENDTO);
smsreturnIt.setData(Uri.parse("smsto:" + tele));
smsreturnIt.putExtra("sms_body", smsContent);
startActivity(smsreturnIt)
} else {
persendInfo("he", "Sorry, no telephone exist!");
}
} else {
persendInfo("he","Sorry, no person is found by the given name!");
}
}
break;
INTELLIGENT VOICE ASSISTANT
57
Code-7-1
case 7:// send Email
personList = getContacts.getPerson(MainActivity.this);
String mailReceiver = getSecondInfo(response);
String mailBody = getThirdInfo(response);
if (isNameFound(mailReceiver, personList)) {
String mailAddress = getMailAddress(mailReceiver,personList);
if (!mailAddress.equals("0")) {
persendInfo("he", "Sending email to " + mailReceiver
+ ".");
Intent intent = new Intent(
Android.content.Intent.ACTION_SEND);
intent.setType("plain/text");
intent.putExtra(Android.content.Intent.EXTRA_EMAIL,
mailReceiver);
intent.putExtra(Android.content.Intent.EXTRA_TEXT,
mailBody);
startActivity(Intent.createChooser(intent,
"Choose Email Client"));
} else {
persendInfo("he", "Sorry, no mail box exist!");
}
} else {
persendInfo("he","Sorry, no person is found by the given name!");
}
break;
Code-8-1
case 8:// google search
String googlWords = getSecondInfo(response);
persendInfo("he", "Searching for google.");
Uri searchUri = Uri
.parse("http://www.google.com/search?hl=en&site=&source=hp&q="
+ googlWords + "&oq=" + googlWords);
Intent returnIt = new Intent(Intent.ACTION_VIEW, searchUri);
startActivity(returnIt);
break;
Code-9-1
case 9:
Calendar calendar = Calendar.getInstance();
int hourOfDay = Integer.parseInt(getSecondInfo(response));
int minute = Integer.parseInt(getThirdInfo(response));
calendar.setTimeInMillis(System.currentTimeMillis());
calendar.set(Calendar.HOUR_OF_DAY, hourOfDay);
calendar.set(Calendar.MINUTE, minute);
calendar.set(Calendar.SECOND, 0);
calendar.set(Calendar.MILLISECOND, 0);
Intent intentAlarm = new Intent(MainActivity.this,
AlarmReceiver.class);
PendingIntent pendingIntent = PendingIntent.getBroadcast(
INTELLIGENT VOICE ASSISTANT
58
MainActivity.this, 0, intentAlarm, 0);
AlarmManager am;
am = (AlarmManager) getSystemService(Context.ALARM_SERVICE);
am.set(AlarmManager.RTC_WAKEUP, calendar.getTimeInMillis(),
pendingIntent);
persendInfo("he", "Set up clock at " + hourOfDay + ":" + minute
+ " .");
break;
Code-10-1
}else if(Intent.ACTION_MEDIA_SCANNER_FINISHED.equals(action)){
Cursor c2 = context.getContentResolver()
.query(MediaStore.Audio.Media.EXTERNAL_CONTENT_URI,
new String[]{MediaStore.Audio.Media.TITLE,
MediaStore.Audio.Media.DURATION,
MediaStore.Audio.Media.ARTIST,
MediaStore.Audio.Media._ID,
MediaStore.Audio.Media.DISPLAY_NAME },
null, null, null);
count2 = c2.getCount();
count = count2-count1;
c = context.getContentResolver()
.query(MediaStore.Audio.Media.EXTERNAL_CONTENT_URI,
new String[]{MediaStore.Audio.Media.TITLE,
MediaStore.Audio.Media.DURATION,
MediaStore.Audio.Media.ARTIST,
MediaStore.Audio.Media._ID,
MediaStore.Audio.Media.DISPLAY_NAME,
MediaStore.Audio.Media.DATA},
null, null, null);
 if (c==null || c.getCount()==0){
 System.out.println("No music in the library!");
 }
 c.moveToFirst();
 ids = new int[c.getCount()];
 titles = new String[c.getCount()];
 path = new String[c.getCount()];
 for(int i=0;i<c.getCount();i++){
 ids[i] = c.getInt(3);
 titles[i] = c.getString(0);
 path[i] = c.getString(5).substring(4);
 c.moveToNext();
 }
 isDone= true;
}
INTELLIGENT VOICE ASSISTANT
59
Code-10-2
case 1:// play song
String songName = getThirdInfo(response);
int songIds[] = scanSdReceiver.getIds();
Intent intentMusic = new Intent();
intentMusic.putExtra("_ids", songIds);
int position = 0;
if (!songName.equals("000")) {
position = nameToId(songName,
scanSdReceiver.getTitles(),
scanSdReceiver.getIds());
} else {
Random r = new Random();
position = r.nextInt(songIds.length);
songName = idToName(position,
scanSdReceiver.getTitles());
persendInfo("he",
DefaultResponse.playSongReponse(songName));
}
if (position != -1) {
intentMusic.putExtra("position", position);
intentMusic.putExtra("op", 1);
intentMusic.setAction("com.Android.MusicService");
startService(intentMusic);
persendInfo("he",
"Playing song "+ songName +".");
Log.v("Music", "Play song :" + songName
+ ", position: " + position);
} else {
persendInfo("he",
"Sorry, I can't find the song on your device.");
}
break;
Code-10-3
case 2:
Intent intent1 = new Intent();
intent1.setAction("com.Android.MusicService");
intent1.putExtra("op", 2);
startService(intent1);
Log.v("Music", "pause song");
break;
case 3:
Intent intent2 = new Intent();
intent2.setAction("com.Android.MusicService");
intent2.putExtra("op", 3);
startService(intent2);
Log.v("Music", "Stop song");
break;
INTELLIGENT VOICE ASSISTANT
60
Code-13
case 13:
Intent in = new Intent();
in.setClass(MainActivity.this, HelpActivity.class);
startActivity(in);
break;
Code-14
case 14:
String languagecode = getSecondInfo(response);
String text = getThirdInfo(response);
persendInfo("he", DefaultResponse.getTranslateSuccessSpeak());
Translator ts = new Translator(text,languagecode);
DetailTranslate dt = new
DetailTranslate(languagecode,ts.getTranslateResult(),
text,R.layout.translate);
list.add(dt);
break;

EXTRUDESIGN

HOME
About Us
Subscribe Here!
Site Map
MECHANICAL ENGINEERING
Machine Design
Engineering Calculators
Motor Torque
Section Modulus
Area Calculator
Shaft Diameter
Stiffness Calculator
Inertia Calculator
More
Metrology
Theory of Machines
Material Science
Advanced Composites
CAD/CAE/CAM
PTC CREO
SOLIDWORKS
CATIA V5
Unit Converters
Torque
Power
Force
Energy
Inertia
Area
How to?
Advanced Excel
Latest Apple news
PROJECTS LIBRARY
HOW TO PUBLISH?
Virtual Assistant Using Python
July 18, 2021 by University Student Leave a Comment

A final year project on “Virtual Assistant Using Python” was submitted by Kavya Damarla (from Chalapathi Institute Of Engineering And Technology, Guntur, Andhra Pradesh) to extrudesign.com.

Virtual Assistant Using Python
Abstract
In this modern era, day to day life became smarter and interlinked with technology. We already know some voice assistance like google, Siri. etc. Now in our voice assistance system, it can act as a basic medical prescriber, daily schedule reminder, note writer, calculator and a search tool. This project works on voice input and give output through voice and displays the text on the screen. The main agenda of our voice assistance makes people smart and give instant and computed results. The voice assistance takes the voice input through our microphone (Bluetooth and wired microphone) and it converts our voice into computer understandable language gives the required solutions and answers which are asked by the user. This assistance connects with the world wide web to provide results that the user has questioned. Natural Language Processing algorithm helps computer machines to engage in communication using natural human language in many forms.

I. Introduction
Today the development of artificial intelligence (AI) systems that can organize a natural human-machine interaction (through voice, communication, gestures, facial expressions, etc.) are gaining in popularity. One of the most studied and popular was the direction of interaction, based on the understanding of the machine by the machine of the natural human language. It is no longer a human who learns to communicate with a machine, but a machine learns to communicate with a human, exploring his actions, habits, behaviour and trying to become his personalized assistant.

Virtual assistants are software programs that help you ease your day to day tasks, such as showing weather reports, creating remainders, making shopping lists etc. They can take commands via text (online chatbots) or by voice. Voice-based intelligent assistants need an invoking word or wake word to activate the listener, followed by the command. We have so many virtual assistants, such as Apple’s Siri, Amazon’s Alexa and Microsoft’s Cortana.
This system is designed to be used efficiently on desktops. Personal assistants software improves user productivity by managing routine tasks of the user and by providing information from an online source to the user.

This project was started on the premise that there is a sufficient amount of openly available data and information on the web that can be utilized to build a virtual assistant that has access to making intelligent decisions for routine user activities.

Keywords: Virtual Assistant Using Python, AI, Digital assistance, Virtual Assistance, Python

II. Related Work
Each company developer of the intelligent assistant applies his own specific methods and approaches for development, which in turn affects the final product. One assistant can synthesize speech more qualitatively, another can more accurately and without additional explanations and corrections perform tasks, others can perform a narrower range of tasks, but most accurately and as the user wants. Obviously, there is no universal assistant who would perform all tasks equally well. The set of characteristics that an assistant has depends entirely on which area the developer has paid more attention to. Since all systems are based on machine learning methods and use for their creation huge amounts of data collected from various sources and then trained on them, an important role is played by the source of this data, be it search systems, various information sources or social networks. The amount of information from different sources determines the nature of the assistant, which can result as a result. Despite the different approaches to learning, different algorithms and techniques, the principle of building such systems remain approximately the same. Figure 1 shows the technologies that are used to create intelligent systems of interaction with a human by his natural language. The main technologies are voice activation, automatic speech recognition, Teach-To-Speech, voice biometrics, dialogue manager, natural language understanding and named entity recognition.

Voice Technology  	Brain Technology  
Voice Activation  	Voice Bio-metrics  
Automatic Speech Recognition (ASR)  	Dialog Management  
    (Teach-To-Speech (TTS)  	Natural Language Understanding (NLU)

Named Entity Recognition NER)  
Fig.1. Technologies for constructing intelligent systems of interaction with a human by natural language
III. Proposed Plan Of Work
The work started with analyzing the audio commands given by the user through the microphone. This can be anything like getting any information, operating a computer’s internal files, etc. This is an empirical qualitative study, based on reading above mentioned literature and testing their examples. Tests are made by programming according to books and online resources, with the explicit goal to find best practices and a more advanced understanding of Voice Assistant.

Virtual Assistant Using Python
Fig.2.  Basic Workflow
Fig.2 shows the workflow of the basic process of the voice assistant. Speech recognition is used to convert the speech input to text. This text is then fed to the central processor which determines the nature of the command and calls the relevant script for execution.

But, the complexities don’t stop there. Even with hundreds of hours of input, other factors can play a huge role in whether or not the software can understand you. Background noise can easily throw a speech recognition device off track. This is because it does not inherently have the ability to distinguish the ambient sounds it “hears” of a dog barking or a helicopter flying overhead, from your voice. Engineers have to program that ability into the device; they conduct data collection of these ambient sounds and “tell” the device to filter them out. Another factor is the way humans naturally shift the pitch of their voice to accommodate for noisy environments; speech recognition systems can be sensitive to these pitch changes.

IV. Methodology of Virtual Assistant Using Python
Virtual Assistant Using Python
Fig 3 Detailed workflow
Speech Recognition module
The system uses Google’s online speech recognition system for converting speech input to text. The speech input Users can obtain texts from the special corpora organized on the computer network server at the information centre from the microphone is temporarily stored in the system which is then sent to Google cloud for speech recognition. The equivalent text is then received and fed to the central processor.

Python Backend:
The python backend gets the output from the speech recognition module and then identifies whether the command or the speech output is an API Call and Context Extraction. The output is then sent back to the python backend to give the required output to the user.

API calls
API stands for Application Programming Interface. An API is a software intermediary that allows two applications to talk to each other. In other words, an API is a messenger that delivers your request to the provider that you’re requesting it from and then delivers the response back to you.

Content Extraction
Context extraction (CE) is the task of automatically extracting structured information from unstructured and/or semi-structured machine-readable documents. In most cases, this activity concerns processing human language texts using natural language processing (NLP). Recent activities in multimedia document processing like automatic annotation and content extraction out of images/audio/video could be seen as context extraction TEST RESULTS.

Text-to-speech module
Text-to-Speech (TTS) refers to the ability of computers to read text aloud. A TTS Engine converts written text to a phonemic representation, then converts the phonemic representation to waveforms that can be output as sound. TTS engines with different languages, dialects and specialized vocabularies are available through third-party publishers.

V. Conclusion
In this paper “Virtual Assistant Using Python” we discussed the design and implementation of Digital Assistance. The project is built using open source software modules with PyCharm community backing which can accommodate any updates shortly. The modular nature of this project makes it more flexible and easy to add additional features without disturbing current system functionalities.

It not only works on human commands but also give responses to the user based on the query being asked or the words spoken by the user such as opening tasks and operations. It is greeting the user the way the user feels more comfortable and feels free to interact with the voice assistant. The application should also eliminate any kind of unnecessary manual work required in the user life of performing every task. The entire system works on the verbal input rather than the next one.

References
[1] R. Belvin, R. Burns, and C. Hein, “Development of the HRL route navigation dialogue system,” in Proceedings of ACL-HLT, 2001
[2] V. Zue, S. Seneff, J. R. Glass, J. Polifroni, C. Pao, T.J.Hazen,and L.Hetherington, “JUPITER: A Telephone Based Conversational Interface for Weather Information,” IEEE Transactions on Speech and Audio Processing, vol. 8, no. 1, pp. 85–96, 2000.
[3] M. Kolss, D. Bernreuther, M. Paulik, S. St¨ucker, S. Vogel, and A. Waibel, “Open Domain Speech Recognition & Translation: Lectures and Speeches,” in Proceedings of ICASSP, 2006.
[4] D. R. S. Caon, T. Simonnet, P. Sendorek, J. Boudy, and G. Chollet, “vAssist: The Virtual Interactive Assistant for Daily Homer-Care,” in Proceedings of pHealth, 2011.
[5] Crevier, D. (1993). AI: The Tumultuous Search for Artificial Intelligence. New York, NY: Basic Books, ISBN 0-465-02997-3.
[6] Sadun, E., &Sande, S. (2014). Talking to Siri: Mastering the Language of Apple’s Intelligent Assistant.
Credit: This Project “Virtual Assistant Using Python” was completed by Damarla Kavya, Daddanala Suvarna, Javisetti Srinivas and Chintha Venkata Ramaiah from the  Department Of Electronics And Communication Engineering, Chalapathi Institute Of Engineering And Technology, Guntur, Andhra Pradesh.

Filed Under: Final year Project papers
Tagged With: AI, Digital assistance, Python, Virtual Assistance, Virtual Assistant Using Python

RECENT POSTS
What is TIG Welding Process? November 1, 2021
Different Interferometers in Metrology October 29, 2021
What are Electric Arc Welding Types? October 26, 2021
What are the Gas Welding Types, Flame types, and Equipment? October 23, 2021

About University Student
This site uses Akismet to reduce spam. Learn how your comment data is processed.

EXTRUDESIGN.COM
Home
About us
Privacy Policy
Terms & Conditions
Submit Content
Site Map
WE ALWAYS CARE ABOUT YOUR PRIVACY!
Name
Your name

Email address
Your email address


EXTRUDESIGN- EXPRESS WITH DESIGN
Our motive is to help students and working professionals with basic and advanced Engineering topics.

We also help students to publish their Articles and research papers.

DMCA.com Protection Status

Copyright ©2021 · ExtruDesign.com - All Rights Reserved ·


© July 2021| IJIRT | Volume 8 Issue 2 | ISSN: 2349-6002
IJIRT 152099 INTERNATIONAL JOURNAL OF INNOVATIVE RESEARCH IN TECHNOLOGY 419
Voice Assistant Using Python
1Nivedita Singh,
2Dr. Diwakar Yagyasen,
3Mr. Surya Vikram Singh,
4Gaurav Kumar,
5Harshit Agrawal
1,2,3,4,5Department of CSE, Babu Banarasi Das National Institute of Technology and Management,
Lucknow, India
Abstract - Today the technological advancement is
increasing day by day. Earlier only there was a computer
system in which we can do only few tasks. But now
machine learning, artificial intelligence, deep learning,
and few more technologies have made computer systems
so advance that we can perform any type of task. In such
era of advancement if people are still struggling to
interact using various input devices, then it’s not worth
it. For this reason, we developed a voice assistant using
python which allows the user to run any type of
command in linux without interaction with keyboard.
The main task of voice assistant is to minimize the use of
input devices like keyboard, mouse etc. It will also reduce
the hardware space and cost.
Index Terms - Artificial Intelligence, Desktop Assistant,
Python, Text to Speech, Virtual Assistant, Voice
Recognition.
INTRODUCTION
In this era of technology everything that human being
can do are being replaced by machines. One of the
main reasons is change in performance. In today’s
world we train our machine to think like humans and
do their task by themselves. Therefore, there came a
concept of virtual assistant.
A virtual assistant is a digital assistant that uses voice
recognition features and language processing
algorithms to recognize voice commands of user and
perform relevant tasks as requested by the user. Based
on specific commands given by the user a virtual
assistant is capable of filtering out the ambient noise
and return relevant information.
Virtual Assistant are completely software based but
nowadays they are integrated in different devices and
also some of the assistants are designed specifically
for single devices like Alexa.
Due to drastic change in technology now it’s a. high
time to train our machine with the help of machine
learning, deep learning, neural networks. Today we
can talk to our machine with the help of Voice
Assistant. Today every big company is using Voice
Assistant so that their user can take the help of
machine through their voice. So, with the Voice
Assistant we are moving to the next level advancement
where we are able to talk to our machine.
These types of virtual assistants are very useful for old
age, blind & physically challenged people, children,
etc. by making sure that the interaction with the
machine is not a challenge anymore for people. Even
blind people who couldn’t see the machine can interact
with it using their voice only.
Here are some of the basic tasks that can be done with
the help of voice assistant: -
• Reading Newspaper
• Getting updates of mail
• Search on web
• Play a music or video
• Setting a reminder and alarm
• Run any program or application
• Getting weather updates
These are some of the examples, we can do many more
things according to our requirement.
The Voice Assistant that we have developed is for
Windows users as well as for Linux Users. The voice
assistant we have developed is a desktop-based built
using python modules and libraries. This assistant is
just a basic version that could perform all the basic
tasks which have been mentioned above but current
technology is although good in it is still to be merged
with Machine Learning and Internet of Things (IoT)
for better enhancements.
We have used python modules and libraries for
making the model and we have used Machine
Learning for training our model, some of the windows
and linux commands are also added to model so that
our model can run smoothly on this operating system.
Basically, our model will work in three modes: -
1. Supervised Learning
2. Unsupervised Learning
3. Reinforcement Learning
© July 2021| IJIRT | Volume 8 Issue 2 | ISSN: 2349-6002
IJIRT 152099 INTERNATIONAL JOURNAL OF INNOVATIVE RESEARCH IN TECHNOLOGY 420
Depending upon the usage for which the assistant is
required for user. And these can be achieved with the
help of Machine learning and Deep Learning.
With the help of Voice Assistant there will be no need
to write the commands again and again for performing
particular task. Once model is created it can be used
any number of times by any number of users in the
easiest ways.
So, with the help of virtual assistant, we will be able
to control many things around us single handedly on
one platform.
II.LITERATURE SURVEY
Bassam A, Raja N. et al, written about statement and
speech which is most significant. In the
communication between human and machine
arrangement was done through analog signal which is
converted by speech signal to digital wave. This
technology is massively utilized, it has limitless uses
and permit machines to reply appropriately and
consistently to user voices, also offers useful and
appreciated facilities. Speech Recognition System
(SRS) is rising gradually and has indefinite
applications. The research has revealed the summary
of the procedure; it is a simple model [1].
B. S. Atal and L. R. Rabiner et al, explained regarding
speech analysis, and result is regularly completed in
combination with pitch analysis. The research
described a pattern recognition technique for
determining whether a given slice of a speech signal
should be categorized as voiced speech, unvoiced
speech, or silence, depending on dimensions finished
on signal. The main restriction of the technique is the
requirement for exercise the algorithm on exact set of
dimensions picked, and for the specific recording
circumstances [2].
V. Radha and C. Vimala et al, explained that most
general mode of communication among human beings
is speech. As this is the utmost technique, human
beings would identical to utilize speech to interrelate
with machines too. Because of this, autonomous
speech identification has got a lot of reputation. Most
techniques for speech recognition be like Dynamic
Time Warping (DTW), HMM. For the feature mining
of speech Mel Frequency Cepstrum Coefficients
(MFCC) has been utilized which offers a group of
characteristic vectors of speech waveform. Prior study
has exposed MFCC to be more precise and real than
rest characteristic mining approaches in the speech
recognition. The effort has been completed on
MATLAB and investigational outcomes depict that
system is capable of identifying words at satisfactorily
great accuracy [3].
T. Schultz and A. Waiel et al, explained about the
spreading of speech technology products around the
globe, the immovability to novel destination languages
turns out to be a useful concern. As a significance, the
research emphases on the query of how to port huge
vocabulary incessant speech recognition (LVCSR)
systems in a fast and well-organized manner. More
particularly the research needs to evaluate acoustic
models for a novel destination language by means of
speech information from different source languages,
but only restricted data from the destination language
identification outcomes using language-dependent,
independent and language-adaptive acoustic models
are described and deliberated in the framework of
Global Phone project which examines LVCSR
methods in 15 languages.[4].
J. B. Allen et al described about the Language that is
the utmost significant means of communication and
speech is its major interface. The interface for human
to machine, speech signal was converted into analog
and digital wave shape as a machine understood. [10]
A technology enormously utilized and has limitless
applications. Speech technologies permit machines to
react appropriately and consistently to human
speeches and offers valuable and appreciated services.
The research provides a summary of the speech
identification procedure, its basic model, and its
application, techniques and also describes reasonable
research of several techniques that are utilized for
speech recognition system. SRS is enhancing
gradually and has infinite applications. [5]
Mugdha Bapat, Pushpak Bhattacharyya et al,
described a morphological analyzer for most of the
NLP solicitations of Indian Languages. [11] During
the work they described and estimated the
morphological analyzer for Marathi language. They
started by planning a to some extent homomorphism
"boos trappable" encryption technique that functions
during the function f is the techniques individual
decryption function. The research showed a great
accuracy for Marathi that adventures consistency in
inflectional standards in engaging the Finite State
Systems for demonstrating language in a sophisticated
way. Grouping of post positions and the growth of 
© July 2021| IJIRT | Volume 8 Issue 2 | ISSN: 2349-6002
IJIRT 152099 INTERNATIONAL JOURNAL OF INNOVATIVE RESEARCH IN TECHNOLOGY 421
FSA is one of significant assistances since Marathi
have difficult morphotactics [6].
G. Muhammad, M. N. Huda et al, presented a model
ASR for Bangla digit. Although Bangla is among the
mostly spoken languages around the globe, some of
the few works of Bangla ASR can be identified in the
collected works, particularly Bangla accented in
Bangladeshi. During this research, the quantity is
gathered from publics in Bangladesh. Mel-frequency
cepstral coefficients (MFCCs) dependent
characteristics and hidden Markov model (HMM)
dependent classifiers are utilized for identification.
Dialectical variance make happen a part of
performance deprivation. In situation of gender-based
trials, female spoken digits had greater accuracy rates
than those by male spoken digits [7].
Sean R Eddy et al operated on Hidden Markov models
which are a common statistical designing approach for
'linear' issues like sequences or time series and have
been extensively utilized in speech identification
requests for twenty years. Inside the HMM formalism,
it is probable to relate formal, completely probabilistic
techniques to profiles and gapped structure
arrangements.[12] Profiles based on Hidden Markov
model have fixed most of the concerns related with
typical profile analysis. HMMs offer a steady theory
for notching insertions and deletions, and a constant
structure for joining structural and sequence data.
HMM based numerous sequence arrangements is
quickly refining. Homolog recognition based on
HMM is previously adequately influential for HMM
techniques to relate satisfactorily to much more
difficult threading techniques for protein reverse fold
[8].
III.PROBLEM FORMULATION
This section describes the description about the
problem formulation.
As we know each human have their own
characteristics and every developer applies his own
method and approaches for development of a product.
One assistant can synthesize speech more
qualitatively, another can more accurately and without
additional explanations and corrections perform tasks,
others are able to perform a narrower range of tasks,
but most accurately and as the user wants.
Therefore, there is no such assistant that can perform
all the work and tasks equally. The set of
characteristics that an assistant has depends on the area
on which developer paid more attention. Since all
system are based on machine learning and use for their
creation huge amounts of data collected from various
sources and then trained on them, an important role is
played by the source of this data.
Despite the different approaches to learn different
algorithms, the principle of building voice assistant
remains the same. The technologies that are used to
build a voice assistant that can interact with the
humans are speech recognition, Teach-To-Speech,
voice biometrics, dialog manager, natural language
understanding and named entity recognition.
IV.PROPOSED APPROACH
The proposed system will have the following
functionality:
(a) The system will keep listening for commands and
the time for listening is variable which can be changed
according to user requirements.
(b) If the system is not able to gather information from
the user input it will keep asking again to repeat till the
desired no. of times.
(c) The system can have both male and female voices
according to user requirements.
(d) Features supported in the current version include
playing music, emails, texts, search on Wikipedia, or
opening system installed applications, opening
anything on the web browser, etc.
(e)The system will keep listening for commands and
the time for listening is variable which can be changed
according to user requirements.
(f) If the system is not able to gather information from
the user input it will keep asking again to repeat till the
desired no. of times.
(g) The system can have both male and female voices
according to user requirements [9].
© July 2021| IJIRT | Volume 8 Issue 2 | ISSN: 2349-6002
IJIRT 152099 INTERNATIONAL JOURNAL OF INNOVATIVE RESEARCH IN TECHNOLOGY 422
V.RESULT AND ANALYSIS
This section describes a brief description of our result
on the basis of the comparison and analysis of our
proposed work. We have employed this idea by means
of Python, Machine Learning and AI. Our main aim is
to assist the users in their tasks with the help of their
voice commands. This can be done in two phases.
Firstly, taking the audio input from the user and
converting it to an English phrase with the help of
Speech Recognition API. Secondly searching for the
task user wants to perform and then redirecting it to
the linux server with the help of HTTP Protocol and
displaying the result on the web browser.
This is the Windows Code which will run on the client
side for taking voice input of the user.
This is the Linux Code which will run on the server
side for running the linux command and displaying the
output on the web.
When the Windows Code is executed the first Output
which will will be displayed is to start speaking. After
this the user has to give the voice command.
This screen will be visible when user has given voice
command and the Google Speech Recognition API has
translated it into an English Phrase.
After translation the command which the user has
given will be displayed on the web browser.
VI.CONCLUSION
In this paper we have discussed a Voice Assistant
developed using python. This assistant currently
works as an application based and performs basic tasks
like weather updates, stream music, search Wikipedia,
open desktop applications, etc. The functionality of the
current system is limited to working on application
based only. The upcoming updates of this assistant 
© July 2021| IJIRT | Volume 8 Issue 2 | ISSN: 2349-6002
IJIRT 152099 INTERNATIONAL JOURNAL OF INNOVATIVE RESEARCH IN TECHNOLOGY 423
will have machine learning incorporated in the system
which will result in better suggestions with IoT to
control the nearby devices similar to what Amazon’s
Alexa does.
REFERENCES
[1] M. Bapat, H. Gune, and P. Bhattacharyya, “A
paradigm-based finite state morphological
analyzer for marathi,” in Proceedings of the 1st
Workshop on South and Southeast Asian Natural
Language Processing (WSSANLP), pp. 26–34,
2010.
[2] B. S. Atal and L. R. Rabiner, “A pattern
recognition approach to voiced unvoiced-silence
classification with applications to speech
recognition,” Acoustics, Speech and Signal
Processing, IEEE Transactions on, vol. 24, no. 3,
pp. 201–212, 1976.
[3] V.Radha and C. Vimala, “A review on speech
recognition challenges and approaches,” doaj.
org, vol. 2, no. 1, pp. 1–7, 2012.
[4] T. Schultz and A. Waibel, “Languageindependent and language adaptive acoustic
modeling for speech recognition”, Speech
Communication, vol. 35, no. 1, pp. 31–51, 2001.
[5] J. B. Allen, “From lord rayleigh to shannon: How
do humans decode speech,” in International
Conference on Acoustics, Speech and Signal
Processing, 2002.
[6] M. Bapat, H. Gune, and P. Bhattacharyya, “A
paradigm-based finite state morphological
analyzer for marathi,” in Proceedings of the 1st
Workshop on South and Southeast Asian Natural
Language Processing (WSSANLP), pp. 26–34,
2010.
[7] G. Muhammad, Y. Alotaibi, M. N. Huda, et al.,
pronunciation variation for asr: A survey of the
“Automatic speech recognition for bangla digits,”
literature,” Speech Communication, vol. 29, no.
in Computers and Information Technology, 2009.
2, pp. 225–246, 1999.
[8] S. R. Eddy, “Hidden Markov models,” Current
opinion in structural biology, vol. 6, no. 3, pp.
361–365, 1996.
[9] excellent style manual for science writers is
“Speech recognition with flat direct models,”
IEEE Journal of Selected Topics in Signal
Processing, 2010.
[10]Srivastava S., Prakash S. (2020) Security
Enhancement of IoT Based Smart Home Using
Hybrid Technique. In: Bhattacharjee A.,
Borgohain S., Soni B., Verma G., Gao XZ. (eds)
Machine Learning, Image Processing, Network
Security and Data Sciences. MIND 2020.
Communications in Computer and Information
Science, vol 1241. Springer, Singapore.
https://doi.org/10.1007/978-981-15-6318-8_44
[11]S. Srivastava and S. Prakash, "An Analysis of
Various IoT Security Techniques: A Review,"
2020 8th International Conference on Reliability,
Infocom Technologies and Optimization (Trends
and Future Directions) (ICRITO), 2020, pp. 355-
362, doi: 10.1109/ICRITO48877.2020.9198027
[12]Saijshree Srivastava, Surya Vikram Singh,
Rudrendra Bahadur Singh, Himanshu Kumar
Shukla,” Digital Transformation of Healthcare: A
blockchain study” International Journal of
Innovative Science, Engineering & Technology,
Vol. 8 Issue 5, May 2021

EXTRUDESIGN

HOME
About Us
Subscribe Here!
Site Map
MECHANICAL ENGINEERING
Machine Design
Engineering Calculators
Motor Torque
Section Modulus
Area Calculator
Shaft Diameter
Stiffness Calculator
Inertia Calculator
More
Metrology
Theory of Machines
Material Science
Advanced Composites
CAD/CAE/CAM
PTC CREO
SOLIDWORKS
CATIA V5
Unit Converters
Torque
Power
Force
Energy
Inertia
Area
How to?
Advanced Excel
Latest Apple news
PROJECTS LIBRARY
HOW TO PUBLISH?
Virtual Assistant Using Python
July 18, 2021 by University Student Leave a Comment

A final year project on “Virtual Assistant Using Python” was submitted by Kavya Damarla (from Chalapathi Institute Of Engineering And Technology, Guntur, Andhra Pradesh) to extrudesign.com.

Virtual Assistant Using Python
Abstract
In this modern era, day to day life became smarter and interlinked with technology. We already know some voice assistance like google, Siri. etc. Now in our voice assistance system, it can act as a basic medical prescriber, daily schedule reminder, note writer, calculator and a search tool. This project works on voice input and give output through voice and displays the text on the screen. The main agenda of our voice assistance makes people smart and give instant and computed results. The voice assistance takes the voice input through our microphone (Bluetooth and wired microphone) and it converts our voice into computer understandable language gives the required solutions and answers which are asked by the user. This assistance connects with the world wide web to provide results that the user has questioned. Natural Language Processing algorithm helps computer machines to engage in communication using natural human language in many forms.

I. Introduction
Today the development of artificial intelligence (AI) systems that can organize a natural human-machine interaction (through voice, communication, gestures, facial expressions, etc.) are gaining in popularity. One of the most studied and popular was the direction of interaction, based on the understanding of the machine by the machine of the natural human language. It is no longer a human who learns to communicate with a machine, but a machine learns to communicate with a human, exploring his actions, habits, behaviour and trying to become his personalized assistant.

Virtual assistants are software programs that help you ease your day to day tasks, such as showing weather reports, creating remainders, making shopping lists etc. They can take commands via text (online chatbots) or by voice. Voice-based intelligent assistants need an invoking word or wake word to activate the listener, followed by the command. We have so many virtual assistants, such as Apple’s Siri, Amazon’s Alexa and Microsoft’s Cortana.
This system is designed to be used efficiently on desktops. Personal assistants software improves user productivity by managing routine tasks of the user and by providing information from an online source to the user.

This project was started on the premise that there is a sufficient amount of openly available data and information on the web that can be utilized to build a virtual assistant that has access to making intelligent decisions for routine user activities.

Keywords: Virtual Assistant Using Python, AI, Digital assistance, Virtual Assistance, Python

II. Related Work
Each company developer of the intelligent assistant applies his own specific methods and approaches for development, which in turn affects the final product. One assistant can synthesize speech more qualitatively, another can more accurately and without additional explanations and corrections perform tasks, others can perform a narrower range of tasks, but most accurately and as the user wants. Obviously, there is no universal assistant who would perform all tasks equally well. The set of characteristics that an assistant has depends entirely on which area the developer has paid more attention to. Since all systems are based on machine learning methods and use for their creation huge amounts of data collected from various sources and then trained on them, an important role is played by the source of this data, be it search systems, various information sources or social networks. The amount of information from different sources determines the nature of the assistant, which can result as a result. Despite the different approaches to learning, different algorithms and techniques, the principle of building such systems remain approximately the same. Figure 1 shows the technologies that are used to create intelligent systems of interaction with a human by his natural language. The main technologies are voice activation, automatic speech recognition, Teach-To-Speech, voice biometrics, dialogue manager, natural language understanding and named entity recognition.

Voice Technology  	Brain Technology  
Voice Activation  	Voice Bio-metrics  
Automatic Speech Recognition (ASR)  	Dialog Management  
    (Teach-To-Speech (TTS)  	Natural Language Understanding (NLU)

Named Entity Recognition NER)  
Fig.1. Technologies for constructing intelligent systems of interaction with a human by natural language
III. Proposed Plan Of Work
The work started with analyzing the audio commands given by the user through the microphone. This can be anything like getting any information, operating a computer’s internal files, etc. This is an empirical qualitative study, based on reading above mentioned literature and testing their examples. Tests are made by programming according to books and online resources, with the explicit goal to find best practices and a more advanced understanding of Voice Assistant.

Virtual Assistant Using Python
Fig.2.  Basic Workflow
Fig.2 shows the workflow of the basic process of the voice assistant. Speech recognition is used to convert the speech input to text. This text is then fed to the central processor which determines the nature of the command and calls the relevant script for execution.

But, the complexities don’t stop there. Even with hundreds of hours of input, other factors can play a huge role in whether or not the software can understand you. Background noise can easily throw a speech recognition device off track. This is because it does not inherently have the ability to distinguish the ambient sounds it “hears” of a dog barking or a helicopter flying overhead, from your voice. Engineers have to program that ability into the device; they conduct data collection of these ambient sounds and “tell” the device to filter them out. Another factor is the way humans naturally shift the pitch of their voice to accommodate for noisy environments; speech recognition systems can be sensitive to these pitch changes.

IV. Methodology of Virtual Assistant Using Python
Virtual Assistant Using Python
Fig 3 Detailed workflow
Speech Recognition module
The system uses Google’s online speech recognition system for converting speech input to text. The speech input Users can obtain texts from the special corpora organized on the computer network server at the information centre from the microphone is temporarily stored in the system which is then sent to Google cloud for speech recognition. The equivalent text is then received and fed to the central processor.

Python Backend:
The python backend gets the output from the speech recognition module and then identifies whether the command or the speech output is an API Call and Context Extraction. The output is then sent back to the python backend to give the required output to the user.

API calls
API stands for Application Programming Interface. An API is a software intermediary that allows two applications to talk to each other. In other words, an API is a messenger that delivers your request to the provider that you’re requesting it from and then delivers the response back to you.

Content Extraction
Context extraction (CE) is the task of automatically extracting structured information from unstructured and/or semi-structured machine-readable documents. In most cases, this activity concerns processing human language texts using natural language processing (NLP). Recent activities in multimedia document processing like automatic annotation and content extraction out of images/audio/video could be seen as context extraction TEST RESULTS.

Text-to-speech module
Text-to-Speech (TTS) refers to the ability of computers to read text aloud. A TTS Engine converts written text to a phonemic representation, then converts the phonemic representation to waveforms that can be output as sound. TTS engines with different languages, dialects and specialized vocabularies are available through third-party publishers.

V. Conclusion
In this paper “Virtual Assistant Using Python” we discussed the design and implementation of Digital Assistance. The project is built using open source software modules with PyCharm community backing which can accommodate any updates shortly. The modular nature of this project makes it more flexible and easy to add additional features without disturbing current system functionalities.

It not only works on human commands but also give responses to the user based on the query being asked or the words spoken by the user such as opening tasks and operations. It is greeting the user the way the user feels more comfortable and feels free to interact with the voice assistant. The application should also eliminate any kind of unnecessary manual work required in the user life of performing every task. The entire system works on the verbal input rather than the next one.

References
[1] R. Belvin, R. Burns, and C. Hein, “Development of the HRL route navigation dialogue system,” in Proceedings of ACL-HLT, 2001
[2] V. Zue, S. Seneff, J. R. Glass, J. Polifroni, C. Pao, T.J.Hazen,and L.Hetherington, “JUPITER: A Telephone Based Conversational Interface for Weather Information,” IEEE Transactions on Speech and Audio Processing, vol. 8, no. 1, pp. 85–96, 2000.
[3] M. Kolss, D. Bernreuther, M. Paulik, S. St¨ucker, S. Vogel, and A. Waibel, “Open Domain Speech Recognition & Translation: Lectures and Speeches,” in Proceedings of ICASSP, 2006.
[4] D. R. S. Caon, T. Simonnet, P. Sendorek, J. Boudy, and G. Chollet, “vAssist: The Virtual Interactive Assistant for Daily Homer-Care,” in Proceedings of pHealth, 2011.
[5] Crevier, D. (1993). AI: The Tumultuous Search for Artificial Intelligence. New York, NY: Basic Books, ISBN 0-465-02997-3.
[6] Sadun, E., &Sande, S. (2014). Talking to Siri: Mastering the Language of Apple’s Intelligent Assistant.
Credit: This Project “Virtual Assistant Using Python” was completed by Damarla Kavya, Daddanala Suvarna, Javisetti Srinivas and Chintha Venkata Ramaiah from the  Department Of Electronics And Communication Engineering, Chalapathi Institute Of Engineering And Technology, Guntur, Andhra Pradesh.

Filed Under: Final year Project papers
Tagged With: AI, Digital assistance, Python, Virtual Assistance, Virtual Assistant Using Python

RECENT POSTS
What is TIG Welding Process? November 1, 2021
Different Interferometers in Metrology October 29, 2021
What are Electric Arc Welding Types? October 26, 2021
What are the Gas Welding Types, Flame types, and Equipment? October 23, 2021

About University Student
This site uses Akismet to reduce spam. Learn how your comment data is processed.

EXTRUDESIGN.COM
Home
About us
Privacy Policy
Terms & Conditions
Submit Content
Site Map
WE ALWAYS CARE ABOUT YOUR PRIVACY!
Name
Your name

Email address
Your email address


EXTRUDESIGN- EXPRESS WITH DESIGN
Our motive is to help students and working professionals with basic and advanced Engineering topics.

We also help students to publish their Articles and research papers.

DMCA.com Protection Status

Copyright ©2021 · ExtruDesign.com - All Rights Reserved ·Skip to content
Search...

Log in
Create account

6

3

17

Rohit Jain
Rohit Jain
Posted on May 19

How to Create a Virtual Assistant Using Python
#python #assistant #programming #school


Hey Guys Today let's create something interesting, a virtual assistant. A computer is a device that helps everyone to achieve things fast. It does things faster than humans and it did not get bored whenever it performs a repetitive task. We can automate our repetitive tasks using a computer so tasks can perform fast and we just need to convey to a computer either by giving a voice command or by typing the command.

First, we need to think about the task that we want the assistant to perform and how it can automate it like greet us, whenever we want to execute something, tell us the date, time, news, weather, jokes, send emails, send messages, open something in a computer, tell us internal information about computers like cup usage and much more. We can make Functions or write simple codes to make it work.

For making these tasks in python we need to install a couple of packages. You can use the below commands for that.

Open terminal with administration privileges execute these commands either one by one or write the package name together.
pip install SpeechRecognition # for Voice commands
pip install clipboard # For working with clipboard
pip install newsapi # For Getting news
pip install newsapi-python # For News api
pip install psutil # For getting compute info
pip install pyaudio # For working with audio
pip install pyautogui # For performing some GUI operation
pip install pyttsx3 # For Voice Interaction
You can use other packages as well and different functionalities with these. Let's jump into the coding

Initially, we need to import the packages as in every Python Program
import clipboard
import datetime
import os
import psutil
import pyautogui
import pyjokes
import pyttsx3
import pywhatkit
import requests
import smtplib
import speech_recognition as sr
import time as ti
import webbrowser as we
from email.message import EmailMessage
from newsapi import NewsApiClient
from secrets import senderemail, password
from time import sleep
Now I would like to set the variables for user name and assistant name so it can be changed easily if we want.
user = "Rohit"
assistant= "Jarvis" # Iron man Fan
Then forgetting voice output we need to use pyttsx3

Initialize Pyttsx3 Engine
engine = pyttsx3.init()
voices = engine.getProperty("voices")

# For Mail voice AKA Jarvis
engine.setProperty("voice", voices[0].id)

# For Female voice AKA Friday
# engine.setProperty("voice", voices[1].id)
These are the voices of Microsoft David (Male) and Microsoft Zira (Female) Voice for the windows narrator program. You can install other voices as well but I find that a bit laggy and everything is not covered in them.

Input/Output Functions
def output(audio):
    # print(audio) # For printing out the output
    engine.say(audio)
    engine.runAndWait()

# For getting the device index you can execute this code So if you want to change the device you can do that.
# for index, name in enumerate(sr.Microphone.list_microphone_names()):
#     print("Microphone with name \"{1}\" found for `Microphone(device_index={0})`".format(
#         index, name))

def inputCommand():
    # query = input() # For getting input from CLI
    r = sr.Recognizer()
    query = ""
    with sr.Microphone(device_index=2) as source:
        print("Listening...")
        r.pause_threshold = 1
        try:
            query = r.recognize_google(r.listen(source), language="en-IN")
        except Exception as e:
            output("Say that again Please...")
    return query
Up to this, we are just setting the things for an assistant. Now we will make functions for our tasks

Greet Function
def greet():
    hour = datetime.datetime.now().hour
    if (hour >= 6) and (hour < 12):
        output(f"Good Morning {user}")
    elif (hour >= 12) and (hour < 18):
        output(f"Good afternoon {user}")
    elif (hour >= 18) and (hour < 21):
        output(f"Good Evening {user}")
    output("How may I assist you?")
Email Function
# You can also use a secret file and store these variables there as I am doing or If you not going to show this code to anyone that you can it here as well.
def sendEmail():
    senderemail = "kingtechnologies2017@gmail.com"
    password = "********"
    email_list = {
        "test1": "bojole7513@httptuan.com", # Temporary Email
        "test2": "<Your Friends, family or business email here>"
    }
    try:
        email = EmailMessage()
        output("To whom you want to send the mail?")
        name = inputCommand().lower()
        email['To'] = email_list[name]
        output("What is the subject of the mail?")
        email["Subject"] = inputCommand()
        email['From'] = senderemail
        output("What should i Say?")
        email.set_content(inputCommand())
        s = smtplib.SMTP("smtp.gmail.com", 587)
        s.starttls()
        s.login(senderemail, password)
        s.send_message(email)
        s.close()
        output("Email has sent")
    except Exception as e:
        print(e)
        output("Unable to send the Email")
Send Whatsapp Message Function
It is utilizing the web browser package
def sendWhatMsg():
    user_name = {
        'Jarvis': '+91 95299 16394'
    }
    try:
        output("To whom you want to send the message?")
        name = inputCommand()
        output("What is the message")
        we.open("https://web.whatsapp.com/send?phone=" +
                user_name[name]+'&text='+inputCommand())
        sleep(6)
        pyautogui.press('enter')
        output("Message sent")
    except Exception as e:
        print(e)
        output("Unable to send the Message")
Weather Function
For Weather, we can use OpenWeatherMap API
def weather():
    city = "jaipur"
    res = requests.get(
        f"http://api.openweathermap.org/data/2.5/weather?q={city}&appid=16f0afad2fd9e18b7aee9582e8ce650b&units=metric").json()
    temp1 = res["weather"][0]["description"]
    temp2 = res["main"]["temp"]
    output(
        f"Temperature is {format(temp2)} degree Celsius \nWeather is {format(temp1)}")
News Function
For News, we can use the News API package
def news():
    newsapi = NewsApiClient(api_key='5840b303fbf949c9985f0e1016fc1155')
    output("What topic you need the news about")
    topic = inputCommand()
    data = newsapi.get_top_headlines(
        q=topic, language="en", page_size=5)
    newsData = data["articles"]
    for y in newsData:
        output(y["description"])
Idea Function
We can use file handling for that it's quite reliable storage but we need to implement it carefully
def idea():
    output("What is your idea?")
    data = inputCommand().title()
    output("You Said me to remember this idea: " + data)
    with open("data.txt", "a", encoding="utf-8") as r:
        print(data, file=r)
Now the last part i.e. Function calling based on Command and some inline execution
First of all the greet function
greet()
# Then with while true we can make it a infinite loop on command
while True:
    # Getting input from the user
    query = inputCommand().lower()
    # According to the query if query have respective word we will execute the respective command
    if ("time" in query):
        output("Current time is " +
               datetime.datetime.now().strftime("%I:%M"))

    elif ('date' in query):
        output("Current date is " + str(datetime.datetime.now().day)
               + " " + str(datetime.datetime.now().month)
               + " " + str(datetime.datetime.now().year))

    elif ('email' in query):
        sendEmail()

    elif ('message' in query):
        print("Sending...")
        sendWhatMsg()

    elif ("search" in query):
        output("what you want to search?")
        we.open("https://www.google.com/search?q="+inputCommand())

    elif ("youtube" in query):
        output("What you want to search on Youtube?")
        pywhatkit.playonyt(inputCommand())

    elif ('weather' in query):
        weather()

    elif ("news" in query):
        news()

    elif ("read" in query):
        output(clipboard.paste())

    elif ("covid" in query):
        r = requests.get(
            'https://coronavirus-19-api.herokuapp.com/all').json()
        output(
            f'Confirmed Cases: {r["cases"]} \nDeaths: {r["deaths"]} \nRecovered {r["recovered"]}')

    elif ("workspace" in query):
        output("Which workspace you want to work on")
        os.startfile("D:\\Work Spaces\\" +
                     inputCommand()+".code-workspace")

    elif ("joke" in query):
        output(pyjokes.get_joke())

    elif ("idea" in query):
        idea()

    elif ("do you know" in query):
        ideas = open("data.txt", "r")
        output(f"You said me to remember these ideas:\n{ideas.read()}")

    elif ("screenshot" in query):
        pyautogui.screenshot(str(ti.time()) + ".png").show()

    elif "cpu" in query:
        output(f"Cpu is at {str(psutil.cpu_percent())}")

    elif "offline" in query:
        hour = datetime.datetime.now().hour
        if (hour >= 21) and (hour < 6):
            output(f"Good Night {user}! Have a nice Sleep")
        else:
            output(f"By {user}")
        quit()

Based on different input we are executing different task is this way our assistant can have so much functionality we can utilize
This is all For this blog, as I mentioned earlier you can customize it according to you and you can check out the GitHub repo for complete code

Let me know if you have any questions or queries. I’ll be happy to help you.
Like share, and follow. You can also check my other profiles on King Technologies
Thanks for reading
Read next
ingosteinke profile image
fractal.build as an atomic design tool
Ingo Steinke - Oct 19

iamtekson profile image
Installation of GDAL on jupyter notebook
Tek Bahadur Kshetri - Oct 19

rammina profile image
What are the things that scare you as a Developer? 🎃
Rammina - Oct 31

iamtekson profile image
How to Access Jupyter Notebook Remotely on Webbrowser
Tek Bahadur Kshetri - Oct 19


Rohit Jain
Follow
Building Web & Mobile Projects and gain a lot of expertise in them. Graphic design is my passion. Like to work in Teams but never hesitate to work alone.
LOCATION
Indian
WORK
Tech Head at King Technologies
JOINED
Apr 23, 2021
Trending on DEV Community 
Breno Lopes do Carmo profile image
100 Days of Code
#webdev #programming #productivity #100daysofcode
Damian Demasi profile image
GitHub Copilot blew my mind on a code-along exercise
#webdev #programming #productivity #discuss
Aditya Priyadarshi profile image
Explain me async like I am a Kid
#programming #python #javascript #java
DEV Community – A constructive and inclusive social network for software developers. With you every step of your journey.

Built on Forem — the open source software that powers DEV and other inclusive communities.

Made with love and Ruby on Rails. DEV Community © 2016 - 2021.
Subscribe to KDnuggets 	Twitter    LinkedIn    Facebook   	Submit a blog
to KDnuggets
search KDnuggets
 
BlogOpinionsTutorialsTop storiesCoursesDatasetsEducation: OnlineCertificatesEvents / MeetingsJobsSoftwareWebinars
 
KDnuggets Home » News » 2019 » Sep » Tutorials, Overviews » Build Your First Voice AssistantBuild Your First Voice Assistant
<= Previous postNext post =>
 
 
Tags: Machine Learning, NLP, Python, Speech Recognition

Hone your practical speech recognition application skills with this overview of building a voice assistant using Python.
By Nagesh Singh Chauhan, Data Science Enthusiast.
comments
Figure
source: giphy

 

Nowadays, it isn’t surprising to hear someone speak to someone that isn’t there. We ask Alexa for the weather and to turn the temperature down on the thermostat. Then, we ask Siri what our schedule for the day is and to call people. We are connected now more than ever using our voice and voice interface technology. I can’t imagine doing things manually anymore! It’s truly the future.

— Forbes

 

Introduction
 
Who doesn't want to have the luxury to own an assistant who always listens for your call, anticipates your every need, and takes action when necessary? That luxury is now available thanks to artificial intelligence-based voice assistants.

Voice assistants come in somewhat small packages and can perform a variety of actions after hearing your command. They can turn on lights, answer questions, play music, place online orders and do all kinds of AI-based stuff.

Voice assistants are not to be confused with virtual assistants, which are people who work remotely and can, therefore, handle all kinds of tasks. Rather, voice assistants are technology based. As voice assistants become more robust, their utility in both the personal and business realms will grow as well.

Figure
source

 

 

What is a Voice Assistant?
 
A voice assistant or intelligent personal assistant is a software agent that can perform tasks or services for an individual based on verbal commands i.e. by interpreting human speech and respond via synthesized voices. Users can ask their assistants’ questions, control home automation devices, and media playback via voice, and manage other basic tasks such as email, to-do lists, open or close any application etc with verbal commands.

Let me give you the example of Braina (Brain Artificial) which is an intelligent personal assistant, human language interface, automation and voice recognition software for Windows PC. Braina is a multi-functional AI software that allows you to interact with your computer using voice commands in most of the languages of the world. Braina also allows you to accurately convert speech to text in over 100 different languages of the world.

 

History of Voice Assistants
 

Figure
A modern history of Voice Assistants

 

In recent times, Voice assistants got the major platform after Apple integrated the most astonishing Virtual Assistant — Siri which is officially a part of Apple Inc. But the timeline of greatest evolution began with the year 1962 event at the Seattle World Fair where IBM displayed a unique apparatus called Shoebox. It was the actual size of a shoebox and could perform scientific functions and can perceive 16 words and also speak them in the human recognizable voice with 0 to 9 numerical digits.

During the period of the 1970s, researchers at Carnegie Mellon University in Pittsburgh, Pennsylvania — with the considerable help of the U.S Department of Defence and its Defence Advanced Research Projects Agency (DARPA) — made Harpy. It could understand almost 1,000 words, which is approximately the vocabulary of a three-year-old child.

Big organizations like Apple and IBM sooner in the 90s started to make things that utilized voice acknowledgment. In 1993, Macintosh began to building speech recognition with its Macintosh PCs with PlainTalk.

In April 1997, Dragon NaturallySpeaking was the first constant dictation product which could comprehend around 100 words and transform it into readable content.

Figure
source

 

Having said that, how cool it would be to build a simple voice-based desktop/laptop assistant that has the capability to:

Open the subreddit in the browser.
Open any website in the browser.
Send an email to your contacts.
Launch any system application.
Tells you the current weather and temperature of almost any city
Tells you the current time.
Greetings
Play you a song on VLC media player(of course you need to have VLC media player installed in your laptop/desktop)
Change desktop wallpaper.
Tells you latest news feeds.
Tells you about almost anything you ask.
So here in this article, we are going to build a voice-based application which is capable of doing all the above-mentioned tasks. But first, check out this video below which I made while I was interacting with the desktop voice assistant and I call her Sofia.

New video by Nagesh Chauhan
Interaction with Sofia
 

I hope you guys have liked the above video in which I was interacting with Sofia. Now let’s start building this cool thing…

Dependencies and requirements :

System requirements: Python 2.7, Spyder IDE, MacOS Mojave(version 10.14)

Install all these python libraries :

pip install SpeechRecognition
pip install beautifulsoup4
pip install vlc
pip install youtube-dl
pip install pyowm
pip install wikipedia


 

Let’s start building our desktop voice assistant using python
 

Figure
source

 

Start by importing all the required libraries :

import speech_recognition as sr
import os
import sys
import re
import webbrowser
import smtplib
import requests
import subprocess
from pyowm import OWM
import youtube_dl
import vlc
import urllib
import urllib2
import json
from bs4 import BeautifulSoup as soup
from urllib2 import urlopen
import wikipedia
import random
from time import strftime



For our voice-assistant to perform all the above-discussed features, we have to code the logic of each of them in one method.

So our first step is to create the method which will interpret user voice response.

def myCommand():
    r = sr.Recognizer()
    with sr.Microphone() as source:
        print('Say something...')
        r.pause_threshold = 1
        r.adjust_for_ambient_noise(source, duration=1)
        audio = r.listen(source)
    try:
        command = r.recognize_google(audio).lower()
        print('You said: ' + command + '\n')
    #loop back to continue to listen for commands if unrecognizable speech is received
    except sr.UnknownValueError:
        print('....')
        command = myCommand();
    return command



Next, create a method that will convert text to speech.

def sofiaResponse(audio):
    print(audio)
    for line in audio.splitlines():
        os.system("say " + audio)



Now create a loop to continue executing multiple commands. Inside the method assistant() passing user command(myCommand()) as parameters.

while True:
    assistant(myCommand())



Our next step is to create multiple if statements corresponding to each of the features. So let us see how to create these small modules inside if statement for each command.

 

1. Open the subreddit Reddit in the browser.
 
The user will give any command to open any subreddit from Reddit and the command should be “Hey Sofia! Can you please open Reddit subreddit_name”. only the italic bold phrase should be used as it is. You can use any kind of prefix, just take care of the italic bold phrase.

How it works : If you have said the phrase open reddit in your command then it will search for subreddit name in the user command using re.search(). The subreddit will be searched using www.reddit.com and will get opened in the browser using pythons Webbrowser module.The Webbrowser module provides a high-level interface to allow displaying Web-based documents to users.

if 'open reddit' in command:
        reg_ex = re.search('open reddit (.*)', command)
        url = 'https://www.reddit.com/'
        if reg_ex:
            subreddit = reg_ex.group(1)
            url = url + 'r/' + subreddit
        webbrowser.open(url)
        sofiaResponse('The Reddit content has been opened for you Sir.')



So, the above code will open your desired Reddit in your default browser.

 

2. Open any website in the browser.
 
You can open any website just be saying “open website.com” or “open website.org”.

For example: “Please open facebook.com” or “Hey, can you open linkedin.com” like this you can ask Sofia to open any website for you.

How it works : If you have said the word open in your command then it will search for website name in the user command using re.search(). Next, it will append the website name to https://www. and using webbrowser module the complete URL gets opened in the browser.

elif 'open' in command:
        reg_ex = re.search('open (.+)', command)
        if reg_ex:
            domain = reg_ex.group(1)
            print(domain)
            url = 'https://www.' + domain
            webbrowser.open(url)
            sofiaResponse('The website you have requested has been opened for you Sir.')
        else:
            pass



 

3. Send Email.
 
You can also ask your desktop assistant to send the email.

How it works : If you have said the word email in your command then the bot will ask for receipient, If my response is rajat, the bot will use pthons smtplib library. The smtplib module defines an SMTP client session object that can be used to send mail to any Internet machine with an SMTP or ESMTP listener daemon. Sending mail is done with Python’s smtplib using an SMTP server. First it will initaite gmail SMTP using smtplib.SMTP(), then identify the server using ehlo() function, then encypting the session starttls(), then login to your mailbox using login(), then sending the message using sendmail().

elif 'email' in command:
        sofiaResponse('Who is the recipient?')
        recipient = myCommand()if 'rajat' in recipient:
            sofiaResponse('What should I say to him?')
            content = myCommand()
            mail = smtplib.SMTP('smtp.gmail.com', 587)
            mail.ehlo()
            mail.starttls()
            mail.login('your_email_address', 'your_password')
            mail.sendmail('sender_email', 'receiver_email', content)
            mail.close()
            sofiaResponse('Email has been sent successfuly. You can check your inbox.')else:
            sofiaResponse('I don\'t know what you mean!')



 

4. Launch any system application.
 
Say “launch calendar” or “can you please launch skype” or “Sofia launch finder” etc. and Sofia will launch that system application for you.

How it works : If you have said the word launch in your command then it will search for application name(if it is present in your system) in the user command using re.search(). It will then append the suffix “.app” to the application name. Now your application name is for example say calender.app(In macOS the executable files end with extension .app unlike in Windows which ends with .exe). So the executable application name will be launched using python subprocess’s Popen() function. The subprocess module enables you to start new applications from your Python program.

elif 'launch' in command:
        reg_ex = re.search('launch (.*)', command)
        if reg_ex:
            appname = reg_ex.group(1)
            appname1 = appname+".app"
            subprocess.Popen(["open", "-n", "/Applications/" + appname1], stdout=subprocess.PIPE)sofiaResponse('I have launched the desired application')



 

5. Tells you the current weather and temperature of almost any city.
 
Sofia can also tell you the weather, maximum and minimum temperature of any city around the world. The user just needs to say something like “what is the current weather in London” or “tell me the current weather in Delhi”.

How it works : If you have said the phrase current weather in your command then it will search for city name using re.search(). I have used pythons pyowm library to get the weather of any city. get_status() will tell you about the weather condition like haze, cloudy, rainy etc and get_temperature() will tell you about the max and min temperature of the city.

elif 'current weather' in command:
     reg_ex = re.search('current weather in (.*)', command)
     if reg_ex:
         city = reg_ex.group(1)
         owm = OWM(API_key='ab0d5e80e8dafb2cb81fa9e82431c1fa')
         obs = owm.weather_at_place(city)
         w = obs.get_weather()
         k = w.get_status()
         x = w.get_temperature(unit='celsius')
         sofiaResponse('Current weather in %s is %s. The maximum temperature is %0.2f and the minimum temperature is %0.2f degree celcius' % (city, k, x['temp_max'], x['temp_min']))



 

6. Tells you the current time.
 
“Sofia can you tell me the current time ?” or “what is the time now ?” and Sofia will tell you the current time of your timezone.

How it works : Its pretty simple

elif 'time' in command:
     import datetime
     now = datetime.datetime.now()
     sofiaResponse('Current time is %d hours %d minutes' % (now.hour, now.minute))



 

7. Greetings/ leave
 
Say “hello Sofia” to greet your voice assistant or when you want the program to terminate say something like “shutdown Sofia” or “Sofia please shutdown” etc.

How it works : If you have said the word hello in your command, then depending on the time of the day, the bot will greet the user. If the time is more than 12 noon, the bot will respond “Hello Sir. Good afternoon”, likewise if the time is more than 6 ck pm, the bot will respond “Hello Sir. Good evening”. And when you give command as shutdown, sys.exit() will be called to terminate the program.

#Greet Sofia
    elif 'hello' in command:
        day_time = int(strftime('%H'))
        if day_time < 12:
            sofiaResponse('Hello Sir. Good morning')
        elif 12 <= day_time < 18:
            sofiaResponse('Hello Sir. Good afternoon')
        else:
            sofiaResponse('Hello Sir. Good evening')#to terminate the program
elif 'shutdown' in command:
     sofiaResponse('Bye bye Sir. Have a nice day')
     sys.exit()



 

8. Play you a song on VLC media player
 
This feature allows your voice bot to play your desired song in VLC media player. The user will say “Sofia play me a song”, the bot will ask “What song shall I play Sir?”. Just say the name of the song and Sofia will download the song from youtube in your local drive, play that song on the VLC media player and if you again play a song the previously downloaded song will get deleted automatically.

How it works :If you have said the phrase play me a song in your command, then it will ask you what video song to play. The song you will ask will be searched in youtube.com, If found than the song will be downloaded in your local directory using pythons youtube_dl library. The youtube-dl is a command-line program to download videos from YouTube.com and a few more sites. Now the song will be played as soon as it gets downloded using pythons VLC library and play(path_to__videosong) module actually playes the song.

Now if the next time you ask for any other song, the local directory will be flushed and a new song will be downloaded in that directory.

elif 'play me a song' in command:
        path = '/Users/nageshsinghchauhan/Documents/videos/'
        folder = path
        for the_file in os.listdir(folder):
            file_path = os.path.join(folder, the_file)
            try:
                if os.path.isfile(file_path):
                    os.unlink(file_path)
            except Exception as e:
                print(e)sofiaResponse('What song shall I play Sir?')mysong = myCommand()
        if mysong:
            flag = 0
            url = "https://www.youtube.com/results?search_query=" + mysong.replace(' ', '+')
            response = urllib2.urlopen(url)
            html = response.read()
            soup1 = soup(html,"lxml")
            url_list = []
            for vid in soup1.findAll(attrs={'class':'yt-uix-tile-link'}):
                if ('https://www.youtube.com' + vid['href']).startswith("https://www.youtube.com/watch?v="):
                    flag = 1
                    final_url = 'https://www.youtube.com' + vid['href']
                    url_list.append(final_url)url = url_list[0]
            ydl_opts = {}os.chdir(path)
            with youtube_dl.YoutubeDL(ydl_opts) as ydl:
                ydl.download([url])
            vlc.play(path)if flag == 0:
                sofiaResponse('I have not found anything in Youtube ')



 

9. Change desktop wallpaper.
 
You guys can also change your desktop wallpaper using this feature. When you say something like “change wallpaper” or “Sofia please change wallpaper” the bot will download random wallpaper from unsplash.comand sets it as your desktop background.

How it works : If you have said the phrase change wallpaper in your command, the program will download a random wallpaper from unsplash.com, store it in local directory and set it as your desktop wallpaper using subprocess.call(). I have used unsplash API to get access to its content.

Now if the next time you ask to change the wallpaper again, your local directory will be flushed and a new wallpaper will be downloaded in that directory.

elif 'change wallpaper' in command:
        folder = '/Users/nageshsinghchauhan/Documents/wallpaper/'
        for the_file in os.listdir(folder):
            file_path = os.path.join(folder, the_file)
            try:
                if os.path.isfile(file_path):
                    os.unlink(file_path)
            except Exception as e:
                print(e)
        api_key = 'fd66364c0ad9e0f8aabe54ec3cfbed0a947f3f4014ce3b841bf2ff6e20948795'
        url = 'https://api.unsplash.com/photos/random?client_id=' + api_key #pic from unspalsh.com
        f = urllib2.urlopen(url)
        json_string = f.read()
        f.close()
        parsed_json = json.loads(json_string)
        photo = parsed_json['urls']['full']
        urllib.urlretrieve(photo, "/Users/nageshsinghchauhan/Documents/wallpaper/a") # Location where we download the image to.
        subprocess.call(["killall Dock"], shell=True)
        sofiaResponse('wallpaper changed successfully')



 

10. Tells you latest news feeds.
 
Sofia can also tell you the latest news update. The user just has to say “Sofia what are the top news for today ?” or “tell me the news for today”.

How it works : If you have said the phrase news for today in your command then it will scrape data using Beautiful Soup from Google News RSS() and read it for you. For convineince I have set number of news limit to 15.

elif 'news for today' in command:
        try:
            news_url="https://news.google.com/news/rss"
            Client=urlopen(news_url)
            xml_page=Client.read()
            Client.close()
            soup_page=soup(xml_page,"xml")
            news_list=soup_page.findAll("item")
            for news in news_list[:15]:
                sofiaResponse(news.title.text.encode('utf-8'))
        except Exception as e:
                print(e)



 

11. Tells you about almost anything you ask.
 
Your bot can fetch details of almost anything you ask her. Like “Sofia tell me about Google” or “Please tell me about Supercomputers” or “please tell me about the Internet”. So as you can see you can ask about almost anything.

How it works : If you have said the phrase tell me about in your command then it will search for the keyword in the user command using re.search(). Using pythons wikipedia library it will search for that topic and extract first 500 characters(if you dont specify the limit the bot will read the whole page for you). Wikipedia is a Python library that makes it easy to access and parse data from Wikipedia.

elif 'tell me about' in command:
        reg_ex = re.search('tell me about (.*)', command)
        try:
            if reg_ex:
                topic = reg_ex.group(1)
                ny = wikipedia.page(topic)
                sofiaResponse(ny.content[:500].encode('utf-8'))
        except Exception as e:
                sofiaResponse(e)



Let's put everything together

import speech_recognition as sr
import os
import sys
import re
import webbrowser
import smtplib
import requests
import subprocess
from pyowm import OWM
import youtube_dl
import vlc
import urllib
import urllib2
import json
from bs4 import BeautifulSoup as soup
from urllib2 import urlopen
import wikipedia
import random
from time import strftimedef sofiaResponse(audio):
    "speaks audio passed as argument"
    print(audio)
    for line in audio.splitlines():
        os.system("say " + audio)def myCommand():
    "listens for commands"
    r = sr.Recognizer()
    with sr.Microphone() as source:
        print('Say something...')
        r.pause_threshold = 1
        r.adjust_for_ambient_noise(source, duration=1)
        audio = r.listen(source)
    try:
        command = r.recognize_google(audio).lower()
        print('You said: ' + command + '\n')
    #loop back to continue to listen for commands if unrecognizable speech is received
    except sr.UnknownValueError:
        print('....')
        command = myCommand();
    return commanddef assistant(command):
    "if statements for executing commands"#open subreddit Reddit
    if 'open reddit' in command:
        reg_ex = re.search('open reddit (.*)', command)
        url = 'https://www.reddit.com/'
        if reg_ex:
            subreddit = reg_ex.group(1)
            url = url + 'r/' + subreddit
        webbrowser.open(url)
        sofiaResponse('The Reddit content has been opened for you Sir.')elif 'shutdown' in command:
        sofiaResponse('Bye bye Sir. Have a nice day')
        sys.exit()#open website
    elif 'open' in command:
        reg_ex = re.search('open (.+)', command)
        if reg_ex:
            domain = reg_ex.group(1)
            print(domain)
            url = 'https://www.' + domain
            webbrowser.open(url)
            sofiaResponse('The website you have requested has been opened for you Sir.')
        else:
            pass#greetings
    elif 'hello' in command:
        day_time = int(strftime('%H'))
        if day_time < 12:
            sofiaResponse('Hello Sir. Good morning')
        elif 12 <= day_time < 18:
            sofiaResponse('Hello Sir. Good afternoon')
        else:
            sofiaResponse('Hello Sir. Good evening')elif 'help me' in command:
        sofiaResponse("""
        You can use these commands and I'll help you out:1. Open reddit subreddit : Opens the subreddit in default browser.
        2. Open xyz.com : replace xyz with any website name
        3. Send email/email : Follow up questions such as recipient name, content will be asked in order.
        4. Current weather in {cityname} : Tells you the current condition and temperture
        5. Hello
        6. play me a video : Plays song in your VLC media player
        7. change wallpaper : Change desktop wallpaper
        8. news for today : reads top news of today
        9. time : Current system time
        10. top stories from google news (RSS feeds)
        11. tell me about xyz : tells you about xyz
        """)#joke
    elif 'joke' in command:
        res = requests.get(
                'https://icanhazdadjoke.com/',
                headers={"Accept":"application/json"})
        if res.status_code == requests.codes.ok:
            sofiaResponse(str(res.json()['joke']))
        else:
            sofiaResponse('oops!I ran out of jokes')#top stories from google news
    elif 'news for today' in command:
        try:
            news_url="https://news.google.com/news/rss"
            Client=urlopen(news_url)
            xml_page=Client.read()
            Client.close()
            soup_page=soup(xml_page,"xml")
            news_list=soup_page.findAll("item")
            for news in news_list[:15]:
                sofiaResponse(news.title.text.encode('utf-8'))
        except Exception as e:
                print(e)#current weather
    elif 'current weather' in command:
        reg_ex = re.search('current weather in (.*)', command)
        if reg_ex:
            city = reg_ex.group(1)
            owm = OWM(API_key='ab0d5e80e8dafb2cb81fa9e82431c1fa')
            obs = owm.weather_at_place(city)
            w = obs.get_weather()
            k = w.get_status()
            x = w.get_temperature(unit='celsius')
            sofiaResponse('Current weather in %s is %s. The maximum temperature is %0.2f and the minimum temperature is %0.2f degree celcius' % (city, k, x['temp_max'], x['temp_min']))#time
    elif 'time' in command:
        import datetime
        now = datetime.datetime.now()
        sofiaResponse('Current time is %d hours %d minutes' % (now.hour, now.minute))elif 'email' in command:
        sofiaResponse('Who is the recipient?')
        recipient = myCommand()
        if 'rajat' in recipient:
            sofiaResponse('What should I say to him?')
            content = myCommand()
            mail = smtplib.SMTP('smtp.gmail.com', 587)
            mail.ehlo()
            mail.starttls()
            mail.login('your_email_address', 'your_password')
            mail.sendmail('sender_email', 'receiver_email', content)
            mail.close()
            sofiaResponse('Email has been sent successfuly. You can check your inbox.')
        else:
            sofiaResponse('I don\'t know what you mean!')#launch any application
    elif 'launch' in command:
        reg_ex = re.search('launch (.*)', command)
        if reg_ex:
            appname = reg_ex.group(1)
            appname1 = appname+".app"
            subprocess.Popen(["open", "-n", "/Applications/" + appname1], stdout=subprocess.PIPE)sofiaResponse('I have launched the desired application')#play youtube song
    elif 'play me a song' in command:
        path = '/Users/nageshsinghchauhan/Documents/videos/'
        folder = path
        for the_file in os.listdir(folder):
            file_path = os.path.join(folder, the_file)
            try:
                if os.path.isfile(file_path):
                    os.unlink(file_path)
            except Exception as e:
                print(e)sofiaResponse('What song shall I play Sir?')
        mysong = myCommand()
        if mysong:
            flag = 0
            url = "https://www.youtube.com/results?search_query=" + mysong.replace(' ', '+')
            response = urllib2.urlopen(url)
            html = response.read()
            soup1 = soup(html,"lxml")
            url_list = []
            for vid in soup1.findAll(attrs={'class':'yt-uix-tile-link'}):
                if ('https://www.youtube.com' + vid['href']).startswith("https://www.youtube.com/watch?v="):
                    flag = 1
                    final_url = 'https://www.youtube.com' + vid['href']
                    url_list.append(final_url)url = url_list[0]
            ydl_opts = {}os.chdir(path)
            with youtube_dl.YoutubeDL(ydl_opts) as ydl:
                ydl.download([url])
            vlc.play(path)if flag == 0:
                sofiaResponse('I have not found anything in Youtube ')#change wallpaper
    elif 'change wallpaper' in command:
        folder = '/Users/nageshsinghchauhan/Documents/wallpaper/'
        for the_file in os.listdir(folder):
            file_path = os.path.join(folder, the_file)
            try:
                if os.path.isfile(file_path):
                    os.unlink(file_path)
            except Exception as e:
                print(e)
        api_key = 'fd66364c0ad9e0f8aabe54ec3cfbed0a947f3f4014ce3b841bf2ff6e20948795'
        url = 'https://api.unsplash.com/photos/random?client_id=' + api_key #pic from unspalsh.com
        f = urllib2.urlopen(url)
        json_string = f.read()
        f.close()
        parsed_json = json.loads(json_string)
        photo = parsed_json['urls']['full']
        urllib.urlretrieve(photo, "/Users/nageshsinghchauhan/Documents/wallpaper/a") # Location where we download the image to.
        subprocess.call(["killall Dock"], shell=True)
        sofiaResponse('wallpaper changed successfully')#askme anything
    elif 'tell me about' in command:
        reg_ex = re.search('tell me about (.*)', command)
        try:
            if reg_ex:
                topic = reg_ex.group(1)
                ny = wikipedia.page(topic)
                sofiaResponse(ny.content[:500].encode('utf-8'))
        except Exception as e:
                print(e)
                sofiaResponse(e)sofiaResponse('Hi User, I am Sofia and I am your personal voice assistant, Please give a command or say "help me" and I will tell you what all I can do for you.')#loop to continue executing multiple commands
while True:
    assistant(myCommand())



So you have seen how just by writing simple lines of python code we can create a very cool voice-based desktop/laptop assistant. Apart from these features, you can also include many different features in your voice assistant.

Please not that once you start executing your program, be loud and clear while you are interacting with voice assistant because it may happen that if your voice is not clear your voice assistant may not be able to interpret you properly.

 

Conclusion: What the future holds
 
Throughout the history of computing, user interfaces have become progressively natural to use. The screen and keyboard were one step in this direction. The mouse and graphical user interface were another. Touch screens are the most recent development. The next step will most likely consist of a mix of augmented reality, gestures and voice commands. After all, it is often easier to ask a question or have a conversation than it is to type something or enter multiple details in an online form.

The more a person interacts with voice-activated devices, the more trends, and patterns the system identifies based on the information it receives. Then, this data can be utilized to determine user preferences and tastes, which is a long-term selling point for making a home smarter. Google and Amazon are looking to integrate voice-enabled artificial intelligence capable of analyzing and responding to human emotion.

I hope you guys have enjoyed reading this article. Share your thoughts/comments/doubts in the comment section. You can reach me out over LinkedIn.

 
Bio: Nagesh Singh Chauhan is a Big data developer at CirrusLabs. He has over 4 years of working experience in various sectors like Telecom, Analytics, Sales, Data Science having specialisation in various Big data components.

Original. Reposted with permission.

Related:

Practical Speech Recognition with Python: The Basics
Comparison of the Top Speech Processing APIs
TensorFlow vs PyTorch vs Keras for NLP

<= Previous postNext post =>


Top Stories Past 30 Days
How I Tripled My Income With Data Science in 18 Months
What Google Recommends You do Before Taking Their Machine Learning or Data Science Course
Data Scientist vs Data Engineer Salary
Learn To Reproduce Papers: Beginner’s Guide
The 20 Python Packages You Need For Machine Learning and Data Science
Design Patterns for Machine Learning Pipelines
Data Scientist Career Path from Novice to First Job
365 Data Science courses free until 18 November
Salary Breakdown of the Top Data Science Jobs
8 Must-Have Git Commands for Data Scientists
Latest News SigOpt AI & HPC Summit, Nov 16 – Virtual and...POS Tagging, ExplainedTop Stories, Nov 1-7: What Google Recommends You do Bef...7 Top Open Source Datasets to Train Natural Language Pr...Federated Learning: Google’s TakeBuild Your Own Automated Machine Learning App

Top Stories
Last Week
What Google Recommends You do Before Taking Their Machine Learning or Data Science Course
What Google Recommends You do Before Taking Their Machine Learning or Data Science Course
Design Patterns for Machine Learning Pipelines
Data Scientist Career Path from Novice to First Job
Salary Breakdown of the Top Data Science Jobs
ORDAINED: The Python Project Template
More Recent Stories
Build Your Own Automated Machine Learning AppMachine Learning Safety: Unsolved ProblemsThe Best Ways for Data Professionals to Market AWS Skills in 2022Toloka 101 Live Demo: Learn how to get reliable training data ...A First Principles Theory of GeneralizationAI Infinite Training & Maintaining LoopNLP for Business in the Time of BERTera: Seven Misplaced Passions7 of The Coolest Machine Learning Topics of 2021 at ODSC WestVisual Scoring Techniques for Classification ModelsData Scientist Career Path from Novice to First JobNeural Networks from a Bayesian PerspectiveKDnuggets 21:n42, Nov 3: Google Recommendations Before Taki...Three reasons to self-host your product analyticsORDAINED: The Python Project TemplateDesign Patterns for Machine Learning Pipelines [Silver Blog]Salary Breakdown of the Top Data Science JobsTop Stories, Oct 25-31: How I Tripled My Income With Data Scie...Advanced PyTorch Lightning with TorchMetrics and Lightning FlashTop 5 Time Series MethodsIs the Modern Data Stack Leaving You Behind?
KDnuggets Home » News » 2019 » Sep » Tutorials, Overviews » Build Your First Voice Assistant

© 2021 KDnuggets. | About KDnuggets  | Contact  | Privacy policy  | Terms of Service
 INTELLIGENT VOICE ASSISTANT
Intelligent Voice Assistant
Bachelor Thesis
Spring 2012
School of Health and Society
Department Computer Science
Computer Software Development
Writer
Shen Hui
Song Qunying
Instructor
Andreas Nilsson
Examiner
Christian Andersson
INTELLIGENT VOICE ASSISTANT
I
School of Health and Society
Department Computer Science
Kristianstad University
SE-291 88 Kristianstad
Sweden
Author, Program and Year:
Song Qunying, Bachelor in Computer Software Development 2012
Shen Hui, Bachelor in Computer Software Development 2012
Instructor:
Andreas Nilsson, School of Health and Society, HKr
Examination:
This graduation work on 15 higher education credits is a part of the requirements for a
Degree of Bachelor in Computer Software Development (as specified in the English translation)
Title:
Intelligent Voice Assistant
Abstract:
This project includes an implementation of an intelligent voice recognition assistant for Android
where functionality on current existing applications on other platforms is compared. Until this day,
there has not been any good alternative for Android, so this project aims to implement a voice
assistant for the Android platform while describing the difficulties and challenges that lies in this
task.
Language:
English
Approved by:
_____________________________________
Christian Andersson Date
Examiner
INTELLIGENT VOICE ASSISTANT
II
Table of Contents Page
Document page I
Abstract I
Table of Contents II
1 Introduction 1
1.1 Context 1
1.2 Aim and Purpose 2
1.3 Method and Resources 3
1.4 Project Work Organization 7
1.5 Acknowledgements 8
2 Analysis 9
2.1 Information Retrieval 9
2.2 Theory Model 11
2.3 Alternative Models/solution 15
2.4 Environmental Consequences 20
3 Realization 21
3.1 Choice of Solution 21
3.2 Equipment/ Choice of Materials 30
INTELLIGENT VOICE ASSISTANT
III
3.3 Problems and Solutions 31
4 Results 34
4.1 Design 34
4.2 Functioning 36
4.3 Operation and Maintenance 39
5 Conclusions 45
6 Recommendations for Further Work 47
6.1 Design Improvements 47
6.2 Additional Functions 47
6.3 Database Capacity 47
6.4 Humanized Voice Recognition 48
6.5 Improved Interface 48
7 References 49
8 Appendix A Figure 50
9 Appendix B Code 52
INTELLIGENT VOICE ASSISTANT
1
1 Introduction
1.1 Context
This project is based on Android application development and provide personal assistant using voice
recognition or text mode operation. This program includes the functions and services of: calling
services, text message transformation, mail exchange, alarm, event handler, location services, music
player service, checking weather, Google searching engine, Wikipedia searching engine, robot chat,
camera, Bing translator, Bluetooth headset support, help menu and Windows azure cloud computing.
As it integrates most of the mobile phone services for daily use, it could be useful for getting a more
convenient life and it will be helpful for those people who have disabilities for manual operations.
This is also part of the reason why it has been chosen as the degree project.
This project is originated from a popular application from Apple called “Siri” [1]. This application
was released on the date when the iPhone4S was published. This application is very interesting, easy
going and convenient, with wide real world usage and large developing potential. This application is
not limited by different generations and occupations, and can be applied to many industries that we
have in the real world. For instance, the voice assistance is very useful for personal assistants,
direction guides or driving, helps among the disabled community, and so on.
This is a short description about “Siri” from Wikipedia to illustrate the voice product: “Siri”
an intelligent personal assistant and knowledge navigator which works as an application for Apple's
iOS. The application uses a natural language user interface to answer questions, make
recommendations, and perform actions by delegating requests to a set of web services. Apple claims
that the software adapts to the user's individual preferences over time and personalizes results, and
performing tasks such as finding recommendations for nearby restaurants or getting directions. 
INTELLIGENT VOICE ASSISTANT
2
1.2 Aim and Purpose
According to the overall description in the context, the purpose of the project is to develop an
Android application that provides an intelligent voice assistant with the functionalities as calling
services, message transformation, mail exchange, alarm, event handler, location services, music play
service, checking weather, searching engine (Google, Wikipedia), camera, Bing translator, Bluetooth
headset support, help menu and Windows azure cloud computing.
Many years ago, software programs were developed and run on the computer. Nowadays, smart
phones are widely used by all people. About 35 percent of the Americans have some sort of
Smartphone. This shows that the market is increasing fast and there are also more capabilities for
Smartphone because of this wide use. [2]
Therefore, the software development on the Smartphone is very promising. The operation modes on
the Smartphone are by working with gestures and through the keyboard. It is not a convenient way
for users with completely manually input. The common way of communication used by people in
daily life is through the speech. If the mobile phone can listen to the user for the request or handle
the daily affairs, then give the right response, it will be much easier for users to communicate with
their phone, and the mobile phone will be much more “Smart” as a human assistant.
This project is focusing on the Android development over the voice control (recognition, generate
and analyze corresponding commands, intelligent responses automatically), Google products and
relevant APIs (Google map, Google weather, Google search and etc), Wikipedia API and mobile
device references ranging from Speech-To-Text, Text-To-Speech technology, Bluetooth headset
support and camera; advanced techniques of Cloud computing, Multi-threading, Adobe Photoshop
image editing skills. As all those functionalities and services for the project have been explained, the
main structure and construction of the project has been basically illustrated with its goals. 
INTELLIGENT VOICE ASSISTANT
3
1.3 Method and Resources
This project mainly concerns the work on Android application development; request calling between
different Android applications, human-mobile phone interaction, database creation and management,
the program will reference a lot of APIs from Google, Wikipedia, and Android development skills.
Apart from the project itself, there is also some investigation works on the existed products in this
area and the tendency of voice product, personal assistant developing. Two products were mainly
investigated that are popular and representative, the English product of “Siri” and the Chinese
product of “iFly” [Chinese name: 讯飞语点 [3]]. The investigation focus on how those ideas
originated; what functionalities and services they have; how they provide these services to the
customers; test the product and related functions to get the architect, structure, logical algorithms of
those products; how they spread and promote the product in marketing; and how they refine and
upgrade the products from different versions. Table-1 shows the comparison about some basic
functions between “Siri” and “iFly”.
Function Siri iFly
Call Service Yes Yes
SMS Message Service Yes Yes
Open Application No Yes
Web Search Service Google Search Engine Baidu Search Engine
Reminder 24h Unlimited
Music Play Local Library Local + Remote Library
Command Text Modify Yes No
Language
English & French & German
& Japanese
Chinese
Table-1
In addition, it has been investigated that the developing tendency in this area based on the internet
information and online video of conference from Apple, Android and some other Chinese products. 
INTELLIGENT VOICE ASSISTANT
4
To learn how they are going to develop the products in this area from all possible aspects and the
potential developing factors.
For a better and efficient development, the project is carried out over the XP (Extreme Programming)
model. Extreme programming (XP) is a software development methodology which is intended to
improve software quality and responsiveness to changing customer requirements. As a type of agile
software development, it advocates frequent "releases" in short development cycles (timeboxing),
which is intended to improve productivity and introduce checkpoints where new customer
requirements can be adopted. [4]
The developments will on the small cycle model repeatedly, every cycle will have analysis, design,
implementation and test. Figure-1 somehow shows how to follow the XP develop model.
Figure-1
The total work have been defined in one hundred percentages, the list show how many percentages
developers finished in each week; totally it has been worked for eight weeks to complete the project.
In addition, the chart also shows how much that has been completed for the different part of the
development from the requirement to the test. Figure-2 figures out the process and the progress that
has been finished in each phase to complete the project. 
INTELLIGENT VOICE ASSISTANT
5
Figure-2
Figure-3 shows the process of the completion percentages with the timeline for each perspective
includes requirement, design, implementation and test. Figure-3 presents the efficiency and
completion of the project from all aspects.
Figure-3
0
5
10
15
20
25
30
35
40
45
50
week 1 week 2 week 3 week 4 week 5 week 6 week 7 week 8
Requriment
Design
Implementation
Test
0
10
20
30
40
50
60
70
80
90
100
week 1 week 2 week 3 week 4 week 5 week 6 week 7 week 8
Requriment
Design
Implementation
Test
INTELLIGENT VOICE ASSISTANT
6
Figure-3 also indicates the tendency and expected working process of the project work. In addition,
the efficiency and evaluation speed of the project can be seen from it. And most important is the
diagram points out how the project will be completed in time.
INTELLIGENT VOICE ASSISTANT
7
1.4 Project Work Organization
The project work is organized based on the actual task for the designing, implementation, test and
optimization. As it has been primary planned, each of the developers worked 5 days a week; 3 days
for implementation, and 2 days for testing and summarizing the work, totally it is 8 weeks’ work.
Apart from the designing, implementation and testing, developers also defined the work plan every
time before the implementation and improve the project after the accomplishment of each individual
section.
Developers communicate though the MSN, Facebook and Skype for sharing the ideas and discuss the
project. Data statistics and relative materials is collected and shared through Dropbox. Mostly the
work was done by pairing programming, that is, every time developers made a meeting and set
together for designing, figure out a valid solution and doing the implementation together.
The high-level designing and the framework was done together, and the individual implementation of
functions was assigned to different developers, but the developer was not only caring his own part, but
also considering the whole program. 
INTELLIGENT VOICE ASSISTANT
8
1.5 Acknowledgements
As it requires an Android phone testing and running the program, the Android phone is quite
necessary. The school provided a Sony Ericsson phone with the Android operating system, but the
phone was in a 2.0 version which is too low to implement the project. Thanks to WANG LINLIN for
lending the phone and it can be frequently used for the project development. 
INTELLIGENT VOICE ASSISTANT
9
2 Analysis
2.1 Information Retrieval
As this program includes the functions and services of: calling services, text message transformation,
mail exchange, alarm, event handler, location services, music player service, checking weather, Google
searching engine, Wikipedia searching engine, robot chat, camera, Bing translator, Bluetooth headset
support and help menu. The list below indicates the information and the requirements of each individual
function.
The program has two modes to well fetch the services and functions. The program will start with voice
mode as its primary mode to provide the voice assistant, but the user can select switching to the text
mode if he or she is not well working with the voice mode or the surrounds don’t support the voice
recognition well.
 Calling service, the application should allow the users to give a call to the person in the contacts.
By giving a correct command with the calling request to a stored person, the Android phone
should successfully direct to the number of the person requested.
 Text Message transformation, customers are able to send the SMS to a specific person in the
contacts. By giving a correct command contains the messaging request keyword together with
the destination person, the message should be sent to the destination immediately.
 Mail exchange, customers are able to send the mail to the person with mail address in the
contacts. By giving a correct command contains the mail request keyword together with the
destination person; the mail should be received by the recipient after it has been sent.
 Alarm, as a basic function on the mobile phone, it is frequently that users need to set the alarm
to a specific time. The user could set the alarm through the request with the given time.
 Event handler, the application should allow the user to set as many events as they want.
Customers with the event content should be stored and available for the user to check, modify
and delete.
 Location services, location services provide the functions for the user to check the current
location or find the direction to a destination. The user should get an easy to understand map
with the locations or routes depending on the category of the request.
INTELLIGENT VOICE ASSISTANT
10
 Music player service, the music player offers the services to the user to play a named or a
randomly picked song in the pre-stored song list on the mobile phone. And it could be stopped
when the user wants to terminate it.
 Checking weather, the user could check the weather in any place. In addition, the weather is
returned with the temperature and humidity; the user could also check the weather for current
day, tomorrow or in next four days.
 Google searching engine, the search engine enable the user to search anything on Google. The
search engine will give result list back and displayed on the browser.
 Wikipedia searching engine, the search engine enable the user to search anything on Wikipedia.
The result is given back on the web browser with the searched content on Wikipedia.
 Robot chat, this is the robot chat which provides fun to the user. After enter the chat mode, a text
response will given by the mobile phone whenever the user speaks to it.
 Camera, the camera function will call the camera on the mobile phone to take a picture of the
current view, the picture will be stored in the Gallery for later viewing and operation.
 Bing translator, the translator will translate the original text in the object language the user wants.
There have been 25 object languages stored and the original text should be English.
 Bluetooth headset support, since it is not possible to do the voice recognition while the music
player is playing or the surroundings are noisy; the Bluetooth headset support makes it possible
to speak to the headset rather than the mobile phone if the user enables it.
 Help menu, the user can choose the help menu if the user doesn’t know how to work with the
functions. The help menu gives the list of functions with the examples and explanation of how to
work with different functions as well. 
INTELLIGENT VOICE ASSISTANT
11
2.2 Theory Model
The project is based on the theories related to various aspects of software engineering principles and
software development model; Java programming skills and Android tutorials, Database management
and network communication technologies.
The database and the web service in this project are put on the windows azure cloud; developers will
never be required to run the web service and database locally. The cloud platform will handle the
execution and maintenance. Hence, cloud computing is an important concept and theory guide the
development.
• Cloud computing: Cloud computing refers to the delivery of computing and storage
capacity as a service to a heterogeneous community of end-recipients. The name comes
from the use of clouds as an abstraction for the complex infrastructure it contains in system
diagrams. Cloud computing entrusts services with a user's data, software and computation
over a network. It has considerable overlap with software as a service (SaaS). [5]
• Software engineering principles
Extreme programming will direct the development process of the project, it focus on the
development cycle of defining the requirement, corresponding design and test, integration
and simplicity; during the development, there should always be working in pair
programming, as well as doing the revision control, calculate the velocity and efficiency.
Extreme programming (XP) is a software development methodology which is intended to i
mprove software quality and responsiveness to changing customer requirements. As a type o
f agile software development, it advocates frequent "releases" in short development cycles (t
imeboxing), which is intended to improve productivity and introduce checkpoints where ne
w customer requirements can be adopted. [6]

• Java programming: java API and reference, which is helpful in guide programming in
eclipse and construction of the framework, and the completion of the functions.
Java is a programming language originally developed by James Gosling at Sun
Microsystems (which has since merged into Oracle Corporation) and released in 1995 as a
core component of Sun Microsystems' Java platform. The language derives much of its
syntax from C and C++ but has a simpler object model and fewer low-level facilities. Java
applications are typically compiled to bytecode (class file) that can run on any Java Virtual
Machine (JVM) regardless of computer architecture. Java is a general-purpose, concurrent,
class-based, object-oriented language that is specifically designed to have as few
implementation dependencies as possible. It is intended to let application developers "write 
INTELLIGENT VOICE ASSISTANT
12
once, run anywhere" (WORA), meaning that code that runs on one platform does not need
to be recompiled to run on another. Java is currently one of the most popular programming
languages in use, particularly for client-server web applications, with a reported 10 million
users. [7] [8]
• Android: this project is mainly focus on the Android development to enable most of the
Android functions for daily use ranging from check the weather to check location, and
weather services and etc, Android reference will be the theory promote the development of
the project and related applications, [9] [10] [11]
• Database management: The program will always work with different databases like
Microsoft SQL Server and MySQL Server. Cloud database to handle the data storing,
updating, and retrieving. The following chapters indicate the usage and information of each
database. Through this information, it can be obtained of the advantages and disadvantages
of each database.
The data stored in this project is not so much and complicated as in a corporation; therefore,
each of the databases mentioned can well meet the requirement of the data storage, updating
or be dropped as well. However, the choice of the databases still depends upon the
convenience while considering the advantage and disadvantage. As the commands are
received by the program, the command should be analyzed with the database, MS SQL
Server has been the best choice since it provides the method to search in the content which
is convenient to identify the keyword, keyword category and keyword content, this
advantage is contributed by the method CHARINDEX.
Microsoft SQL Server 2012 is a cloud-ready information platform that will help
organizations unlock breakthrough insights across the organization and quickly build
solutions to extend data across on-premises and public cloud, backed by mission critical
confidence [12]
The MySQL database has become the world's most popular open source database because of
its high performance, high reliability and ease of use. It is also the database of choice for a
new generation of applications built on the LAMP stack (Linux, Apache, MySQL, PHP /
Perl / Python.) Many of the world's largest and fastest-growing organizations including
Facebook, Google, Adobe, Alcatel Lucent and Zappos rely on MySQL to save time and
money powering their high-volume Web sites, business-critical systems and packaged
software.
MySQL runs on more than 20 platforms including Linux, Windows, Mac OS, Solaris, IBM
AIX, giving you the kind of flexibility that puts you in control. Whether you're new to
database technology or an experienced developer or DBA, MySQL offers a comprehensive
range of database tools, support, training and consulting services to make you successful.
[13]
INTELLIGENT VOICE ASSISTANT
13
SQL Azure is a highly available and scalable cloud database service built on SQL Server
technologies. With SQL Azure, developers do not have to install setup or manage any
database. High availability and fault tolerance is built-in and no physical administration is
required. SQL Azure is a managed service that is operated by Microsoft and has a 99.9%
monthly SLA. [14]
• Network communication technologies
The communication in this program is based on the predefined protocol, the communication
within the program is implemented in following the pre-defined protocol, the other main
part of the communication is between the Android program in eclipse and the cloud
platform, this will be done by working with URL, WSDL file. Figure-4 shows some
knowledge of cloud platform, URL and WSDL. [15]
Figure 4
The WSDL describes services as collections of network endpoints, or ports. The WSDL
specification provides an XML format for documents for this purpose. The abstract
definitions of ports and messages are separated from their concrete use or instance,
allowing the reuse of these definitions. A port is defined by associating a network address
with a reusable binding, and a collection of ports defines a service. Messages are abstract
descriptions of the data being exchanged, and port types are abstract collections of
supported operations. The concrete protocol and data format specifications for a 
INTELLIGENT VOICE ASSISTANT
14
particular port type constitutes a reusable binding, where the operations and messages are
then bound to a concrete network protocol and message format. In this way, WSDL
describes the public interface to the Web service. [16]
INTELLIGENT VOICE ASSISTANT
15
2.3 Alternative Models/solution
Figure-5
The architecture (see figure-5) is depending on the developing simulation. The architecture diagram
is not only directed the development of the project, but also figure out the main fields and technique
references related to implementing the project with expected functions.
- The voice input will be firstly recorded by the Android phone.
- The voice will be recognized by the Android applications by using the Android API and Java
API. A recorded text will be generated and send to the cloud server or Android applications
depending on the command.
- The cloud server will decode the received text with the Java API, references, and predefined
database, then decide the following procedures that should be executed.
- A command will be generated into a URL by the cloud server and sent to the specific server
(Google server, Wikipedia server).
- The server which receives the request will using the specific API of Wikipedia API, Google
API to generate the response in XML or JSON format.
- Cloud server will obtain the XML/ JSON response file and transform to a specific response
which will be led to the Android application.
- The Android application will generate the audio output to the customers with the mobile
speaker.
INTELLIGENT VOICE ASSISTANT
16
Figure-6
The configuration diagram (see figure-6) explains all the develop methods, the real strategies and
development process with the core techniques that are used in the project work. Most of the
applications and useful mechanisms are included.
- When the Android application received the audio input, the speech recognition will record
the voice with acoustic model and language model/Grammar, a string reflects the audio input
will be delivered to the java server.
- Whenever the string input is received by the cloud server, it will be passed down to the web
service, further decoded with the cloud database which includes all the possible commands.
- While the meaning of the string has been detected, the corresponding command is
transmitted to the specific application/ server program depending on the command.
- The application/server program generates the result and response back with an object to the
Android phone according to the command and relevant data.
INTELLIGENT VOICE ASSISTANT
17
- The Android phone generates the response into the audio output that delivered to the
customer, or the operations that should be carried out to complete the expected result.
List below indicates the solutions to each of the functions in this program.
• Calling service, when the application receive the command for making phone calls to
someone, with the name it will first check the contacts and find the phone number of the
person that contain the given name, then make the phone call by directing to that number.
By checking through the contact list and find the phone number, the calling can be dialled
out by calling the system call action intent in Android.
• Text Message, when the application receives the command for sending a SMS message to
someone, it will first check the contacts and find the phone number of the person contain the
given name, and then send the message successfully. By checking through the contact list
and find the phone number, the message can be sent out by calling the system message send
action intent in Android. There are two alternative solutions to complete it:
 By capturing the content and name, directly send the message content to the number
of the person’s name.
 By capturing the content and name, switch to the message sending function interface
on the mobile phone with the person and content, the user can decide if send it or not
depend on the captured content is correct or not.
• Mail exchange, when the application receives the command for sending email to someone, it
will first check the contacts and find the email address of the person which contains the
given name, and then send the email successfully to the destination. By checking through
the contact list and find the email address, the email can be sent out by calling the system
email send intent in Android. There are two alternative solutions to complete it:
 By capturing the content and name, directly send the email content to the address of
the person’s name.
 By capturing the content and name, switch to the email interface on the mobile phone
with the person and content, the user can decide if send it or not depend on the
captured content is correct or not.
• Alarm, when the application receives the request of setting the alarm to a valid time, the
program will get the time with dedicated hour and minute, the set the alarm to that specific
time. The alarm can be set by the system alarm manager with the time. There are two forms
to get alarm work:
INTELLIGENT VOICE ASSISTANT
18
• Set the alarm to the given time and alarm will be activated when the time comes up.
• Set the alarm to the given time and alter appears when the time comes up, the user
decide to stop the alarm or not.
• Event handler, when the application receives the command of setting an event to a valid
time, the event will be stored and can be viewed later. The user can check one/all events and
choose to modify, delete the event, this function can be achieved by starting the sub event
application in the program with the title, content, and time from the user’s input.
• Location service, the location service can be categorized in two forms depend on the request,
the service will either return the current location or the route from the current location to the
destination depending on what is required by the user.
• If the user wants to check the current location, the program will get and display the
location through mobile phone GPS module in a map.
• If the user wants to get the route from the current location to other city, the program
will first check the GEO information for the destination, then send current and
destination position to the Google map server and get the route info then display it in
a map with highlighted route.
• Music player service, when the program receive a command of play a song, it will firstly
check whether the command contains the song’s name or not, if the name appeared in the
command, it will get the path of the song and play the song, otherwise the program will
randomly pick a song from the media library and play it. Every time when the program is
loaded, it will called the system to collection all the media files on the mobile then save then
into the library, if the user wants to play the song, it will start the music play service and
play the music in background.
• Checking weather, when the program receives the request of checking weather, it will firstly
check whether the command contains the location information or not, if the command
contain to a location name, then it will check if the command have a date value included or
not. The Google weather service is used to accomplish the weather checking.
 If today is detected, the weather for today in the specified location will be presented
with the temperature, condition, humidity, wind direction.
 If no today is detected, the weather for next four days in the specified location will be
presented with the highest and lowest temperature, condition.
INTELLIGENT VOICE ASSISTANT
19
• Google searching engine, when the command is detected with the action to use the Google
search engine. The program will generate the URL of the Google search link with the given
search content and then start the system’s internet browser with this link, finally gives the
result back on the web browser.
• Wikipedia searching engine, when the command is detected with the action to use the
Wikipedia engine. The program will generate the URL of the Wikipedia link with the given
search content and then start the system’s internet browser with this link, finally gives the
result back on the web browser.
• Robot chat, if the command contains the words can be understood to enable chat, the
program will enter the chat mode and give the user a predefined response to each sentence
give by the user. The chat mode continues work until the chat is finished by the correct
command.
• Camera, when the application receives the command to start the camera, the program will
start the intent to enable the camera preview, after the photo has been captured, it will be
saved in to the SD card memory and notify to the gallery for updating.
• Bing translator, the program will firstly detect the command with the destination language
code and the content; generate a URL that contains the original language, the destination
language and content. Then the URL will be opened and receive the result from the Bing
translator for presenting to the user.
• Bluetooth headset support, the Bluetooth mode can be automatically activated by the user
plug in the Bluetooth headset to the mobile phone. The program will enable the Bluetooth
button when it receives a broadcast from the system. When the connection is enabled
between the mobile phone and the Bluetooth headset, the audio manager of the mobile
phone can be set to the Bluetooth headset mode and use the Microphone and speaker on the
headset.
• Help menu, the user can open the help menu by selecting on the main option menu or given
the help command, the help menu is designed by a main help menu and a list of sub menus,
each sub menu is corresponded to one function with the explanation and examples to show
how it works, each menu is designed in an individual activity.
INTELLIGENT VOICE ASSISTANT
20
2.4 Environmental Consequences
This program is green to the environment and no pollution will be generated by the software or
hardware. During the development, the process will not do any harm to the surrounding
environment since it is software development on the computer. The following list contains all the
software, hardware, develop platform, developing process we use in this project. Hence it can
prove that no pollution is created by these rephrases.
Develop platform: Microsoft Windows 7, Windows Azure Platform.
Develop tools and environment: Java ™, JDK, Eclipse IDE, Android SDK, ADT Plug-in, ADV,
and Plug-in for Eclipse, MySQL query browser, DB-Designer, SQL Server Management Studio,
and Microsoft Visual Web Developer 2010 Express.
API and reference: Java API, Android API, Google API (Google Map, Google Weather),
Wikipedia API, SQL tutorial, UML reference, JSON, XML, Cloud computing, multi-threading
techniques, .net framework 4.0.
Software application on Android phone: Android Internet explorer, Google voice recognize, TTS
Service Extended, Alarm, Mobile phone calling services, text message services.
Support application: Adobe Photoshop CS5, Meitu (Chinese).
Hardware support: Android phone [HTC/Samsung], PC.
Developing model: XP (Extreme programming)
INTELLIGENT VOICE ASSISTANT
21
3 Realization
3.1 Choice of Solution
This chapter explains the actual solution to construct of the whole program. The functions include:
Calling services, message transformation, mail exchange, alarm, event handler, location services,
music play service, checking weather, searching engine (Google, Wikipedia), camera, Bing
translator, Bluetooth headset support, help menu and Windows azure cloud computing.
As it has been illustrated in 2.3, the whole construction of the program mainly cover Android
application development, the database design, web service and cloud computing.
The Android application, which implements and presents all the functions, is constructed in Eclipse
with Android development references. The program implements voice recognition to capture the
incoming requests. Creating the main activity and building each of the functions, implementing the
logic to construct the whole program. Further by fetching the web service on the Windows Azure
Cloud, the command can be analyzed with the storage on the database; corresponding responses will
be directed to specific function in the program. Figure-7 shows the overall design of the program
through UML.
INTELLIGENT VOICE ASSISTANT
22
Figure-7
The database is designed with MS SQL server. By creating different tables to store the data in
different category, the data can be well stored, retrieved, updated or deleted. To well support the data
process in web service, the database is uploaded on the Windows Azure Cloud.
Web service, the web service is implemented in C# since it is placed on the Windows Cloud. The
web service takes the incoming request as the parameter; analyze it by check the keyword contained
in the request, and give correct response to the program. The same with the database, the web service
is uploaded on the Windows Azure Cloud.
Cloud computing, Windows Azure has been chosen as the cloud platform since it provide a three
months’ free use with a registered account. By establishing the database and creating the web
services for intended use, the database and the web service are uploaded on the Cloud and, the data
processing are going as cloud computing.
The following indicate the design for each individual function in this program.
• The programs start with the voice recognition, by implementing the RecognitionListener, it
will capture the text every time the speaker speaks to it, then the generated text and send to
the cloud (see Figure-8).
Figure-8
• The azure cloud which is an open cloud platform, where the software, database, web service
can be placed there for future use. In this program, the web service and database are uploaded
on the azure cloud for executing and maintenance (see Figure-9).

Speech
Recognizer
Weather today “Weather today”
“Weather today”
Internet
WS
Database
Cloud
“3|1|0”
INTELLIGENT VOICE ASSISTANT
23
Figure-9
 The web service is written in C# and connects to the cloud database, the captured text
will firstly be sent to the cloud as a parameter to call the analysis method and the method
will check the keywords from the database keyword library. When the keyword is
identified, it will implement different operations depending on the keyword category and
give corresponding response that follows the protocol. (See Table-2 from Appendix A)
 The database was created in MS SQL server and uploaded on windows azure cloud
through windows azure database manager, it defines the different keyword categories
depending on the functions, the keywords for each category and response for different
keywords category. (see Figure-10)
Figure-10
The database has been designed into eight tables, each table contain different information
for each category, the “Keywords”, “Language”, “Map”, “Weather”, “Weatherlocation”
tables is used for the application to identify the different command, “RobotCategories”,
“RobotKeywords”, “RobotResponse” table are used for the robot chat. The following
chapters describe each of the table and what is intended usage.
“Keywords” table: (see Figure-11)
Figure-11
INTELLIGENT VOICE ASSISTANT
24
The “keywords” table contains three columns to present the data, the “KeywordsID”
column is used to specify the different keyword in its unique ID, “KeywordsContent”
column is used to save the keyword info and the “KeywordsCategory” classify the
content into different category.
“Language” table: (see Figure-12)
Figure-12
The “Language” table is used to discern the language and translate it to objective
language code, the “languageID” column is used to specify the different language in its
unique ID, “languageDescription” is used to describe the language and the
“languageCode” is used to change the text-based language in to language code.
“Map” table: (see Figure-13)
Figure-13
The “Map” table is used to discern the user’s navigation proposes. The “MapID” is used
to specify the different info in its unique ID and the “Info” table is used to specify the
content.
“RobotCategories” table: (see Figure-14)
Figure-14
The “RobotCategories” table is used to discern the robot response category. The
“CategoryID” is used to specify the different category name in its unique ID and the
“CategoryName” column is used to specify the content in different case. 
INTELLIGENT VOICE ASSISTANT
25
“RobotKeywords” table: (see Figure-15)
Figure-15
The “RobotKeywords” table is used to discern the robot response category. The
“KeywordID” is used to specify the different keyword in its unique ID, the
“KeywordContent” column is used to give the response to the user in different case and
the “CategoryID” column is used to specify the content in different case based on the
“RobotCategories” table.
“RobotResponse” table: (see Figure-16)

Figure-16
The “RobotResponse” table is used to given the robot response depending on the request
category. The “ResponseID” is used to specify the different response in its unique ID,
the “CategoryID” column is used to give the response to the user into different case and
the “Response content” column is used to give the response content.
“Weather” table: (see Figure-17)

Figure-17
The “Weather” table is used to discern the robot response category. The
“KeywordCategory” is used to define the category of this content, the “TimeID” column
is used to give the unique number to each “Time” content and the “Time” column is
used to specify the time content.
INTELLIGENT VOICE ASSISTANT
26
“Weatherlocation” table: (see Figure-18)

Figure-18
• Detailed solutions and implementation for each function depend on the request categories.
0. Chat Mode: The program will get the captured text and send it to the cloud web
service, the cloud will loop over the robot chat keywords and identify the
keyword category; the response will be randomly accessed through the response
pool according to the keyword category, finally the program init the TextToSpeech
engine from the Android system and generate the audio output with the response.
[Code-0-1]
1. Chat Mode Switcher: the program will have a Boolean variable initiated to false.
If the chat mode is enabled, the variable will be assigned as true and anything
captured will be in the chat mode until the chat mode is finished. While the chat
mode is exited, it gets back to the normal mode and analyzes the requested
commands. [Code-1-1]
2. Location Service: The program will firstly distinguish the command in two
different ways; one is to find the current location, another one is find the routes
between the current location and the destination location. To find the current
location, the program will check the location information from the device GPS
Module and get the current Longitude and Latitude values, then start the
MapActivity by assign the pair values and the mode “current”, present the maps
for the user. To find the route to a specific destination, the program will also
check the current location and get the GEO values, generate the target location
name to an URL, read the GEO Information from the link [Code-2-1], with the GEO
info for both the origination and destination, the program will start the
MapActivity by assign the current location geo value and the remote location geo
value with mode “Remote”. The map activity will generate that information to an
URL and send to the Google map server, then get the route XML. And draw the
route on the map.
3. Weather: the program will firstly check the command whether it has the specific
city name, if the city name is obtained in the command, the program will send the
city name to the Google map server and get the corresponding geo information
with the longitude and latitude and set as a location to get the weather condition; 
INTELLIGENT VOICE ASSISTANT
27
otherwise the location will be the current location information from the mobile
GPS Module, if no city name is given, the program will generate an URL by the
location’s geo info, and get the corresponding weather condition XML from the
Google weather Server. The program will also check the data info from the cloud
response, if the user requires the weather for today, the program will present the
first weather condition from the XML, otherwise, it will get the next four days
conditions.[Code-3-1]
4. Wikipedia search: the program will replace the space in the search content to “+”
and formalize the searching URL, and then switch to the search activity by calling
ACTION_VIEW and give back the result as navigate to the previous obtained URL.
[Code-4-1]
5. Calling service: the program will extract the name section from the response
accessed from the cloud web service, then check through the contact list and get
all the stored contacts [Code-5-1], further fetch all the details of the person with
name, email, phone number [Code-5-2]. Identifying the person and get the first
phone number, and the system will make the phone call by calling the system
ACTION_CALL intent and start the calling activity. [Code-5-3]
6. SMS: the program will extract the name section and the message content from the
response accessed from the cloud web service, then check through the contact list
and get all the stored contacts [Code-5-1], further fetch all the details of the
person with name, email, phone number [Code-5-2]. Identifying the person and
get the first phone number, and the system will send the message by calling the
system ACTION_SENDTO intent and start the sending message activity. [Code-6-1]
7. Email: the program will extract the name section and the email content from the
response obtained from the cloud web service, then check through the contact list
and get all the stored contacts [Code-51], further fetch all the details of the person
with name, email, phone number [Code-52]. Identifying the person and get the
first email address, and the system will send the email by calling the system
ACTION_SEND intent and start the sending email activity. [Code-7-1]
8. Google Search: the program will replace the space in the search content to “+”
and formalize the searching URL, and then switch to the search activity by calling
ACTION_VIEW and give back the result as navigate to the previously obtained URL.
[Code-8-1]
9. Alarm: the program will extract the Hour and Minute parts from the response
obtained from the cloud web service, set a calendar with the requested time of
hour, minute and second. Then start the Alarm manager by calling the system 
INTELLIGENT VOICE ASSISTANT
28
ALARM_SERVICE with the settled calendar and broadcast. In addition, the broadcast
is a trigger to activated an alert and the alarm music will by played when the
alarm is activated by system action RTC_WAKEUP. [Code-9-1]
10. Music Player: When the program is loaded and initialized, it will call the system
ACTION_MEDIA_SCANNER_FINISHED to scan all the media files on the SD card
memory and save the file’s path, id, title, and put all these attributes into a
list[Code-10-1], the program will first extract the action command from the
response obtained from the cloud web service, if the command requires to playing
music, it will further check whether the response contain with the song’s name or
not, if the request does not have a specified name of the song, the program will
randomly pick a song from the list and start the music play service by given the
path of the requested song, otherwise, the song’s path will be obtained from the
list by the song’s name and start the music with start command[Code-10-2]. If the
response contains the pause command, the program will set the music service at a
pause state. As it is the same with pause, the stop command also will be sent in
this way and the music player will stop playing the music. [Code-10-3].
11. Event handler, the program will firstly extract the command part to decide if the
user wants to add or view or delete events. The event program will navigate to the
event activity with the requested command. The layout of the event activity is
designed through the XML file and different operations “Add/View/Delete” are
set on the interface. By extending SQLiteOpenHelper and SQLiteDatabase, the
events can be stored, and updated or deleted.
12. Camera: when the program receives the start camera command, it will start the
Camera activity, then init the Speech Recognizer on that activity. After the user
take photo by recognize the “Cheese” command and save the image into the SD
card memory, a broadcast will be triggered to notify the system’s gallery to
refresh the photos. After the photo has been taken and stored, the camera activity
is finished and give the image path back to main activity, and the main activity
will present the image to the user based on the image path from the given path,
the user also can touch on the preview image to view the image detail by start the
ImageViewActivity.
13. Help: the program will navigate from the current activity to the help activity while
the help menu is activated from the main option menu or by the detected
command. The help activity contains a list of items correspond to each different
function; they share the same outline with an icon, text explanation [Figure 13]. If
any image button is clicked, it will switch to the help content activity with the
corresponding name of the function. By getting the name of the function, the
content activity will fill its content with the icon, title, and the examples to tell 
INTELLIGENT VOICE ASSISTANT
29
how to work with the function. The layout of the activity mainly been constructed
with the TextView, ImageView, and ListView. [Code-13]
14. Translate: the program will get the target language code and the content text, then
generate the original language code, target language code and the content text to a
URL; start the URL and get the translate result from Bing, finally present the
result with the original text and the translated text for user.[Code-14]
15. Bluetooth headset support: when the user plug-in the Bluetooth headset the
system will send a broadcast to the program, the program will use a Bluetooth
receiver to receive this broadcast then enable the button for user to select if use
the Bluetooth or not.
INTELLIGENT VOICE ASSISTANT
30
3.2 Equipment/ Choice of Materials
This chapter indicates all the equipments of the hardware, software and developing platforms.
Apart from the equipments, the materials that used in developing the program are also showed in
API and reference.
Develop tools and environment: Java ™, JDK, Eclipse IDE, Android SDK, ADT Plugin, ADV,
and Plug-in for Eclipse, MySQL query browser, DB-Designer, Microsoft Visual Web Developer
2010 Express and Windows Azure Cloud Platform.
API and reference: Java API, Android API, Google API (Google Map, Google Weather),
Wikipedia API, SQL tutorial, UML reference, JSON, XML, WSDL, Cloud computing, multithreading techniques.
Software application on Android phone: Android Internet explorer, Google voice recognize, TTS
Service Extended, Alarm, Mobile phone calling services, text message serivces.
Support application: Adobe Photoshop CS5, StarUML, Meitu (Chinese).
Hardware support: Android phone [HTC/Samsung], PC, Bluetooth Headset.
Developing model: XP (Extreme programming) (specify model)
- Requirement Card (Requirement analysis and identification)
- Design Card (Implementation and construction of modules)
- Test Card (Black & White Box test on modules)
- Pair-programming (Code modification, optimization and Communication)
- Integration and Simplicity (Integrated modules)
- High-Level Test (Black & White Box test on system)
- System debug (Potential errors and possible bugs)
- Build Product & Revision control (Evaluation and developing history)
- Calculate velocity and efficiency
INTELLIGENT VOICE ASSISTANT
31
3.3 Problems and Solutions
During development (see Figure-6) we have encountered many problems while implementing
those functions. Selected core problems with their solutions are listed by the following section:
• Chat Mode VS Command Mode: When the user wants to chat with the robot, the program
will not distinguish the keyword in the statements, because the chat is random and every
sentence have higher possibility to contain a keyword that Mapping to a command, that will
cause the program confuse about the words and may give a false response.
Solution: The program has been designed in two modes: Chat Mode and Command Mode.
Both modes has different databases(explain), if the user want to chat with the robot, he or she
can say ”Chat mode enable” or “Let us chat” , that will lead the program enter the chat mode.
After entering the chat mode, every statement will be a chat request and a response will be
given until the user says “finish chat” or “end chat”. During the chat mode, the program will
give chat response for the command statements like “weather today” or “where am I”
instead of giving response to the weather/location functions, that will be much easier for the
program to distinguish the keywords.
• Location: there have been problems in getting the GEO info according to the given city name
when implementing the location service. Except getting the current location where the user is,
there should also be allowed to get the location by a city name. The direction must be
precisely given from the current location to the destination according to the given name.
Google Map Service is the solution to get the GEO info based on the city name. By
implementing the Google Map Service which is a free API, the GEO info and the route trace
from the current location to the destination can be accessed and clearly presented on the map.
• Weather data retrieving: When trying to design the keyword functions about the weather data
part, it was discovered that in the sentences “tomorrow” and “the day after tomorrow” it was
hard for the program to distinguish the actual data info in the statement. Since the statement
“the day after tomorrow” also contains the word “tomorrow”, the program may only capture
the word “tomorrow” and skip “the day after”. To solve this problem, the weather condition
will display the next 4 days’ weather in to an entity. When the program captures the word
“today”, it will only show the current weather condition, otherwise, the program will show
the forecast for next 4 days in an entity for all the other cases.
• Calling service: There has been a very fundamental problem when implementing the calling
service. The program cannot run properly with the expected function after finishing the
implementation of the coding. And it was always the same runtime problem when it was
tested and it was modified lots of times without any solutions.
INTELLIGENT VOICE ASSISTANT
32
The solution is found after the CONCAT explorer is opened, and developers can access each
entity of the running message and identify the problem. There has been found no calling
permission is allowed in this program and that is reason why the program gets crash while
trying to revoke the calling service. Access the manifest.xml file of the program and add
calling permission, then the program works as expected and calling service can be
successfully made.
• Alarm: The alarm was firstly implemented with a broadcast which will be trigged when the
time comes up, but after a carefully concern on the user-friendly design, the broadcast should
also have a alert as well to stop the alarm music which is implemented on other class [main
activity – since the system music player must be implemented in the activity which the
broadcast is not an activity] rather than the broadcast. Therefore, the problem was how to
trigger an event in another class.
Different solution has been tried as define the music player a static/ final static object which
can be directly fetched from the other classes, define methods as to get and set the different
variables between classes, and etc; all those solutions failed because the mismatch between
two classes, hence, the object might be null while they were sent to another class which
generated NULLPOINTEXCEPTION. The final solution which solved this problem was
using message handler. Send the message handler info to stop the alarm while the time is up
and the message handler will trigger the alert and actually stop the music.
• Music player: there have been problems of how to get the get, load and update the list of
music when doing the music player. Since the user might update the list of the music any
time as he/ she wants, the program should load the song list with updated info.
The solution is to implement a broadcast, while loading the list of the songs every time the
program is started, the broadcast will inform the broadcast receiver to scan and filter the
mobile phone SD card, then access all the music available and store with the info of each
song into a list for later use.
• Camera: The Android mobile may have the two cameras: front camera and the back camera.
The front camera is always used for self-shooting or video chat, this camera does not have
the autofocus function and that it is a low-definition device, the back camera always use for
shooting the landscapes, or Portraits. The program needs to be designed to have a function
for the use choose to switch the cameras. For this function required, the program has to use
the API in Android library but the front camera method only implement since API 10
(Android 2.3), and the program has build on API 8 (Android 2.2), in that API, the switch
camera method cannot be implement since we use API 8, so we decide to update the whole
program on API 10 to solve this problem.
INTELLIGENT VOICE ASSISTANT
33
Another part of the camera is about the voice record. At the beginning, this function was
designed to take a long range self-shooting, during the camera listening mode, it can
automatically record the speech about every3-5 seconds and then distinguish the statement
whether contain the keywords, after the word has been captured, the camera will
automatically capture the photo or do anther listening to the user. But during the testing, the
voice recognizer was not be able to enable the microphone to start a new listening after the
first recognition, so a button has been put on the screen to let the user to start a new listening
by pushing the button on the screen manually instead of automatically start a new listening
after each time.
After the photo has been taken, the photo will be saved into the SD-card memory, but the
Android’s system will not automatically update the photos into the galley. The system’s
galley only refreshes its source when the system starts. So there have to design a method to
broadcast a message to notify the system gallery to refresh its library on the SD-card when
the photo has been captured.
• Owning no equipment: it has been a long time problem for the development since having no
Android phone. Even the program can be write in Eclipse and test with the emulator, the
physical phone is needed for real-time test on the real phone; having no mobile phone, the
voice recognition cannot be test and there can only be text input manually if the program
need to be test. In addition, the school provided a Sony Ericsson phone with Android
operating system, but that phone was too old with a 2.0 Version which cannot implement this
program.
Thanks to WANG LINLIN who lends her HTC to the developers and the program was well
finished and test on the real phone. The mobile phone will be available to use until the
program is fully finished.
INTELLIGENT VOICE ASSISTANT
34
4 Results
4.1 Design
Figure-19
The Model and Flow Chart (see Figure-19) describes the develop process that include all the phases
in the software development life cycle. This chart is well illustrating how the project is carried out
and how the development was managed. The project started with the motivation and brain storm,
repeatedly implement in the developing life cycle until the system has been fully constructed.
- Brain storm, the project start with the ideas from the brain storm. Here the basic ideas and
design the primary concepts, prototype of the program have been obtained.
- While the ideas has been obtained, it has been analyzed which of them can be accomplished
and make sure the structure of the project.
- According to the requirements that had been identified, collected all the resources and useful
references from any channel, together with the programming skills and experiences, the
design items were pointed out.
- Implement each individual design item based on the planning, structure and references.
- Test each single module that has been implemented and fix the possible bugs appear in the
code implementation and make sure the functions are well constructed.
- Integrate all the individual sections to contribute to a complete system.
- Try the black and white box testing strategies to test the system, both the functional and nonfunctional logic and implementation should be verified.
INTELLIGENT VOICE ASSISTANT
35
- Debug the system and optimize the project from the possible aspects.
- Build the product and pack all the stuffs as a whole.
INTELLIGENT VOICE ASSISTANT
36
4.2 Functioning
The program should firstly be started on the Android phone; the initial mode of the program is Voice
mode since this program aims at making a voice assistant program. However, if there are users who
prefer to operate in text mode by inputting the text manually, the text mode is also available.
After the program has been started, the user should have correct voice input “command/request” to make
those functions work properly. And this program includes the functions and services of: calling services,
text message transformation, mail exchange, alarm, event handler, location services, music player
service, checking weather, Google searching engine, Wikipedia searching engine, robot chat, camera,
Bing translator, Bluetooth headset support, help menu. The details below explain how those functions
work and different possibilities while facing different commands.
 Calling service, the calling function allows the users to give a call to the person in the contacts.
By giving a correct command with the calling request to a stored person, the Android phone will
check the contact list and get the phone number of the person, then successfully direct to the
phone number found in the contacts.
 Text Message transformation, the text message transformation enable customers able to send the
SMS to the person in the contacts. By giving a correct command contains the request keyword to
send SMS together with the destination person; the program will navigate to the sending message
function on the mobile phone with the phone number, message content. The message will be sent
to the destination immediately if the user selects to send it with the correct content.
 Mail exchange, customers are able to send the mail to the person with mail address in the
contacts. By giving a correct command contains the mail request keyword together with the
destination person; the program will switch to the sending mail function on the mobile phone
with the mail address and mail content. If the content is correctly detected, the mail will be
received by the recipient after the user selects to send the mail, otherwise the user can modify the
mail content if the voice recognition is not well detect the mail content.
 Alarm, as a basic function on the mobile phone, the user could simply set the alarm through the
command with the setting alarm keyword and a specific valid time. When the alarm request and
time are detected, the program will set the alarm to the given time with dedicated hour, minute
and second; when the time comes up, the alarm will be trigged with a alarm bell and an alert
notification which the user can choose to stop the alarm, otherwise the alarm will keep working
and the song will always be playing.
 Event handler, the application allows the user to set as many events as they want. Customers set
the events with the content and title, the program switch to the event handler interface with the
content and the title, and the event will be stored immediately if the user ensure the event. With 
INTELLIGENT VOICE ASSISTANT
37
the stored events, the event handler makes the events available for the user to check all events,
check one event, modify the selected event and delete all events.
 Location services, location services works in two categories depending on the request.
If it has been required to present the current location of the user, the location services check the
GEO info by using the Google Map Service and give back the result as a map with the current
location.
If it has been required to provide the route trace from the current position to a specific city, the
location service check the GEO info of both the origination and the destination, and provides the
direction on the map with a route indicating how to get to the destination from the origination.
 Music player service, the music player offers the services to the user to play a named or random
song in the pre-stored song list depending on the request.
The music player service will play the specific song according to the name given by the user, the
music player check the music list and identify the song, then presenting to the user.
The music player service will play a randomly picked song through the list if the user doesn’t
provide the song that he or she wants. The music player traces through the music list and get one
from it for playing to the user.
The music player could be also be stopped or paused while it is playing a song. By giving the
correct commands, the working music player will be paused or stop playing.
 Checking weather, weather service provides the user the weather condition in different city on
different dates. This service works in the same logic and gives back different result depending
on the requested date and city.
The weather service return the current date weather condition of the current location with the
humidity, wind speed, temperature scope and display in a formalized entity which can be easily
read by the user if the local weather for current date weather is required.
The weather service return the next four days' weather condition of the current location with the
date, wind speed, temperature scope and display in a formalized entity which can be easily read
by the user if local weather for other dates except today’s weather is required.
The weather service return the current date weather condition of the given city with the humidity,
wind speed, temperature scope and display in a formalized entity which can be easily read by the
user if weather for current date weather for the given city is required.
The weather service return the next four days’ weather condition of the given city with the date,
wind speed, temperature scope and display in a formalized entity which can be easily read by the
user if weather for next for days of the given city is required.
INTELLIGENT VOICE ASSISTANT
38
 Google searching engine, the search engine enable the use to search anything on Google. By
detecting the search keyword and search request, the Google search engine will returns the result
list displayed on the browser on the mobile phone.
 Wikipedia searching engine, the search engine enable the use to search anything on Wikipedia.
By detecting the search keyword and search request, the Wikipedia search engine will returns the
Wikipedia result displayed on the browser on the mobile phone.
 Robot chat, the robot chat enables the user to chat with the Android phone to have fun. The chat
mode is initially closed and will be required to activate it with the corresponding command.
After entering the chat mode, a text response will given by the mobile phone whenever the user
speaks to it; the response, however, were predefined and stored in the database. For each request,
the program will define the request category and randomly pick a response from the response
pool depending on the request category.
 Camera, the camera function enables the user to capture the current view with the camera on the
mobile phone. When the camera is activated by the user, the user can selects to use the front or
back camera on the mobile phone manually, and the picture will be taken by the camera if the
user selects to photograph the current view, an instant picture for previously taken will be
displayed in the program for viewing as a entity, and the picture will be stored in the Gallery for
later checking.
 Bing translator, the translator will provide the user both the original text and the translated text
depending on the objective language the user given. The user gives the original text and the
object language the he wants; then the translator will give the result back of a translated text
based on the original text and required language. Meanwhile, there have been 25 object
languages stored in the database which the user can enjoy and the original text should be in
English to use the translate function.
 Bluetooth headset support, the Bluetooth headset support makes the program well work
especially the phone is playing music or the surrounding is noise which affect the voice
recognition. Since it is not possible to do the voice recognition while the music player is playing,
the Bluetooth will be loaded and available to the user, the user can select to turn on or turn off
the Bluetooth function, and the Bluetooth headset support makes it possible to speak to the
headset rather than the mobile phone if the Bluetooth is enabled.
 Help menu, the help menu provides the user a help list to each function in this program. The user
can choose the help menu manually or over the voice if the user doesn’t know how to work with
the functions. While the help menu is opened, the help menu gives the examples and explanation
of how to work with different functions, the examples clearly show how to work with the
function and the user can simply imitate the example to work with different functions. 
INTELLIGENT VOICE ASSISTANT
39
4.3 Operation and Maintenance
Operation
 Calling Service: If the user wants to consume the calling service, he or she must have a
command contains a valid name the calling keyword like “call”, ”make a phone”, then the call
will be made if the person is found in the contacts. There are different ways to make a phone call,
the list below shows the correct command to use the calling service.
“Call Tom”, make a phone call to tom. The program will first capture the key words “call”, and
then the program will continue to capture the person’s name “Tom” after the word “call”, then
get all the contacts on the mobile and compare them one by one, if “Tom” is equal to the name
that the user is give in the command, the phone call will be made to “Tom”.
“I want to give a call to Lucy”, make a phone call to Lucy. The program will capture the
command keyword “call” and the name “Lucy” and make a phone call to Lucy.
 Text Message Transfer: If the user wants to use the application to send the text message, he or
she must have a command with the SMS message keyword and a valid name, then the message
will be send if the person is found in the contacts. They are different forms to send the message;
the list below shows the correct command can do the message sending.
“Send a message to LiLei Let's dinner together”, send a message to LiLei with the content “Let’s
dinner together”, the program will capture the keyword “message” and the content “let’s dinner
together”, then the program will check the mobile contacts and get the first phone number
corresponding to “LiLei” and send the message to LiLei.
“SMS Hui Nihao”, send a message to Hui with the content “Nihao”.
 Mail exchange: The user can send an email to the person in his contacts and with person’s email
address. He or she must have a command with the email keyword like “Mail”, “Post” and a valid
name; the email will be send if the person is found in the contacts. They are different forms to
send the message; the list below shows the correct command can do the email sending.
“Mail Bellis it will rain today”, send an email to Bellis the content “it will rain today”, the
program will capture the keyword “Mail” and the content “it will rain today”, and then the
program will check the mobile contacts and get the email address corresponding to “Bellis” and
send the message to “Bellis”.
“Post Mimy a boy is waiting for you” send an email to “Mimy” with the content “a boy is
waiting for you”
INTELLIGENT VOICE ASSISTANT
40
 Alarm: The user can use the set alarm command to set an alarm at the corresponding time. When
the time is up, the alarm will be activated and play the sound; meanwhile, an alert will be
presented for the user to stop the alarm.
“"Set alarm to 10” the alarm will be set at 10 o’clock. The program will capture the setting
command “Set alarm” and get the time command “10” and then the alarm will be active at
10AM.
“Make time to 11:50” the alarm will be set at 11:50. The program will capture the command
“Make time” and the time “11:50”, the alarm will be wake up at 11:50.
 Event handler: The application can allow the user set many events. He or she can set many
events and be saved into the application’s database by using the add event command, also he or
she can view the event or delete the event by corresponding keywords like “Set up”, “make up”,
“View one/all event(s)”, “Delete”. The list below shows the correct command can do the
operation.
 Add Event:
“Set up a meeting at 10”, the Program will first capture the keyword “set up” then the title of the
event “a meeting” and the content “a meeting at 10”, then the event activity will be start with the
add event dialog, automatically fill with the title “a meeting” and content “a meeting at 10”.
Then the user should to choose the date time and add the event.
 View Event(s)
“View all/one event(s)” / “Find event”, the Program will start the event activity and present the
event(s) based on the user choose to show the all events or one event. If the user chooses to show
one event, the data picker will be shows up and the user can choose the event that he or she
wants to present based on the date, otherwise, the application will show up all the events if the
user wants to check all.
Delete Events
“Delete all events”, the Program will delete all the events that in the application’s database.
 Location services: The user can use this service to locate the user’s position or get the routes to
the destination by giving the city name. There are different ways to locate the position or
navigate to a specific city. The use must use the keywords “where” and “I” or “my location” to
let the application to know he or she wants to locate the current position. And the keywords “go
to” and the name of the place to get the route to the destination.
INTELLIGENT VOICE ASSISTANT
41
Locate position
“Where am I” / “Show my current location”, the program will present the current location of the
user on the map.
Navigation
“How can I go to Lund” / “Navigation to Lund”, the program will present the routes to “Lund”
on the map with the highlighted route from the current location to Lund.
 Music player service, the user can use this application to play songs, his or her command must
contain keyword “play”. If the user wants to play the specific song, he or she should also say the
name of the song after “play”, and the song should be exist in the SD-card memory. Or if the
user wants to play a random song, he or she just needs to say “a song” instead of the song’s name.
During the playing, the user can pause or stop the song by giving the command “pause” or “stop”.
 Play
“Play Canon”, the program will play the song “Canon”
“Play a song for me”, the program will randomly pick a song from the library and play it.
 Pause
“Pause playing music”, the song will be paused immediately.
 Stop
“Stop music player”, the song will be stopped immediately.
 Checking weather: the user can use the application to check the weather for recent days in local
place or specific location. He or she should say the keyword “weather”, then the user should
notify the date that should be presented as “today/tomorrow/the day after tomorrow” if he or she
wants to get the information about the other days otherwise the application will default set the
date as today, and the user can also can choose to tell about the place name “in Malmo”, the
application will check the weather belong to that place, otherwise the place will be set as locally.
 Weather check today:
“What's the weather for today”, the current weather condition for local place will be show.
“What's the weather in Malmo”, the current weather condition for Malmo will be show.
 Weather check other days:
“What's the weather next few days”, the forecast in next 4 days will be show. 
INTELLIGENT VOICE ASSISTANT
42
“What's the weather next few days in Malmo”, the forecast for Malmo in next 4 days will be
show.
 Google searching engine, the Google search engine is activated by the user commands which
contain ‘Google’ or ‘Search’. By detecting the search keyword and search request, the Google
search engine will returns the search result displayed on the browser on the mobile phone.
“Google China”, the keyword ‘Google’ is detected and the result will be presented on the web
browser by searching ‘China’ on Google.
“Try to Google Java API”, the user can have the keyword Google in the middle of a request and
the result of searching ‘Java API’ on Google will be displayed on the web browser.
“Search for apple”, the user can also use the keyword ‘search’ to do the Google search, this
command will have the result of searching ‘apple’ on Google.
 Wikipedia searching engine, whenever the user wants to search any content in Wikipedia, it is
possible to do in this program by having a command contain the keyword ‘define’. If ‘define’ is
detected by the program, the program will automatically give the result by search the content
after ‘define’ in Wikipedia.
“Define Android”, the keyword ‘define’ is detected, and the program will return the result by
searching ‘Android’ on Wikipedia.
“Define true love”, the keyword ‘define’ is detected, and the program will return the result by
search the content after ‘define’, which is ‘true love’ on Wikipedia.
 Robot chat, the robot chat will work only after the chat mode is enabled which can be done with
a command that contains keyword ‘chat’. After the chat mode is enabled, a response will be
given every time when the user gives a request. The chat can be finished by the user commands
contain the keywords of ‘finish/ disable/ end/ complete chat’.
“Enable chat”, the keyword ‘chat’ will be detected and the chat mode will be enabled. Now the
user can enjoy the chat by inputting any text he /she wants.
“Let’s chat”, the keyword ‘chat’ will be detected and the chat mode will be enabled. Now the
user can enjoy the chat by inputting any text he /she wants.
“Finish chat”, the keyword ‘finish chat’ is detected and the chat mode will be disabled. When
the user exits the chat mode, the program gets back the normal mode to receive and analyze the
commands, and give correct response.
INTELLIGENT VOICE ASSISTANT
43
 Camera, the camera is started while the keyword ‘camera’ is detected. Therefore, the user who
wants to operate with the camera will have to give a command with camera inside. After camera
is started by the correct command, the camera itself will guide the user how to take photograph.
“Open the camera”, as the keyword ‘camera’ is detected, the camera is started. And the user can
work with the camera by clicking the different selection on the mobile phone.
“Start the camera”, as the keyword ‘camera’ is detected, the camera is started. And the user can
work with the camera by clicking the different selection on the mobile phone.
“I want to use the camera”, as the keyword ‘camera’ is detected, the camera is started. And the
user can work with the camera by clicking the different selection on the mobile phone.
 Bing translator, the user should have the keyword ‘translate’ / ‘how to say’ as the keywords to
define this is a translate request, and ‘in’ as keyword to indicate the objective language. As the
user have the command contains these keywords, the translator will return the result with the text
in the objective language.
“Translate I love you in Chinese”, as ‘translate’ and ‘in’ are detected by the program, the
program will call the translator with ‘I love you’ as the original text and Chinese as the objective
language, the result will be the Chinese words of ‘I love you’.
“How to say hello in Swedish”, as ‘how to say’ and ‘in’ are detected by the program, the
program will activate the translator with ‘hello’ as the original text and Swedish as the objective
language, the result will be the Swedish text of ‘hello’.
 Bluetooth headset support, the Bluetooth headset support will be enabled when the program is
loaded. The user should firstly turn on the Bluetooth in the setting of the mobile phone, and the
Bluetooth icon will be valid in the program after executing the program. The user will be
required to plug in the Bluetooth headset and turn on /off it manually by clicking on the
Bluetooth icon.
 Help menu, the help menu can be activated by manually select on the option menu or through the
command. The commands should have ‘help’ as the keyword contained, then the help menu will
be activated and the help menu provides the list of all functions with their explanation and
examples to use it.
“I want to check the help menu”, if the users have the keyword ‘help’ contained in the command,
it will be detected as a keyword and the help menu will be returned with a list of the functions,
the functions are presented in two pages and user can scroll the pages by slipping the touch pad
of the mobile phone; by selecting on each of the functions, the user can enjoy the details of the
explanation and the examples of each function. 
INTELLIGENT VOICE ASSISTANT
44
Maintenance
After the program is completed, the program still needs long term maintenance to make it
available and stable to execute. The program will be test after a certain period of time and debug
each of the function and possible bugs, whenever a potential bug is detected; the program needs
to be refined to a better design. Meanwhile, there will update and add more data to the database
to increase the database capacity. Depending on the new keywords, responses, relevant data
found that could be applied in this program; the database will always be improved and can
handle more and more cases.
INTELLIGENT VOICE ASSISTANT
45
5 Conclusions
- Project development and implementation
As it has been previous stated, the program is mainly concerns with the techniques of Android
development, Java programming, Database management, Cloud computing, different APIs for
Google products, Bing translate and etc. The program is developed by two developers and
follows the extreme programming model. During the eight weeks development, the developers
did the same cycle in each phase of analyze requirements, construct design, implement the
solutions in pair programming mode and test the result. The development is carried out as its
primary planning which guide the work process of how to work with the program, how much
time should the each of the developers spent in every week, the rescores needed for developing
and how to handle the problems while it came up. The project was efficiently completed under
the development model and the resources we found in early time were really useful when
implementing the program.
- Project usage & prospect, potential
The project is very useful and owns a large potential use in different industries. Although the
program primary concerns more about how to do the personal assistant on Android phone using
the voice, the concept of voice recognition can be applied in different industries as in many
situations it will be more convenient, save a lot of time and helpful especially for those who have
difficulty in working with manual operations. Thus, the concept is only for programming the
Android application.
For the program itself, it is a collection of 15 functions that are frequently used on a mobile
phone. The user can enjoy different services within this platform. Therefore, it is easy to use with
simple operation compared with the traditional working strategies which the user should well
know how to work with the mobile phone.
In addition, the program which works using the voice is helpful for those who prefer voice
operation and those who have difficulty /disability with the manual operations. The primary
objective of the program is to provide services using the voice, and it enables more people who
can enjoy this program.
The prospect of the program can be more applications or products developed using the voice
control, and it could in some sense change the working forms that is totally different from the
traditional form. As people can easily operate and have a lot of fun from it, it owns an
enlightened prospect as SIRI succeed in attracting people in the market.
INTELLIGENT VOICE ASSISTANT
46
INTELLIGENT VOICE ASSISTANT
47
- Project experience & teamwork
Apart from the program, we as the developers have improved a lot from the degree project. It is
quite different from what we previously experienced in the working model, volume of tasks, and
the problems we have encountered. In conclusion, we have been improved a lot from the project
development, and gained development experience as well as programming skills; the most
important is work as a team for a long term, challenge development.
INTELLIGENT VOICE ASSISTANT
48
6 Recommendations for Further Work
6.1 Design Improvements
No program has a perfect design without any flaws; it is the same here in this program. Even
though the program is completed with all the primary functions implemented and work properly,
there are still many things that can be done with this program. As the future improvement, the
potential work that can be implemented ranging from adding more functions to offering the user
a more comprehensive, convenient program, refining the logic to make the program more
humanized and easy to use, increase the database capacity and add more possible keywords,
responses and data in this program, interface optimization and etc.
6.2 Additional Functions
Add more functions: although there have been 15 normal functions that are used really often
with the mobile phone, there can be more functions which simplify our daily life and make it
convenient to use. Functions as playing movies, checking stocks, exchange rate, downloading
and uploading, installing APPs and etc, these can be the potential functions that make the
program more comprehensive and people can enjoy more services in this program.
6.3 Database Capacity
Add database capacity and more humanized logical design; the program has a predefined logic to
make it work with the corresponding commands. Thus, the user need to follow the structure of
the commands, contain the dedicated keywords and well formalize the commands to work with
each of the functions. In other words, the program is limited by the database capacity and no
solution will be found if the user gives commands that are not readable by the program. Even if
two commands have the same meaning and should get exactly same result set, the result might
be that of one is working and the other one fails. Hence, the program is to some extent limited by
the vocabulary and can be further optimized. 
INTELLIGENT VOICE ASSISTANT
49
6.4 Humanized Voice Recognition
The more humanized the program is, more easier the user can use it. People should accept that
even if developers constantly try to add more predefined commands, more responses to it,
analyze and respond to the command more intelligently, the program will never be completely
comprehensive and contain all the possible circumstances that the users meets. Nevertheless, the
program will certainly be improved and be more user-friendly if there can be more readable
commands, more humanized structure and more intelligent response.
6.5 Improved Interface
Interface optimization, the interface can be further improved to make it nice to the users.
Currently the interface design meets the basic requirement to present everything for this program,
and the users are able to interact with the program through this interface, but the interface can
always be optimized and more suitable constructed.
INTELLIGENT VOICE ASSISTANT
50
7 References
7.1 List of References
 [1] http://en.wikipedia.org/wiki/Siri_(software)
 [2] http://en.wikipedia.org/wiki/Smartphone
 [3] http://yudian.voicecloud.cn/
 [4] http://en.wikipedia.org/wiki/Extreme_programming
 [5] http://en.wikipedia.org/wiki/Cloud_computing
 [6] http://en.wikipedia.org/wiki/Extreme_programming
 [7] http://en.wikipedia.org/wiki/Java_programming
 [8] http://docs.oracle.com/javase/6/docs/api/
 [9] http://developer.Android.com/index.html
 [10] http://developer.Android.com/reference/packages.html
 [11] http://developer.Android.com/guide/index.html
 [12] http://www.microsoft.com/sqlserver/en/us/product-info/overview-capabilities.aspx
 [13] http://www.mysql.com/why-mysql/
 [14] http://www.windowsazure.com/en-us/home/features/sql-azure/
 [15] https://www.windowsazure.com/en-us/develop/net/fundamentals/intro-to-windowsazure/#cloud
 [16] http://en.wikipedia.org/wiki/Web_Services_Description_Language
INTELLIGENT VOICE ASSISTANT
51
8 Appendix A Figure
Request Request
category Response Response code
Chat
0
Chat “0|1|Content”
Disable “0|0”
1
Enable “1|1”
Disable “1|0”
Location Service 2
Location “2|1”
Direction “2|2|Destination City Name”
Weather 3
Local & today “3|1|0”
Local & other day “3|2|0”
Remote & today “3|1|1|City Name”
Remote & other day “3|2|1|City Name”
Wikipedia 4 Definition “4|Content”
Calling Service 5 Make phone call “5|Receiver’s name”
SMS 6 Send message “6|Receiver’s name| Content”
Email 7 Send email “7|Receiver’s name| Content”
Google 8 Search engine “8|Content”
Alarm 9 Set alarm “9|Hour|Minute”
Music player 10
Start & Random Song “10|1|000”
Start & Given Song “10|1|Song name”
Pause “10|2”
Stop “10|3”
INTELLIGENT VOICE ASSISTANT
52
Event 11
Add an event “11|1|title|Content”
View one event “11|2”
View all events “11|3”
Delete all events “11|4”
Camera 12 Start camera “12|1”
Help 13 Help Menu “13|1”
Translate 14 Translate content “14| target language code|
Content”
Table-2
INTELLIGENT VOICE ASSISTANT
53
9 Appendix B Code
Code-0-1
case 0:
int state = Integer.parseInt(getSecondInfo(response));
switch (state) {
case 1:
chat = true;
persendInfo("he", getThirdInfo(response));
break;
case 0:
chat = false;
persendInfo("he", DefaultResponse.getChatFinishSpeak());
break;
}
break;
Code-1-1
case 1:// robot
switch (Integer.parseInt(getSecondInfo(response))) {
case 1:
chat = true;
persendInfo("he", DefaultResponse.getChatSuccessSpeak());
break;
case 0:
chat = false;
persendInfo("he",DefaultResponse.getChatFinishSpeak());
break;
}
break;
Code-2-1
public Geo(String location)
 {
 String url = "http://maps.google.com/maps/geo?q="+location+"&output=csv";
 try
 {
 DefaultHttpClient client = new DefaultHttpClient();
 HttpUriRequest request = new HttpGet(url);
 HttpResponse Response = client.execute(request);
 HttpEntity Entity = Response.getEntity();
 InputStream stream = Entity.getContent();
 DataInputStream ds = new DataInputStream(stream);

 String toLine= ds.readLine();
 String geos[] = toLine.split(",");
 this._latitude = geos[2];
INTELLIGENT VOICE ASSISTANT
54
 this._longtitude = geos[3];
 Log.v("Message", toLine);
 }
 catch (Exception ex)
 {
 System.out.println(ex.toString());
 }
}
Code-3-1
case 3:// weather
if (getThirdInfo(response).equals("0")) {// local
gw = new GoogleWeather(getLatitude(), getLongtitude());
}
if (getThirdInfo(response).equals("1")) {// other place
String cityName = getFourthInfo(response);
geo = new Geo(cityName);
gw = new GoogleWeather(Double.parseDouble(geo
.get_latitude()), Double.parseDouble(geo
.get_longtitude()));
}
switch (Integer.parseInt(getSecondInfo(response))) {
default: // local today weather
persendInfo("he","Here's the forecast for recent days:");
ww = gw.getWeatherWeek();
DetailEntity d2 = ww;
list.add(d2);
break;
case 1: // local weather for recent days
persendInfo("he", "Here's the weather for today:");
dw=gw.getWeatherDetail(String.valueOf(getSecondInfo(response)));
DetailEntity d3 = dw;
list.add(d3);
break;
}
break;
Code-4-1
case 4:// WikiPedia
String wikiWords = getSecondInfo(response);
persendInfo("he", "Searching for wikipedia");
Uri myBlogUri = Uri.parse("http://www.wikipedia.org/searchredirect.php?search="+wikiWords+"&language=en&go=++→ "+ "++&go=Go");
Intent returnwikiIt = new Intent(Intent.ACTION_VIEW, myBlogUri);
startActivity(returnwikiIt);
break;
Code-5-1
INTELLIGENT VOICE ASSISTANT
55
public List<Person> getPerson(Context context)
{
Uri uri=ContactsContract.Data.CONTENT_URI;
Cursor cursor=context.getContentResolver().query(uri, null, null, null,
"display_name");
cursor.moveToFirst();
 List<Person> list=new ArrayList<Person>();
 int Index_CONTACT_ID = cursor.getColumnIndex(ContactsContract.Data.CONTACT_ID);
 int Index_DATA1 = cursor.getColumnIndex(ContactsContract.Data.DATA1);
 int Index_MIMETYPE = cursor.getColumnIndex(ContactsContract.Data.MIMETYPE);
 while(cursor.getCount()>cursor.getPosition())
 {
 Person person = null;
 String id=cursor.getString(Index_CONTACT_ID);
 String info=cursor.getString(Index_DATA1);
 String mimeType=cursor.getString(Index_MIMETYPE);

 for(int n = 0; n<list.size(); n++)
 {
 if(list.get(n).getID() != null)
 {
 if(list.get(n).getID().equals(id))
 {
 person = list.get(n);
 break;
 }
 }
 }
Code-5-2
 if(person == null)
 {
 person=new Person();
 person.setID(id);
 list.add(person);
 }
 if(mimeType.equals("vnd.Android.cursor.item/email_v2"))
 {
 person.setEmail(info);
 }
 else if(mimeType.equals("vnd.Android.cursor.item/postal-address_v2"))
 {
 person.setAddress(info);
 }
 else if(mimeType.equals("vnd.Android.cursor.item/phone_v2"))
 {
 person.addPhone(info);
 }
 else if(mimeType.equals("vnd.Android.cursor.item/name"))
 {
 person.setName(info);
 }
 cursor.moveToNext();
 }
INTELLIGENT VOICE ASSISTANT
56
return list;
}
Code-5-3
case 5:// call
personList = getContacts.getPerson(MainActivity.this);
String callName = getName(response);
if (isNameFound(callName, personList)) {
String tele = getTele(callName, personList);
if (!tele.equals("0")) {
persendInfo("he", "Calling to " + callName + ".");
Intent myIntentDial = new Intent(Intent.ACTION_CALL,
Uri.parse("tel:" + tele));
startActivity(myIntentDial);
} else {
persendInfo("he", "Sorry, no telephone exist!");
}
} else {
persendInfo("he",
"Sorry, no person is found by the given name!");
}
break;
Code-6-1
case 6:// send SMS
String smsName = getSecondInfo(response);
String smsContent = getThirdInfo(response);
if (smsName != null) {
personList = getContacts.getPerson(MainActivity.this);
if (isNameFound(smsName, personList)) {
String tele = getTele(smsName, personList);
if (!tele.equals("0")) {
persendInfo("he", "Sending message to " + smsName);
Log.v("tele", tele);
Intent smsreturnIt = new Intent();
smsreturnIt.setAction(Intent.ACTION_SENDTO);
smsreturnIt.setData(Uri.parse("smsto:" + tele));
smsreturnIt.putExtra("sms_body", smsContent);
startActivity(smsreturnIt)
} else {
persendInfo("he", "Sorry, no telephone exist!");
}
} else {
persendInfo("he","Sorry, no person is found by the given name!");
}
}
break;
INTELLIGENT VOICE ASSISTANT
57
Code-7-1
case 7:// send Email
personList = getContacts.getPerson(MainActivity.this);
String mailReceiver = getSecondInfo(response);
String mailBody = getThirdInfo(response);
if (isNameFound(mailReceiver, personList)) {
String mailAddress = getMailAddress(mailReceiver,personList);
if (!mailAddress.equals("0")) {
persendInfo("he", "Sending email to " + mailReceiver
+ ".");
Intent intent = new Intent(
Android.content.Intent.ACTION_SEND);
intent.setType("plain/text");
intent.putExtra(Android.content.Intent.EXTRA_EMAIL,
mailReceiver);
intent.putExtra(Android.content.Intent.EXTRA_TEXT,
mailBody);
startActivity(Intent.createChooser(intent,
"Choose Email Client"));
} else {
persendInfo("he", "Sorry, no mail box exist!");
}
} else {
persendInfo("he","Sorry, no person is found by the given name!");
}
break;
Code-8-1
case 8:// google search
String googlWords = getSecondInfo(response);
persendInfo("he", "Searching for google.");
Uri searchUri = Uri
.parse("http://www.google.com/search?hl=en&site=&source=hp&q="
+ googlWords + "&oq=" + googlWords);
Intent returnIt = new Intent(Intent.ACTION_VIEW, searchUri);
startActivity(returnIt);
break;
Code-9-1
case 9:
Calendar calendar = Calendar.getInstance();
int hourOfDay = Integer.parseInt(getSecondInfo(response));
int minute = Integer.parseInt(getThirdInfo(response));
calendar.setTimeInMillis(System.currentTimeMillis());
calendar.set(Calendar.HOUR_OF_DAY, hourOfDay);
calendar.set(Calendar.MINUTE, minute);
calendar.set(Calendar.SECOND, 0);
calendar.set(Calendar.MILLISECOND, 0);
Intent intentAlarm = new Intent(MainActivity.this,
AlarmReceiver.class);
PendingIntent pendingIntent = PendingIntent.getBroadcast(
INTELLIGENT VOICE ASSISTANT
58
MainActivity.this, 0, intentAlarm, 0);
AlarmManager am;
am = (AlarmManager) getSystemService(Context.ALARM_SERVICE);
am.set(AlarmManager.RTC_WAKEUP, calendar.getTimeInMillis(),
pendingIntent);
persendInfo("he", "Set up clock at " + hourOfDay + ":" + minute
+ " .");
break;
Code-10-1
}else if(Intent.ACTION_MEDIA_SCANNER_FINISHED.equals(action)){
Cursor c2 = context.getContentResolver()
.query(MediaStore.Audio.Media.EXTERNAL_CONTENT_URI,
new String[]{MediaStore.Audio.Media.TITLE,
MediaStore.Audio.Media.DURATION,
MediaStore.Audio.Media.ARTIST,
MediaStore.Audio.Media._ID,
MediaStore.Audio.Media.DISPLAY_NAME },
null, null, null);
count2 = c2.getCount();
count = count2-count1;
c = context.getContentResolver()
.query(MediaStore.Audio.Media.EXTERNAL_CONTENT_URI,
new String[]{MediaStore.Audio.Media.TITLE,
MediaStore.Audio.Media.DURATION,
MediaStore.Audio.Media.ARTIST,
MediaStore.Audio.Media._ID,
MediaStore.Audio.Media.DISPLAY_NAME,
MediaStore.Audio.Media.DATA},
null, null, null);
 if (c==null || c.getCount()==0){
 System.out.println("No music in the library!");
 }
 c.moveToFirst();
 ids = new int[c.getCount()];
 titles = new String[c.getCount()];
 path = new String[c.getCount()];
 for(int i=0;i<c.getCount();i++){
 ids[i] = c.getInt(3);
 titles[i] = c.getString(0);
 path[i] = c.getString(5).substring(4);
 c.moveToNext();
 }
 isDone= true;
}
INTELLIGENT VOICE ASSISTANT
59
Code-10-2
case 1:// play song
String songName = getThirdInfo(response);
int songIds[] = scanSdReceiver.getIds();
Intent intentMusic = new Intent();
intentMusic.putExtra("_ids", songIds);
int position = 0;
if (!songName.equals("000")) {
position = nameToId(songName,
scanSdReceiver.getTitles(),
scanSdReceiver.getIds());
} else {
Random r = new Random();
position = r.nextInt(songIds.length);
songName = idToName(position,
scanSdReceiver.getTitles());
persendInfo("he",
DefaultResponse.playSongReponse(songName));
}
if (position != -1) {
intentMusic.putExtra("position", position);
intentMusic.putExtra("op", 1);
intentMusic.setAction("com.Android.MusicService");
startService(intentMusic);
persendInfo("he",
"Playing song "+ songName +".");
Log.v("Music", "Play song :" + songName
+ ", position: " + position);
} else {
persendInfo("he",
"Sorry, I can't find the song on your device.");
}
break;
Code-10-3
case 2:
Intent intent1 = new Intent();
intent1.setAction("com.Android.MusicService");
intent1.putExtra("op", 2);
startService(intent1);
Log.v("Music", "pause song");
break;
case 3:
Intent intent2 = new Intent();
intent2.setAction("com.Android.MusicService");
intent2.putExtra("op", 3);
startService(intent2);
Log.v("Music", "Stop song");
break;
INTELLIGENT VOICE ASSISTANT
60
Code-13
case 13:
Intent in = new Intent();
in.setClass(MainActivity.this, HelpActivity.class);
startActivity(in);
break;
Code-14
case 14:
String languagecode = getSecondInfo(response);
String text = getThirdInfo(response);
persendInfo("he", DefaultResponse.getTranslateSuccessSpeak());
Translator ts = new Translator(text,languagecode);
DetailTranslate dt = new
DetailTranslate(languagecode,ts.getTranslateResult(),
text,R.layout.translate);
list.add(dt);
break;A PROJECT REPORT
ON
JARVIS: The Personal Linux
Assistant
Submitted in the partial fulfilment of award of
BACHELOR OF TECHNOLOGY
Degree In
Computer Science and Engineering
Submitted To:
Mr Manoranjan Panda
Submitted By:
Harkishen Singh
Muskan Khedia
Jayashree Panda
Subham Mishra
Ankit Singh
DECLARATION
We do hereby declare that the report entitled “Jarvis-Personal-Assistant”
submitted by us to College of Engineering and Technology, Bhubaneswar in
partial of the requirement for the award of the degree of B.TECH in
COMPUTER SCIENCE AND ENGINEERING is a record of bonafide project
work carried out by us under the guidance of Mr Manoranjan Panda and
Department of Computer Science and Engineering.
Place: Bhubaneswar Harkishen Singh
Date: Muskan Khedia
Jayashree Panda
Subham Mishra
Ankit Singh
1
CERTIFICATE
This is to certify that the project entitled “Jarvis: Personal Assistant” is a
bonafide work done by Mr. Harkishen Singh (1701106073), Ms. Muskan Khedia
(1701106115), Ms. Jayashree Panda (1701106130), Mr. Subham Mishra
(1701106099), and Mr. Ankit Singh (1701106084) of 4th Semester B.Tech in
Computer Science and Engineering from College Of Engineering and
Technology, Bhubaneswar under the guidance of Mr. Manoranjan Panda in the
partial fulfilment of the requirement of the award for the Degree of B.TECH. in
COMPUTER SCIENCE AND ENGINEERING in College of Engineering and
Technology, Bhubaneswar.
Project Guide:
Mr. Manoranjan Panda
Department Of Computer
Science and Engineering
Place - Bhubaneswar
Date -
External:
(Head of the Department)
2
ACKNOWLEDGEMENT
We had a great experience working on this project and we got to learn a plethora
of new skills through this project. However, it would not have been possible
without the kind support and help of many individuals. We would like to extend
our sincere thanks to all of them. We are highly indebted to the teachers and
especially Mr Manoranjan Panda for their guidance and constant
supervision as well as providing necessary information regarding the project
and also for their support in completing the project.
We would like to express our gratitude towards our parents and friends for their
kind cooperation and encouragement which help us in the completion of the
project.
Place - Bhubaneswar Harkishen Singh (1701106073)
Date - Muskan Khedia (1701106115)
Jayashree Panda (1701106130)
Subham Mishra (1701106099)
Ankit Singh (1701106084)
3
ABSTRACT
The project aims to develop a personal-assistant for Linux-based systems. Jarvis
draws its inspiration from virtual assistants like Cortana for Windows, and Siri
for iOS. It has been designed to provide a user-friendly interface for carrying
out a variety of tasks by employing certain well-defined commands. Users
can interact with the assistant either through voice commands or using
keyboard input.
As a personal assistant, Jarvis assists the end-user with day-to-day activities
like general human conversation, searching queries in google, bing or yahoo,
searching for videos, retrieving images, live weather conditions, word
meanings, searching for medicine details, health recommendations based on
symptoms and reminding the user about the scheduled events and tasks. The
user statements/commands are analysed with the help of machine learning
to give an optimal solution.
Keywords:- Personal Assistant, Linux Systems, Automation,
Machine Learning
4
CONTENT
❖ Declaration
❖ Certificate
❖ Acknowledgement
❖ Abstract
❖ Problem Statement
❖ Scope
❖ Technologies Stack Used:
❖ Docker Container
❖ Selenium Automation tool
❖ Subprocesses/Child Process
❖ Golang
❖ DevOps
❖ Relationship to other approaches.
❖ Sorensen-Dice Coefficient
❖ Features in Jarvis
❖ Future Prospectives
❖ Software Requirements and Specification
❖ DFD’s of our Virtual Assistant
❖ Functional Requirements
❖ Non-Functional Requirements
❖ Conclusion
5
PROBLEM STATEMENT
We are all well aware about Cortana, Siri, Google Assistant and many other virtual
assistants which are designed to aid the tasks of users in Windows, Android and
iOS platforms. But to our surprise, there’s no such virtual assistant available for
the paradise of Developers i.e. Linux platform.
PURPOSE
This Software aims at developing a personal assistant for Linux-based systems.
The main purpose of the software is to perform the tasks of the user at certain
commands, provided in either of the ways, speech or text. It will ease most of
the work of the user as a complete task can be done on a single command. Jarvis
draws its inspiration from Virtual assistants like Cortana for Windows and Siri
for iOS. Users can interact with the assistant either through voice commands or
keyboard input.
PRODUCT GOALS AND OBJECTIVES
Currently, the project aims to provide the Linux Users with a Virtual Assistant
that would not only aid in their daily routine tasks like searching the web,
extracting weather data, vocabulary help and many others but also help in
automation of various activities.
In the long run, we aim to develop a complete server assistant, by automating
the entire server management process - deployment, backups, auto-scaling,
logging, monitoring and make it smart enough to act as a replacement for a
6
general server administrator.
PRODUCT DESCRIPTION
As a personal assistant, Jarvis assists the end-user with day-to-day activities like
general human conversation, searching queries in various search engines like
Google, Bing or Yahoo, searching for videos, retrieving images, live weather
conditions, word meanings, searching for medicine details, health
recommendations based on symptoms and reminding the user about the
scheduled events and tasks. The user statements/commands are analysed with
the help of machine learning to give an optimal solution.
SCOPE
Presently, Jarvis is being developed as an automation tool and virtual assistant.
Among the Various roles played by Jarvis are:
1. Search Engine with voice interactions
2. Medical diagnosis with Medicine aid.
3. Reminder and To-Do application.
4. Vocabulary App to show meanings and correct spelling errors.
5. Weather Forecasting Application.
There shall be proper Documentation available on its Official Github repository
for making further development easy and we aim to release our virtual assistant as
an Open Source Software where modifications and contributions by the
community are warmly welcomed.
Link to Github Repository:
https://github.com/Harkishen-Singh/Jarvis-personal-assistant
7
TECHNOLOGIES USED
FRONTEND FRAMEWORK
➢ AngularJS
BACKEND STACK
➢ GO-lang
➢ Machine Learning
➢ Docker Container
DATABASE
➢ SQLite
➢ Cookies
DOCKER CONTAINER
Docker is a computer program that performs operating-system-level
virtualization. It is used to run software packages called containers. Containers are
isolated from each other and bundle their own application, tools, libraries and
configuration files; they can communicate with each other through well-defined
channels. All containers are run by a single operating-system kernel and are thus
more lightweight than virtual machines. Containers are created from images that
specify their precise contents. Images are often created by combining and
modifying standard images downloaded from public repositories.
8
Docker is developed primarily for Linux, where it uses the resource isolation
features of the Linux kernel such as cgroups and kernel namespaces, and a
union-capable file system such as OverlayFS and others to allow independent
containers to run within a single Linux instance, avoiding the overhead of starting
and maintaining virtual machines (VMs). The Linux kernel's support for
namespaces mostly isolates an application's view of the operating environment,
including process trees, network, user IDs and mounted file systems, while the
kernel's cgroups provide resource limiting for memory and CPU.
9
Docker can use various interfaces to access virtualisation features of the kernel. A
Docker container, unlike a virtual machine, does not require or include a separate
operating system. Instead, it relies on the kernel's functionality and uses resource
isolation for CPU and memory, and separate namespaces to isolate the
application's view of the operating system. Docker accesses the Linux kernel's
virtualization features either directly using the libcontainer library, which is
available as of Docker 0.9, or indirectly via libvirt, LXC (Linux Containers).
COMPONENTS
The Docker software is a service consisting of three components:
● Software: The Docker daemon, called dockerd, is a persistent process
that manages Docker containers and handles container objects. The
daemon listens for requests sent via the Docker Engine API. The
Docker client program, called docker, provides a command-line
interface that allows users to interact with Docker daemons.
● Objects: Docker objects are various entities used to assemble an
application in Docker. The main classes of Docker objects are images,
containers, and services.
○ A Docker container is a standardized, encapsulated
environment that runs applications. A container is managed
using the Docker API or CLI
○ A Docker image is a read-only template used to build
containers. Images are used to store and ship applications.
[34]
○ A Docker service allows containers to be scaled across multiple
Docker daemons. The result is known as a swarm, a set of
cooperating daemons that communicate through the Docker
API.
● Registries: A Docker registry is a repository for Docker images.
Docker clients connect to registries to download ("pull") images for use
or upload ("push") images that they have built. Registries can be public
or private. Two main public registries are Docker Hub and Docker
10
Cloud. Docker Hub is the default registry where Docker looks for
images. Docker registries also allow the creation of notifications based
on events.
Tools
● Docker Compose is a tool for defining and running multi-container
Docker applications. It uses YAML files to configure the application's
services and performs the creation and start-up process of all the
containers with a single command. The docker-compose CLI utility
allows users to run commands on multiple containers at once, for
example, building images, scaling containers, running containers that
were stopped, and more. Commands related to image manipulation, or
user-interactive options, are not relevant in Docker Compose because
they address one container. The docker-compose.yml file is used to
define an application's services and includes various configuration
options. For example, the build option defines configuration options
such as the Dockerfile path, the command option allows one to override
default Docker command, and more.
]The first public version of Docker
Compose (version 0.0.1) was released on December 21, 2013. The first
production-ready version (1.0) was made available on October 16,
2014.
● Docker Swarm provides native clustering functionality for Docker
containers, which turns a group of Docker engines into a single virtual
Docker engine.
] In Docker 1.12 and higher, Swarm mode is integrated
with Docker Engine. The swarm CLI utility allows users to run Swarm
containers, create discovery tokens, list nodes in the cluster, and more.
The docker node CLI utility allows users to run various commands to
manage nodes in a swarm, for example, listing the nodes in a swarm,
updating nodes, and removing nodes from the swarm. Docker manages
swarms using the Raft Consensus Algorithm. According to Raft, for an
11
update to be performed, the majority of Swarm nodes need to agree on
the update.
INTEGRATION
Docker can be integrated into various infrastructure tools, including Amazon
Web Services, Ansible CFEngine, Chef Google Cloud Platform, IBM Bluemix,
HPE Helion Stackato, Jelastic, Jenkins, Kubernetes, Microsoft Azure,
OpenStack Nova, OpenSVC, Oracle Container Cloud Service, Puppet, ProGet,
Salt,Vagrant, and VMware vSphere Integrated Containers.
The Cloud Foundry Diego project integrates Docker into the Cloud Foundry
PaaS.
Nanobox uses Docker (natively and with VirtualBox) containers as a core part of
its software development platform.
Red Hat's OpenShift PaaS integrates Docker with related projects (Kubernetes,
Geard, Project Atomic and others) since v3 (June 2015).
The Apprenda PaaS integrates Docker containers in version 6.0 of its product.
Jelastic PaaS provides managed multi-tenant Docker containers with full
compatibility to the native ecosystem.
The Tsuru PaaS integrates Docker containers in its product in 2013, the first
PaaS to use Docker in a production environment.
SELENIUM AUTOMATION TOOL
Selenium is a free (open source) automated testing suite for web applications
across different browsers and platforms. It is quite similar to HP Quick Test Pro
(QTP now UFT) only that Selenium focuses on automating web-based
applications. Testing done using Selenium tool is usually referred to as Selenium
12
Testing.
Selenium is not just a single tool but a suite of software, each catering to different
testing needs of an organization.
The entire Selenium Tool Suite is comprised of four components:
● Selenium IDE, a Firefox add-on that you can only use in creating relatively
simple test cases and test suites.
● Selenium Remote Control, also known as Selenium 1, which is the first
Selenium tool that allowed users to use programming languages in creating
complex tests.
● WebDriver, the newer breakthrough that allows your test scripts to
communicate directly to the browser, thereby controlling it from the OS
level.
● Selenium Grid is also a tool that is used with Selenium RC to execute parallel
tests across different browsers and operating systems.
13
Selenium RC and WebDriver were merged to form Selenium. Selenium is more
advantageous than QTP in terms of costs and flexibility. It also allows you to run
tests in parallel, unlike in QTP where you are only allowed to run tests
sequentially.
SUB-PROCESSES/CHILD PROCESS
A subprocess is a process started by another program. There are two major
procedures for creating a child process: the fork system call (preferred in Unix-like
systems and the POSIX standard) and the spawn (preferred in the modern (NT)
kernel of Microsoft Windows, as well as in some historical operating systems).
A child process inherits most of its attributes, such as file descriptors, from its
parent. In Unix, a child process is typically created as a copy of the parent, using
the fork system call. The child process can then overlay itself with a different
program (using exec) as required.
Each process may create many child processes but will have at most one parent
process; if a process does not have a parent this usually indicates that it was
created directly by the kernel. In some systems, including Linux-based systems,
the very first process (called init) is started by the kernel at booting time and never
terminates (see Linux startup process); other parentless processes may be
launched to carry out various daemon tasks in userspace. Another way for a
process to end up without a parent is if its parent dies, leaving an orphan process;
but in this case, it will shortly be adopted by init.
14
When a child process terminates, some information is returned to the parent
process. When a child process terminates before the parent has called wait, the
kernel retains some information about the process, such as its exit status, to
enable its parent to call wait later. Because the child is still consuming system
resources but not executing it is known as a zombie process.
Go-Lang
Go is an open source programming language that makes it easy to build simple,
reliable, and efficient software. Go is syntactically similar to C, but with memory
safety, garbage collection, structural typing, and CSP-style concurrency. The
main reasons why we chose Go for this project are:
#1 It Compiles Into Single Binary: Golang is built as a compiled language
and Google developers did a great job with it. Using static linking it is actually
combining all dependency libraries and modules into one single binary file
based on OS type and architecture. This means if you are compiling your
backend application on your laptop with Linux X86 CPU you can just upload
compiled binary into the server and it will work, without installing any
dependencies there.
#2 Static Type System: Type system is really important for large scale
applications. Python is great and fun language but sometimes we get unusual
exceptions because of using the variable as an integer only to find out that it’s a
string. Go will let you know about this issue during compile time as a compiler
error, thus saving your time and the hassle.
15
#3 Performance: This could be surprising but in most of the application cases
Go is faster than Python (2 and 3). The result of the Benchmarking Game, used
to determine the faster programming language, clearly favours Go, because of
its concurrency model and CPU scalability. Whenever we need to process some
internal request we are doing it with a separate Goroutine, which is 10 times
cheaper in resources than Python threads, thus saving us a lot of resources
(Memory, CPU, etc.) because of the built-in language features.
#4 You don’t need web framework for Go: This is the most awesome
thing about the programming language. Go language creators and the
community have built in so many tools natively supported by language core,
that in most of the cases you don’t need any 3rd party library. For example, it
has HTTP, JSON, HTML templating built in language natively and you can
build very complex API services without even thinking about finding the library
on Github. Though there are a lot of libraries and frameworks built for Go and
making web applications with Go, we will recommend building your web
application or API service without any 3rd party library because in most cases
they are not making your life easier than using native packages.
#5 Great IDE support and debugging: IDE support is one of the most
important things when you are trying to switch your programming language.
Comfortable IDE on average can save up to 80% of your coding time. We found
Go Plugin For JetBrains IDEA which has support also for Webstorm,
PHPStorm, etc. This plugin is giving everything that you need for project
16
development. With the power of JetBrains IDEA, you can really boost your
development.
DevOps
This project extensively uses DevOps to speed up the development process and
make the entire process of delivery of code seamless by using Travis CI builds
along with Heroku based deployment services
.DevOps is a set of software development practices that combines software
development (Dev) and information technology operations(Ops) to shorten the
systems development life cycle while delivering features, fixes, and updates
frequently in close alignment with business objectives. It is a set of practices
intended to reduce the time between committing a change to a system and the
change being placed into normal production while ensuring high quality.
As DevOps is intended to be a cross-functional mode of working, those that
practice the methodology use different sets of tools—referred to as
"toolchains"—rather than a single one. These toolchains are expected to fit into
one or more of the following categories, reflective of key aspects of the
development and delivery process:
1. Coding – code development and review, source code management
tools, code merging
2. Building – continuous integration tools, build status
3. Testing – continuous testing tools that provide feedback on business
risks
4. Packaging – artifact repository, application pre-deployment staging
5. Releasing – change management, release approvals, release
automation
6. Configuring – infrastructure configuration and management,
infrastructure as code tools
17
7. Monitoring – applications performance monitoring, end-user
experience
Some categories are more essential in a DevOps toolchain than others;
especially continuous integration (e.g. Jenkins) and infrastructure as code.
Relationship to other approaches
AGILE
Agile and DevOps both often utilize practices such as automated build and test,
continuous integration, and continuous delivery. Agile can be viewed as
addressing communication gaps between customers and developers, while
DevOps addresses gaps between developers and IT operations/infrastructure.
Also, DevOps has focused on the deployment of developed software, whether it
is developed via Agile or other methodologies.
ArchOps
ArchOps presents an extension for DevOps practice, starting from software
architecture artefacts, instead of source code, for operational deployment.
ArchOps states that architectural models are first-class entities in software
development, deployment, and operations.
Continuous delivery
Continuous delivery and DevOps have common goals and are often used in
conjunction, but there are subtle differences.
18
While continuous delivery is focused on automating the processes in software
delivery, DevOps also focuses on the organization change to support great
collaboration between the many functions involved.
[19]
DevOps and continuous delivery share a common background in agile methods
and lean thinking: small and frequent changes with focused value to the end
customer. They are well communicated and collaborated internally, thus
helping achieve faster time to market, with reduced risks.
DataOps
The application of continuous delivery and DevOps to data analytics has been
termed DataOps. DataOps seeks to integrate data engineering, data integration,
data quality, data security, and data privacy with operations. It applies
principles from DevOps, Agile Development and the statistical process control,
used in lean manufacturing, to improve the cycle time of extracting value from
data analytics.
DevSecOps
DevSecOps is another practice that rose from DevOps that includes information
technology security as a fundamental aspect in all the stages of software
development.
Site reliability engineering
In 2003, Google developed site reliability engineering (SRE), an approach for
releasing new features continuously into large-scale high-availability systems
while maintaining high-quality end-user experience. While SRE predates the
development of DevOps, they are generally viewed as being related to each
other. Some aspects of DevOps have taken a similar approach.
19
DevOps is often viewed as an approach to applying systems administration work
to cloud technology.
WinOps
WinOps is the term used for DevOps practices for a Microsoft-centric view.
Goals
The goals of DevOps span the entire delivery pipeline. They include Improved
deployment frequency:
● Faster time to market;
● Less failure rate of new releases;
● Shortened lead time between fixes;
● Faster mean time to recovery (in the event of a new release crashing or
otherwise disabling the current system).
Simple processes become increasingly programmable and dynamic, using a
DevOps approach. DevOps aims to maximize the predictability, efficiency,
security, and maintainability of operational processes. Very often, automation
supports this objective.
DevOps integration targets product delivery, continuous testing, quality testing,
feature development, and maintenance releases in order to improve reliability
and security and provide faster development and deployment cycles. Many of
the ideas (and people) involved in DevOps came from the enterprise systems
management and agile software development movements.
Companies that practice DevOps have reported significant benefits, including
significantly shorter time to market, improved customer satisfaction, better
product quality, more reliable releases, improved productivity and efficiency,
and the increased ability to build the right product by fast experimentation.
20
Deployment
Companies with very frequent releases may require knowledge of DevOps. For
example, the company that operates an image hosting website Flickr developed
a DevOps approach to support ten deployments a day. Daily deployment cycle
would be much higher at organizations producing multi-focus or multi-function
applications. Daily deployment is referred to as continuous deployment or
continuous delivery and has been associated with the lean startup methodology.
Professional associations and blogs posts have formed on the topic since 2009.
DevOps automation
DevOps automation can be achieved by repackaging platforms, systems, and
applications into reusable building blocks through the use of technologies such
as virtual machines and containerization.
Implementation of DevOps automation in the IT-organization is heavily
dependent on tools, which are required to cover different areas of the systems
development lifecycle (SDLC):
1. Infrastructure as code — Ansible, Terraform, Puppet, Chef
2. CI/CD — Jenkins, TeamCity, Shippable, Bamboo, Azure DevOps
3. Test automation — Selenium, Cucumber, Apache JMeter
4. Containerization — Docker, Rocket, Unik
5. Orchestration — Kubernetes, Swarm, Mesos
6. Deployment — Elastic Beanstalk, Octopus, Vamp
7. Measurement — NewRelic, Kibana, Datadog, DynaTrace
8. ChatOps — Hubot, Lita, Cog
21
Sorensen-Dice Coefficient
This method is intensively used in the project to analyse the query string by the
user. This leads to the implementation of machine learning in the project, as the
system could analyse the requirements of the user in a better and defined
manner.
The Sørensen–Dice coefficient (see below for other names) is a statistic used to
gauge the similarity of two samples. It was independently developed by the
botanists Thorvald Sørensen and Lee Raymond Dice, who published in 1948
and 1945 respectively.
Formula
Sørensen's original formula was intended to be applied to discrete data. Given
two sets, X and Y, it is defined as
where |X| and |Y| are the cardinalities of the two sets (i.e. the number of
elements in each set). The Sørensen index equals twice the number of elements
common to both sets divided by the sum of the number of elements in each set.
When applied to boolean data, using the definition of true positive (TP), false
positive (FP), and false negative (FN), it can be written as
It is different from the Jaccard index which only counts true positives once in
both the numerator and denominator. DSC is the quotient of similarity and
ranges between 0 and 1. It can be viewed as a similarity measure over sets.
Similarly to the Jaccard index, the set operations can be expressed in terms of
vector operations over binary vectors a and b:
which gives the same outcome over binary vectors and also gives a more general
similarity metric over vectors in general terms.
22
For sets X and Y of keywords used in information retrieval, the coefficient may
be defined as twice the shared information (intersection) over the sum of
cardinalities :
When taken as a string similarity measure, the coefficient may be calculated for
two strings, x and y using bigrams as follows.
where nt
is the number of character bigrams found in both strings, nx
is the
number of bigrams in string x and ny
is the number of bigrams in string y. For
example, to calculate the similarity between:
night
nacht
We would find the set of bigrams in each word:
{ni,ig,gh,ht}
{na,ac,ch,ht}
Each set has four elements, and the intersection of these two sets has only one
element: ht.
Inserting these numbers into the formula, we calculate, s = (2 · 1) / (4 + 4) =
0.25.
Applications
The Sørensen–Dice coefficient is useful for ecological community data (e.g.
Looman & Campbell, 1960). The justification for its use is primarily empirical
rather than theoretical (although it can be justified theoretically as the
intersection of two fuzzy sets). As compared to Euclidean distance, the Sørensen
distance retains sensitivity in more heterogeneous data sets and gives less
weight to outliers. Recently the Dice score (and its variations, e.g. logDice taking
a logarithm of it) has become popular in computer lexicography for measuring
the lexical association score of two given words. It is also commonly used in
23
image segmentation, in particular for comparing algorithm output against
reference masks in medical applications.
Features in JARVIS
1. Queries from the web:
Making queries is an essential part of one’s life, and nothing changes even for a
developer working on Linux. We have addressed the essential part of a netizen’s
life by enabling our voice assistant to search the web. Here we have used Node
JS and Selenium framework for extracting the result from the web as well as
displaying it to the user. Jarvis supports a plethora of search engines like Google,
Bing and Yahoo and displays the result by scraping the searched queries.
In order to make queries from different search engines, the given format should be
adopted:
<search engine name> <query>
Jarvis supports Google, Bing and Yahoo, which should precede the desired query.
24
2. Accessing youtube videos
Videos have remained as a main source of entertainment, one of the most
prioritized tasks of virtual assistants. They are equally important for
entertainment as well as educational purposes as most teaching and research
activities in present times are done through Youtube. This helps in making the
learning process more practical and out of the four walls of the classroom.
Jarvis implements the feature through a subprocess module which is handled by
the main Golang service. This service initiates the subprocess for Node JS which
serves the Selenium WebDriver, and scraps the searched YouTube query.
In order to access videos from youtube format is:
youtube <video you want to search for>
25
3. Get weather for a location
Getting live weather conditions about a place remains an important task of virtual
assistants. It helps the user charter the course of their action. Jarvis addresses this
issue with the help of Python.
In order to access the live weather condition format is:
Weather <city> <state/country>
26
4. Retrieve images
Users could get images directly through the Jarvis interface. This implementation
is done using the Selenium WebDriver. The images are derived as iframes from
the entire web code received from Google images. These are formatted according
to use and displayed in a compact manner in the Jarvis interface.
In order to retrieve image format is:
Image <image you want to search>
27
5. Dictionary meaning
One of the usages of the web is to find word meaning and its usage in our day to
day life. Instead of going through the bulky books, our users can simply search for
it using the voice assistant and get the meaning within a fraction of seconds.
For retrieving the meaning of a word format is,
meaning <word>
6. Medicine Details
One of the important issue Jarvis addresses is of healthcare, and medicine in
general. The user can query either the medicine or the symptoms. The former lets
you know the complete details of the medicine, like indications, contradictions,
trade or brand names, dosage, the process of consumption, warning and
precautions, storage conditions, etc. On the other hand, the symptom feature lets
28
you query about the symptoms while Jarvis lists various diseases one is likely to be
affected along with their medicine. This is helpful for people who are quite busy
with their life and find trouble visiting the doctor immediately, thus relying on the
web to find the best result for short term cause.
Here we use Node JS framework along with Selenium to scrap the required data
from the web and display it to the user. We have a huge database of various
medicines and symptoms which helps Jarvis respond to the queries of the user at
ease. The syntax to be used for querying the necessary are:
In order to get details about medicine format is,
Medicine <medicine name>
In order to re-track the causes of symptoms format is,
Symptoms <disease/ailment>
29
7. Set Reminders
One of the main features of a voice assistant is to set a reminder for the user
accordingly. Jarvis is no different when it comes to this. The user can set
reminders to be notified about a task at a particular time. This will help users,
especially developers to schedule their time and resources easily. All the user have
to do is to input Set reminder to the assistant. A form will be displayed. Fill the
form with the required details and click on set reminder button.
30
8. Sending Emails
Integrating mailing features to Jarvis eases the job of mailing, which otherwise
would have to be done by opening the concerned email address. With Jarvis, you
do not need to go for another tab to do one of the major task of your day to day
affairs. The user can send emails to the desired receiver. He should input Send
mail, after which a form will be displayed. Fill the form with the required details
and click on the send mail button.
31
Why to use Jarvis?
1. It fulfils the lack of a virtual assistant in Linux systems.
2. It has an easy to install and use interface.
3. It accepts inputs even through voice or keyboard.
4. It automates tedious tasks like deployment, unit testing through a single
command.
5. It gives live weather updates.
6. It gives advice on health.
32
FUTURE PROSPECTIVE
We plan to Integrate Jarvis with mobile using react native, to provide a
synchronized experience between the two connected devices.
Further, in the long run, Jarvis is planned to feature auto deployment
supporting elastic beanstalk, backup files, and all operations which a
general Server Administrator does. The functionality would be seamless
enough to replace the Server Administrator with Jarvis.
Functional Requirements:
● Linux Distribution
● Proper Internet Connection
● Github Credentials
● Docker installed
● Python 2.7
● Heroku CLI
● Mplayer for voice support (Text-to-Speech)
● Chromium-based browser, like Chrome, Edge
● Heroku Credentials
● Node JS with npm
Non-Functional Requirements:
The non-functional requirements of the system include:
● The system ensures safety, security and usability, which are
observable during operation (at run time).
● The system is adaptable to different situations.
● The project has good and compact UI using AngularJS with
responsive interface.
● The project is light on resources.
33
CONCLUSION
Through this voice assistant, we have automated various services using a single
line command. It eases most of the tasks of the user like searching the web,
retrieving weather forecast details, vocabulary help and medical related queries.
We aim to make this project a complete server assistant and make it smart
enough to act as a replacement for a general server administration. The future
plans include integrating Jarvis with mobile using React Native to provide a
synchronised experience between the two connected devices. Further, in the
long run, Jarvis is planned to feature auto deployment supporting elastic
beanstalk, backup files, and all operations which a general Server Administrator
does. The functionality would be seamless enough to replace the Server
Administrator with Jarvis.
34© July 2021| IJIRT | Volume 8 Issue 2 | ISSN: 2349-6002
IJIRT 152099 INTERNATIONAL JOURNAL OF INNOVATIVE RESEARCH IN TECHNOLOGY 419
Voice Assistant Using Python
1Nivedita Singh,
2Dr. Diwakar Yagyasen,
3Mr. Surya Vikram Singh,
4Gaurav Kumar,
5Harshit Agrawal
1,2,3,4,5Department of CSE, Babu Banarasi Das National Institute of Technology and Management,
Lucknow, India
Abstract - Today the technological advancement is
increasing day by day. Earlier only there was a computer
system in which we can do only few tasks. But now
machine learning, artificial intelligence, deep learning,
and few more technologies have made computer systems
so advance that we can perform any type of task. In such
era of advancement if people are still struggling to
interact using various input devices, then it’s not worth
it. For this reason, we developed a voice assistant using
python which allows the user to run any type of
command in linux without interaction with keyboard.
The main task of voice assistant is to minimize the use of
input devices like keyboard, mouse etc. It will also reduce
the hardware space and cost.
Index Terms - Artificial Intelligence, Desktop Assistant,
Python, Text to Speech, Virtual Assistant, Voice
Recognition.
INTRODUCTION
In this era of technology everything that human being
can do are being replaced by machines. One of the
main reasons is change in performance. In today’s
world we train our machine to think like humans and
do their task by themselves. Therefore, there came a
concept of virtual assistant.
A virtual assistant is a digital assistant that uses voice
recognition features and language processing
algorithms to recognize voice commands of user and
perform relevant tasks as requested by the user. Based
on specific commands given by the user a virtual
assistant is capable of filtering out the ambient noise
and return relevant information.
Virtual Assistant are completely software based but
nowadays they are integrated in different devices and
also some of the assistants are designed specifically
for single devices like Alexa.
Due to drastic change in technology now it’s a. high
time to train our machine with the help of machine
learning, deep learning, neural networks. Today we
can talk to our machine with the help of Voice
Assistant. Today every big company is using Voice
Assistant so that their user can take the help of
machine through their voice. So, with the Voice
Assistant we are moving to the next level advancement
where we are able to talk to our machine.
These types of virtual assistants are very useful for old
age, blind & physically challenged people, children,
etc. by making sure that the interaction with the
machine is not a challenge anymore for people. Even
blind people who couldn’t see the machine can interact
with it using their voice only.
Here are some of the basic tasks that can be done with
the help of voice assistant: -
• Reading Newspaper
• Getting updates of mail
• Search on web
• Play a music or video
• Setting a reminder and alarm
• Run any program or application
• Getting weather updates
These are some of the examples, we can do many more
things according to our requirement.
The Voice Assistant that we have developed is for
Windows users as well as for Linux Users. The voice
assistant we have developed is a desktop-based built
using python modules and libraries. This assistant is
just a basic version that could perform all the basic
tasks which have been mentioned above but current
technology is although good in it is still to be merged
with Machine Learning and Internet of Things (IoT)
for better enhancements.
We have used python modules and libraries for
making the model and we have used Machine
Learning for training our model, some of the windows
and linux commands are also added to model so that
our model can run smoothly on this operating system.
Basically, our model will work in three modes: -
1. Supervised Learning
2. Unsupervised Learning
3. Reinforcement Learning
© July 2021| IJIRT | Volume 8 Issue 2 | ISSN: 2349-6002
IJIRT 152099 INTERNATIONAL JOURNAL OF INNOVATIVE RESEARCH IN TECHNOLOGY 420
Depending upon the usage for which the assistant is
required for user. And these can be achieved with the
help of Machine learning and Deep Learning.
With the help of Voice Assistant there will be no need
to write the commands again and again for performing
particular task. Once model is created it can be used
any number of times by any number of users in the
easiest ways.
So, with the help of virtual assistant, we will be able
to control many things around us single handedly on
one platform.
II.LITERATURE SURVEY
Bassam A, Raja N. et al, written about statement and
speech which is most significant. In the
communication between human and machine
arrangement was done through analog signal which is
converted by speech signal to digital wave. This
technology is massively utilized, it has limitless uses
and permit machines to reply appropriately and
consistently to user voices, also offers useful and
appreciated facilities. Speech Recognition System
(SRS) is rising gradually and has indefinite
applications. The research has revealed the summary
of the procedure; it is a simple model [1].
B. S. Atal and L. R. Rabiner et al, explained regarding
speech analysis, and result is regularly completed in
combination with pitch analysis. The research
described a pattern recognition technique for
determining whether a given slice of a speech signal
should be categorized as voiced speech, unvoiced
speech, or silence, depending on dimensions finished
on signal. The main restriction of the technique is the
requirement for exercise the algorithm on exact set of
dimensions picked, and for the specific recording
circumstances [2].
V. Radha and C. Vimala et al, explained that most
general mode of communication among human beings
is speech. As this is the utmost technique, human
beings would identical to utilize speech to interrelate
with machines too. Because of this, autonomous
speech identification has got a lot of reputation. Most
techniques for speech recognition be like Dynamic
Time Warping (DTW), HMM. For the feature mining
of speech Mel Frequency Cepstrum Coefficients
(MFCC) has been utilized which offers a group of
characteristic vectors of speech waveform. Prior study
has exposed MFCC to be more precise and real than
rest characteristic mining approaches in the speech
recognition. The effort has been completed on
MATLAB and investigational outcomes depict that
system is capable of identifying words at satisfactorily
great accuracy [3].
T. Schultz and A. Waiel et al, explained about the
spreading of speech technology products around the
globe, the immovability to novel destination languages
turns out to be a useful concern. As a significance, the
research emphases on the query of how to port huge
vocabulary incessant speech recognition (LVCSR)
systems in a fast and well-organized manner. More
particularly the research needs to evaluate acoustic
models for a novel destination language by means of
speech information from different source languages,
but only restricted data from the destination language
identification outcomes using language-dependent,
independent and language-adaptive acoustic models
are described and deliberated in the framework of
Global Phone project which examines LVCSR
methods in 15 languages.[4].
J. B. Allen et al described about the Language that is
the utmost significant means of communication and
speech is its major interface. The interface for human
to machine, speech signal was converted into analog
and digital wave shape as a machine understood. [10]
A technology enormously utilized and has limitless
applications. Speech technologies permit machines to
react appropriately and consistently to human
speeches and offers valuable and appreciated services.
The research provides a summary of the speech
identification procedure, its basic model, and its
application, techniques and also describes reasonable
research of several techniques that are utilized for
speech recognition system. SRS is enhancing
gradually and has infinite applications. [5]
Mugdha Bapat, Pushpak Bhattacharyya et al,
described a morphological analyzer for most of the
NLP solicitations of Indian Languages. [11] During
the work they described and estimated the
morphological analyzer for Marathi language. They
started by planning a to some extent homomorphism
"boos trappable" encryption technique that functions
during the function f is the techniques individual
decryption function. The research showed a great
accuracy for Marathi that adventures consistency in
inflectional standards in engaging the Finite State
Systems for demonstrating language in a sophisticated
way. Grouping of post positions and the growth of 
© July 2021| IJIRT | Volume 8 Issue 2 | ISSN: 2349-6002
IJIRT 152099 INTERNATIONAL JOURNAL OF INNOVATIVE RESEARCH IN TECHNOLOGY 421
FSA is one of significant assistances since Marathi
have difficult morphotactics [6].
G. Muhammad, M. N. Huda et al, presented a model
ASR for Bangla digit. Although Bangla is among the
mostly spoken languages around the globe, some of
the few works of Bangla ASR can be identified in the
collected works, particularly Bangla accented in
Bangladeshi. During this research, the quantity is
gathered from publics in Bangladesh. Mel-frequency
cepstral coefficients (MFCCs) dependent
characteristics and hidden Markov model (HMM)
dependent classifiers are utilized for identification.
Dialectical variance make happen a part of
performance deprivation. In situation of gender-based
trials, female spoken digits had greater accuracy rates
than those by male spoken digits [7].
Sean R Eddy et al operated on Hidden Markov models
which are a common statistical designing approach for
'linear' issues like sequences or time series and have
been extensively utilized in speech identification
requests for twenty years. Inside the HMM formalism,
it is probable to relate formal, completely probabilistic
techniques to profiles and gapped structure
arrangements.[12] Profiles based on Hidden Markov
model have fixed most of the concerns related with
typical profile analysis. HMMs offer a steady theory
for notching insertions and deletions, and a constant
structure for joining structural and sequence data.
HMM based numerous sequence arrangements is
quickly refining. Homolog recognition based on
HMM is previously adequately influential for HMM
techniques to relate satisfactorily to much more
difficult threading techniques for protein reverse fold
[8].
III.PROBLEM FORMULATION
This section describes the description about the
problem formulation.
As we know each human have their own
characteristics and every developer applies his own
method and approaches for development of a product.
One assistant can synthesize speech more
qualitatively, another can more accurately and without
additional explanations and corrections perform tasks,
others are able to perform a narrower range of tasks,
but most accurately and as the user wants.
Therefore, there is no such assistant that can perform
all the work and tasks equally. The set of
characteristics that an assistant has depends on the area
on which developer paid more attention. Since all
system are based on machine learning and use for their
creation huge amounts of data collected from various
sources and then trained on them, an important role is
played by the source of this data.
Despite the different approaches to learn different
algorithms, the principle of building voice assistant
remains the same. The technologies that are used to
build a voice assistant that can interact with the
humans are speech recognition, Teach-To-Speech,
voice biometrics, dialog manager, natural language
understanding and named entity recognition.
IV.PROPOSED APPROACH
The proposed system will have the following
functionality:
(a) The system will keep listening for commands and
the time for listening is variable which can be changed
according to user requirements.
(b) If the system is not able to gather information from
the user input it will keep asking again to repeat till the
desired no. of times.
(c) The system can have both male and female voices
according to user requirements.
(d) Features supported in the current version include
playing music, emails, texts, search on Wikipedia, or
opening system installed applications, opening
anything on the web browser, etc.
(e)The system will keep listening for commands and
the time for listening is variable which can be changed
according to user requirements.
(f) If the system is not able to gather information from
the user input it will keep asking again to repeat till the
desired no. of times.
(g) The system can have both male and female voices
according to user requirements [9].
© July 2021| IJIRT | Volume 8 Issue 2 | ISSN: 2349-6002
IJIRT 152099 INTERNATIONAL JOURNAL OF INNOVATIVE RESEARCH IN TECHNOLOGY 422
V.RESULT AND ANALYSIS
This section describes a brief description of our result
on the basis of the comparison and analysis of our
proposed work. We have employed this idea by means
of Python, Machine Learning and AI. Our main aim is
to assist the users in their tasks with the help of their
voice commands. This can be done in two phases.
Firstly, taking the audio input from the user and
converting it to an English phrase with the help of
Speech Recognition API. Secondly searching for the
task user wants to perform and then redirecting it to
the linux server with the help of HTTP Protocol and
displaying the result on the web browser.
This is the Windows Code which will run on the client
side for taking voice input of the user.
This is the Linux Code which will run on the server
side for running the linux command and displaying the
output on the web.
When the Windows Code is executed the first Output
which will will be displayed is to start speaking. After
this the user has to give the voice command.
This screen will be visible when user has given voice
command and the Google Speech Recognition API has
translated it into an English Phrase.
After translation the command which the user has
given will be displayed on the web browser.
VI.CONCLUSION
In this paper we have discussed a Voice Assistant
developed using python. This assistant currently
works as an application based and performs basic tasks
like weather updates, stream music, search Wikipedia,
open desktop applications, etc. The functionality of the
current system is limited to working on application
based only. The upcoming updates of this assistant 
© July 2021| IJIRT | Volume 8 Issue 2 | ISSN: 2349-6002
IJIRT 152099 INTERNATIONAL JOURNAL OF INNOVATIVE RESEARCH IN TECHNOLOGY 423
will have machine learning incorporated in the system
which will result in better suggestions with IoT to
control the nearby devices similar to what Amazon’s
Alexa does.
REFERENCES
[1] M. Bapat, H. Gune, and P. Bhattacharyya, “A
paradigm-based finite state morphological
analyzer for marathi,” in Proceedings of the 1st
Workshop on South and Southeast Asian Natural
Language Processing (WSSANLP), pp. 26–34,
2010.
[2] B. S. Atal and L. R. Rabiner, “A pattern
recognition approach to voiced unvoiced-silence
classification with applications to speech
recognition,” Acoustics, Speech and Signal
Processing, IEEE Transactions on, vol. 24, no. 3,
pp. 201–212, 1976.
[3] V.Radha and C. Vimala, “A review on speech
recognition challenges and approaches,” doaj.
org, vol. 2, no. 1, pp. 1–7, 2012.
[4] T. Schultz and A. Waibel, “Languageindependent and language adaptive acoustic
modeling for speech recognition”, Speech
Communication, vol. 35, no. 1, pp. 31–51, 2001.
[5] J. B. Allen, “From lord rayleigh to shannon: How
do humans decode speech,” in International
Conference on Acoustics, Speech and Signal
Processing, 2002.
[6] M. Bapat, H. Gune, and P. Bhattacharyya, “A
paradigm-based finite state morphological
analyzer for marathi,” in Proceedings of the 1st
Workshop on South and Southeast Asian Natural
Language Processing (WSSANLP), pp. 26–34,
2010.
[7] G. Muhammad, Y. Alotaibi, M. N. Huda, et al.,
pronunciation variation for asr: A survey of the
“Automatic speech recognition for bangla digits,”
literature,” Speech Communication, vol. 29, no.
in Computers and Information Technology, 2009.
2, pp. 225–246, 1999.
[8] S. R. Eddy, “Hidden Markov models,” Current
opinion in structural biology, vol. 6, no. 3, pp.
361–365, 1996.
[9] excellent style manual for science writers is
“Speech recognition with flat direct models,”
IEEE Journal of Selected Topics in Signal
Processing, 2010.
[10]Srivastava S., Prakash S. (2020) Security
Enhancement of IoT Based Smart Home Using
Hybrid Technique. In: Bhattacharjee A.,
Borgohain S., Soni B., Verma G., Gao XZ. (eds)
Machine Learning, Image Processing, Network
Security and Data Sciences. MIND 2020.
Communications in Computer and Information
Science, vol 1241. Springer, Singapore.
https://doi.org/10.1007/978-981-15-6318-8_44
[11]S. Srivastava and S. Prakash, "An Analysis of
Various IoT Security Techniques: A Review,"
2020 8th International Conference on Reliability,
Infocom Technologies and Optimization (Trends
and Future Directions) (ICRITO), 2020, pp. 355-
362, doi: 10.1109/ICRITO48877.2020.9198027
[12]Saijshree Srivastava, Surya Vikram Singh,
Rudrendra Bahadur Singh, Himanshu Kumar
Shukla,” Digital Transformation of Healthcare: A
blockchain study” International Journal of
Innovative Science, Engineering & Technology,
Vol. 8 Issue 5, May 2021International Journal of Engineering and Advanced Technology (IJEAT)
ISSN: 2249-8958 (Online), Volume-10 Issue-4, April 2021
162
Published By:
Blue Eyes Intelligence Engineering
& Sciences Publication
© Copyright: All Rights Reserved
Retrieval Number: 100.1/ijeat.D24250410421
DOI:10.35940/ijeat.D2425.0410421
Journal Website: www.ijeat.org
 Abstract: Personal Assistants, or conversational interfaces, or
chat bots reinvent a new way for individuals to interact with
computes. A Personal Virtual Assistant allows a user to simply ask
questions in the same manner that they would address a human,
and are even capable of doing some basic tasks like opening apps,
reading out news, taking notes etc., with just a voice command.
Personal Assistants like Google Assistant, Alexa, Siri works by
Speech Recognition (Speech-to-text) and Text-to-Speech.
 Keywords: Personal Assistants; chat bots; conversational
interfaces; Speech Recognition; Text-to-Speech.
I. INTRODUCTION
Knowingly, or unknowingly, personal assistants have
become an integral part of our lives these days. It is because of
all the features and ease of use they provide. Personal
Assistants are also capable of automating some day-to-day
tasks, so that a user can focus on what matters the most to
them. Features like, making calls, writing messages, taking
photographs, storing to-dos on the go, browsing internet etc.,
are offered by personal assistants. So, utilization of these
features of a virtual assistant will save an individual a lot of
time, and effort. It is important to focus more on what matters
the most for an individual, whether it could be personal work,
or professional work. People often spend more time on doing
routine tasks, and they can be automated with these types of
personal assistants. When someone works in an environment
with which he/she is not familiar with, they often find it
difficult to locate applications that they need, like browser,
any IDE or nay other software. Most of the time, they will end
up wasting hours of time, searching for the application alone.
This results in unnecessary time wastage. Therefore, a voice
enabled personal assistant will help automating this process.
User is expected just to give a voice command, and the
assistant will take care of the rest.
Manuscript received on April 07, 2021.
Revised Manuscript received on April 12, 2021.
Manuscript published on April 30, 2021.
* Correspondence Author
Dr. V. Geetha, Assistant Professor, CSE Department, SCSVMV
Deemed to be University, Kanchipuram, Tamil Nadu.
Dr. C K Gomathy*, Assistant Professor, CSE Department,
SCSVMV Deemed to be University, Kanchipuram, Tamil Nadu.
Mr. Kottamasu Manasa Sri Vardhan, UG Scholar CSE
Department, SCSVMV Deemed to be University, Kanchipuram,
Tamil Nadu.
Mr. Nukala Pavan Kumar, UG Scholar CSE Department,
SCSVMV Deemed to be University, Kanchipuram, Tamil Nadu.
© The Authors. Published by Blue Eyes Intelligence Engineering and
Sciences Publication (BEIESP). This is an open access article under the CC
BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/)
The paper indicates the usage of a Voice enabled personal
assistant and it can enable an individual to get things done
with voice commands, and can save a lot of their time as well.
This Voice enabled personal assistant can be implemented by
using technologies like Speech-to-Text and Text-to-Speech,
and can be integrated with other functionalities as well,
depending on our requirement.
II. LITERATURE SURVEY
Personal Assistants, or Virtual assistants have become an
integral part of our lives these days. Every organisation, or
individual is switching to this kind of technologies, as they
help them get their things done in an easier way.
This system is based on a Desktop Application. This
system includes a Virtual Assistant, that is capable of
accepting input from the user, understanding it, analysing it,
and performing tasks accordingly. This helps users save a lot
of time.
III. PROPOSED METHODOLOGY
In this proposed concept effective way of implementing a
Personal voice assistant, Speech Recognition library has
many in-built functions, that will let the assistant understand
the command given by user and the response will be sent back
to user in voice, with Text to Speech functions. When
assistant captures the voice command given by user, the under
lying algorithms will convert the voice into text. And
according to the keywords present in the text (command given
by user), respective action will be performed by the assistant.
This is made possible with the functions present in different
libraries. Also, the assistant was able to achieve all the
functionalities with help of some API’s. We had used these
APIs for functionalities like performing calculations,
extracting news from web sources, and for some other things.
We will be sending a request, and through the API, we’re
getting the respective output. API’s like
WOLFRAMALPHA, are very helpful in performing things
like calculations, making small web searches. And for getting
the data from web, not every API will have the capability to
convert the raw JSON data into text. So, we used a library
called JSON, and it will help in parsing the JSON Data
coming form websites, to string format. In this way, we are
able to extract news from the web sources, and send them as
input to a function for further purposes. Also, we have
libraries like Random and many other libraries, each
corresponding to a different technology. We used the library
OS to implement
The Voice Enabled Personal Assistant for Pc
using Python
V. Geetha, C.K.Gomathy, Kottamasu Manasa Sri Vardhan, Nukala Pavan Kumar
The Voice Enabled Personal Assistant for Pc using Python
163
Published By:
Blue Eyes Intelligence Engineering
& Sciences Publication
© Copyright: All Rights Reserved
Retrieval Number: 100.1/ijeat.D24250410421
DOI:10.35940/ijeat.D2425.0410421
Journal Website: www.ijeat.org
Operating System related functionalities like Shutting
down a system, or restarting a system. pyautogui is a library
that is implemented for functionalities like, capturing a
screenshot. psutil is a library, and is used for functionalities
like checking battery status.
IV TECHNOLOGIES USED
The programming language used in this project is Python,
which is known for its versatility, and availability of wide
range of libraries. For programming the Virtual Assistant, we
used Microsoft Visual Studio Code (IDE) which supports
Python programming language. Speech Recognition library is
present in Python, and is having some in-built functions.
Initially, we will define a function for converting the text to
speech. For that, we use pyttsx3 library. We will initialize the
library instance to a variable. We use say() method and pass
the text as an argument to that, for which the output will be a
voice reply. For recognizing the voice command given by
user, another function has been defined. In that function,
define microscope source and within its scope, we use
respective functions and store the output in a variable. For the
whole process, we have many services to use, like Google
Speech Recognition engine, Microsoft Bing Voice
Recognition engine, and products of many other big
companies like IBM, Houndify etc., For this project, we
choose Google’s Speech Recognition Engine, that will
convert the respective analog voice command into a digital
text format. We pass that text as an input to the Assistant, and
it will search for the keyword. If the input command has a
word that matches with the respective word, the respective
function will be called, and it will perform the action
accordingly, like telling time, or date, or telling battery status,
taking a screenshot, saving a short note, and many more.For
this Personal Virtual Assistant, the main advantage is that it
saves a lot of time, and it can even handle queries from
people, of different voices. There is no rule that one has to
give any exact specified command to trigger a particular
action. User has the flexibility to give command for user, in
natural language. The programming language used to design
this Voice enabled Personal Assistant for PC is PYTHON
3.8.3. And the IDE (Integrated Development Environment)
that we used is Microsoft Visual Code.
V SYSTEM ARCHITECTURE
This Assistant consists of three modules. First is, assistant
accepting voice input from user. Secondly, analysing the input
given by the user, and mapping it to the respective intent and
function. And the third is, the assistant giving user the result
all along with voice.
Fig 1: Block Diagram
Initially, the assistant will start accepting the user input. After
receiving the input, the assistant will convert the analog voice
input to the digital text. If assistant was not able to convert the
voice into text, it will start asking user for the input again. If
converted, it will start analyzing the input and will map the
input with particular function. And later, the output will be
given to user via the voice command.
VI WORKING MODEL
The assistant, on starting, will initially wait for the input to
be given from user. If the user gives input command, via
voice, the assistant will capture it, and searches for the
keyword present in the input command. If the assistant was
able to find a key word, then it will perform the task
accordingly, and returns the output back to user, in voice. If
not, the assistant will again start waiting for the user to give
input.Each of these functionalities are having their own
importance in the whole system working.
 User Input—The assistant will wait for the user to give
voice command for further processing.
Fig 2: User Input
 Introducing to user—The user who is asking assistant to
introduce itself, will display the following.
Fig 3: Introducing itself
 Reading out news—If the user asks the assistant to read
out some news, the assistant will display the new line by
line and it will also read out the news.
Fig 4: Reading news
International Journal of Engineering and Advanced Technology (IJEAT)
ISSN: 2249-8958 (Online), Volume-10 Issue-4, April 2021
164
Published By:
Blue Eyes Intelligence Engineering
& Sciences Publication
© Copyright: All Rights Reserved
Retrieval Number: 100.1/ijeat.D24250410421
DOI:10.35940/ijeat.D2425.0410421
Journal Website: www.ijeat.org
 Taking a sample note—If the user has a small note to be
taken, he can ask the assistant to do so, and the assistant will
take the notes and save it in a notepad file.
Fig 5: Taking a short note
 Showing Note—If the user asks the assistant to display the
note, and to speak out the note, the assistant will do so.
Fig 6: Notes, saved in a notepad file
 YouTube searches—If the user asks the assistant to do
some YouTube searches, the assistant will do that. It will
ask the user, what to search in YouTube. After receiving the
input, it will open the YouTube page with that respective
search.
Fig 7: Asking assistant to open YouTube
 Web Searches—If the user asks the assistant to do some
web searches, the assistant will also do that. It will ask the
user to search for what, and it will open the google search in
a new tab of browser.
Fig 8: Assistant doing google search
 Opening Applications—If the user asks the assistant to
open an application, like MS Word, or any other, the assistant
will do so immediately. And also, it will speak that it opens
the application.
Fig 9: Assistant opening MS Word
Fig 10: Assistant opening MS Excel
Fig 11: Assistant opening MS Power point
Performing Calculations—If the user asks the assistant to
do some calculations, the assistant will speak out the result
Fig 12: Assistant doing calculations
The Voice Enabled Personal Assistant for Pc using Python
165
Published By:
Blue Eyes Intelligence Engineering
& Sciences Publication
© Copyright: All Rights Reserved
Retrieval Number: 100.1/ijeat.D24250410421
DOI:10.35940/ijeat.D2425.0410421
Journal Website: www.ijeat.org
Taking Screenshots—If the user asks the assistant to take
screenshots, the assistant will take a screenshot, and will
save it in a particular location.
Fig 13: Assistant taking a screenshot
 Locating a place—If the user asks the assistant to locate a
place, the assistant will open the Google Map with that
location
Fig 14: Assistant locating a place in Google Maps
VII CONCLUSION
This paper presents a comprehensive overview of the design
and development of a Voice enabled personal assistant for pc
using Python programming language. This Voice enabled
personal assistant, in today's life style will be more effective
in case of saving time, compared to that of previous days. This
Personal Assistant has been designed with ease of use as the
main feature. The Assistant works properly to perform some
tasks given by user. Furthermore, there are many things that
this assistant is capable of doing, like turning our PC off, or
restarting it, or reciting some latest news, with just one voice
command.
REFERENCES
1. Elizabeth Sucupira Furtado, Virgilio Almedia And Vasco Furtado,
“Personal Digital Assistants: The Need Of Governance”
2. Zecheng Zhan, Virgilio Almedia, And Meina Song,
“Table-To-Dialog: Building Dialog Assistants To Chat With People
On Behalf Of You”
3. Yusuf Ugurlu, Murat Karabulut, Islam Mayda “A Smart Virtual
Assistant Answering Questions About COVID-19” Mathangi Sri
“NLP In Virtual Assistants”
4. Anxo Pérez, Paula Lopez-Otero, Javier Parapar. “Designing An
Open-Source Virtual Assistant”
5. C K Gomathy And V Geetha. Article: A Real Time Analysis Of
Service Based Using Mobile Phone Controlled Vehicle Using DTMF
For Accident Prevention. International Journal Of Computer
Applications 138(2):11-13, March 2016. Published By Foundation Of
Computer Science (FCS), NY, USA,ISSN No: 0975-8887
6. Dr.C.K.Gomathy , K. Bindhu Sravya , P. Swetha , S.Chandrika
Article: A Location Based Value Prediction For Quality Of Web
Service, Published By International Journal Of Advanced Engineering
Research And Science (IJAERS), Vol-3, Issue-4 , April- 2016] ISSN:
2349-6495
7. C.K.Gomathy And Dr.S.Rajalakshmi.(2014),"A Business Intelligence
Network Design For Service Oriented Architecture", International
Journal Of Engineering Trends And Technology (IJETT) ,Volume IX,
Issue III, March 2014, P.No:151-154, ISSN:2231-5381.
8. “VIRTUAL PERSONAL ASSISTANT (VPA) FOR MOBILE USERS”
9. D. SOMESHWAR, DHARMIK BHANUSHALI, SWATI NADKARNI,
“IMPLEMENTATION OF VIRTUAL ASSISTANT WITH SIGN LANGUAGE
USING DEEP LEARNING AND TENSORFLOW”
10. C.K.Gomathy.(2010),"Cloud Computing: Business Management For
Effective Service Oriented Architecture" International Journal Of
Power Control Signal And Computation (IJPCSC), Volume 1, Issue
IV, Oct - Dec 2010, P.No:22-27, ISSN: 0976-268X.
11. Dr.C K Gomathy, Article: A Semantic Quality Of Web Service
Information Retrieval Techniques Using Bin Rank, International
Journal Of Scientific Research In Computer Science Engineering And
Information Technology ( IJSRCSEIT ) Volume 3 | Issue 1 | ISSN :
2456-3307, P.No:1563-1578, February-2018
12. Dr.C K Gomathy, Article: A Scheme Of ADHOC Communication
Using Mobile Device Networks, International Journal Of Emerging
Technologies And Innovative Research ( JETIR ) Volume 5 | Issue 11 |
ISSN : 2349-5162, P.No:320-326, Nov-2018.
13. Dr.C K Gomathy, Article: Supply Chain-Impact Of Importance And
Technology In Software Release Management, International Journal
Of Scientific Research In Computer Science Engineering And
Information Technology ( IJSRCSEIT ) Volume 3 | Issue 6 | ISSN :
2456-3307, P.No:1-4, July-2018
14. Hemalatha. C.Kand N. Ahmed Nisar (2011)., Explored Teachers’
Commitment In Self Financing Engineering Colleges, International
Journal Of Enterprise Innovation Management Studies (IJEIMS),
Vol2. No2. July-Dec 2011 ISSN: 0976-2698 Retrieved From
Www.Ijcns.Com
15. Dr.C K Gomathy, Article: The Efficient Automatic Water Control
Level Management Using Ultrasonic Sensor, International Journal Of
Computer Applications (0975 – 8887) Volume 176 – No. 39, July
2020.
16. C K Gomathy And V Geetha. Article: A Real Time Analysis Of Service
Based Using Mobile Phone Controlled Vehicle Using DTMF For
Accident Prevention. International Journal Of Computer
Applications 138(2):11-13, March 2016. Published By Foundation Of
Computer Science (FCS), NY, USA,ISSN No: 0975-8887
AUTHORS PROFILE
Dr.V.Geetha, is assistant professor in computer science
and engineering at Sri Chandrasekharendra Saraswathi
Viswa Mahavidyalaya , Enathur,Kanchipuram,India. Her
area of intrest lies in Java Programming,Software Quality
Assurance,Computer System Architecture Domain.
Dr C,K,Gomathy, is Assistant Professor in CSE at Sri
Chandrashekarendra Saraswathi Viswa Mahavidyalaya
deemed to be university, Enathur, Kanchipuram, India. Her
area of Intrest is Software Engineering Web Services,
Knowledge Management and IOT.
Kottamasu Manasa Sri Vardhan, student, B.E.
Computer Science and Engineering, SCSVMV Deemed to
be university,Enathur.
Nukala Pavan Kumar, student, B.E. Computer Science
and Engineering,, SCSVMV Deemed to be
university,,Enathur.
.UNIVERSTY OF MUMBAI
PROJECT REPORT ON
VIRTUAL ASSISTANT
SUBMITTED BY
JATU NAAZNEEN ABDUL GAFFAR
DTSS COLLEGE OF COMMERCE
UNDER THE GUIDANCE OF
PROF. ABHIJIT PALSE
BSCIT SEM V [2018-2019]
Ref No : Date :
Certificate
This is to certify that the project entitled VIRTUAL ASSISTANT is
undertaken at the D.T.S.S COLLEGE OF COMMERCE by JATU
NAAZNEEN ABDUL GAFFAR in partial fulfillment of B.Sc. IT degree
(Semester V) Examination had not been submitted for any other examination
and does not form part of any other course undergone by the candidate.
It is further certified that he has completed all required phases of project.
Signature of Internal Guide Signature of External
HOD/In -Charge/Co-ordinator
Acknowledgement
In completing this project report on project titled VIRTUAL ASSISTANT, I had to
take the help and guideline of a few respected people, who deserve my greatest gratitude.
The completion of this project report gives me much Pleasure. I would like to show
my gratitude to Prof. Abhijit Palse for giving me a good guideline for project throughout
numerous consultations. I would also like to expand my deepest gratitude to all those who
have directly and indirectly guided us in writing this project report.
Many people, especially my classmates and friends themselves, have made valuable
comments and suggestions on this proposal which gave me inspiration to improve my project.
Here I thank all the people for their help directly and indirectly to complete this project
report.
The author
Table of Contents
Sr.No Title Page No
1 Introduction 1
1.1 Background
1.2 Objectives
1.3 Purpose, Scope and Applicability
2
4
5
2 Survey of Technology 6
3 Requirement and Analysis 8
3.1 Problem Definition
3.2 Requirement Specification
3.3 Software and Hardware Requirement
8
9
11
4 System Design 12
4.1 ER Diagram
4.2 Activity Diagram
4.3 Class Diagram
4.4 Use Case Diagram
4.5 Sequence Diagram
4.6 Data Flow Diagram
4.7 Component Diagram
4.8 Deployment Diagram
4.9 Data Dictionary
4.10 Test Case Design
12
13
14
15
16
18
21
22
23
24
Reference and Bibliography 26
1
1.INTRODUCTION
VIRTUAL ASSISTANT
In today’s era almost all tasks are digitalized. We have Smartphone in hands and it is
nothing less than having world at your finger tips. These days we aren’t even using fingers.
We just speak of the task and it is done. There exist systems where we can say Text Dad, “I’ll
be late today.” And the text is sent. That is the task of a Virtual Assistant. It also supports
specialized task such as booking a flight, or finding cheapest book online from various ecommerce sites and then providing an interface to book an order are helping automate search,
discovery and online order operations.
Virtual Assistants are software programs that help you ease your day to day tasks, such
as showing weather report, creating reminders, making shopping lists etc. They can take
commands via text (online chat bots) or by voice. Voice based intelligent assistants need an
invoking word or wake word to activate the listener, followed by the command. For my
project the wake word is JIA. We have so many virtual assistants, such as Apple’s Siri,
Amazon’s Alexa and Microsoft’s Cortana. For this project, wake word was chosen JIA.
This system is designed to be used efficiently on desktops. Personal assistant software
improves user productivity by managing routine tasks of the user and by providing
information from online sources to the user. JIA is effortless to use. Call the wake word ‘JIA’
followed by the command. And within seconds, it gets executed.
Voice searches have dominated over text search. Web searches conducted via mobile
devices have only just overtaken those carried out using a computer and the analysts are
already predicting that 50% of searches will be via voice by 2020.Virtual assistants are turning
out to be smarter than ever. Allow your intelligent assistant to make email work for you.
Detect intent, pick out important information, automate processes, and deliver personalized
responses.
This project was started on the premise that there is sufficient amount of openly
available data and information on the web that can be utilized to build a virtual assistant that
has access to making intelligent decisions for routine user activities.
2
1.1 BACKGROUND
There already exist a number of desktop virtual assistants. A few examples of current
virtual assistants available in market are discussed in this section along with the tasks they can
provide and their drawbacks.
SIRI from Apple
SIRI is personal assistant software that interfaces with the user thru voice interface,
recognizes commands and acts on them. It learns to adapt to user’s speech and thus improves
voice recognition over time. It also tries to converse with the user when it does not identify the
user request.
It integrates with calendar, contacts and music library applications on the device and
also integrates with GPS and camera on the device. It uses location, temporal, social and task
based contexts, to personalize the agent behavior specifically to the user at a given point of
time.
Supported Tasks
• Call someone from my contacts list
• Launch an application on my iPhone
• Send a text message to someone
• Set up a meeting on my calendar for 9am tomorrow
• Set an alarm for 5am tomorrow morning
• Play a specific song in my iTunes library
• Enter a new note
Drawback
SIRI does not maintain a knowledge database of its own and its understanding comes
from the information captured in domain models and data models. 
3
ReQall
ReQall is personal assistant software that runs on smartphones running Apple iOS or
Google Android operating system. It helps user to recall notes as well as tasks within a
location and time context. It records user inputs and converts them into commands, and
monitors current stack of user tasks to proactively suggest actions while considering any
changes in the environment. It also presents information based on the context of the user, as
well as filter information to the user based on its learned understanding of the priority of that
information.
Supported Tasks
• Reminders
• Email
• Calendar, Google Calendar
• Outlook
• Evernote
• Facebook, LinkedIn
• News Feeds
Drawback
Will take some time to put all of the to-do items in – you could spend more time
putting the entries in than actually doing the revision.
4
1.2 OBJECTIVES
Main objective of building personal assistant software (a virtual assistant) is using
semantic data sources available on the web, user generated content and providing knowledge
from knowledge databases. The main purpose of an intelligent virtual assistant is to answer
questions that users may have. This may be done in a business environment, for example, on
the business website, with a chat interface. On the mobile platform, the intelligent virtual
assistant is available as a call-button operated service where a voice asks the user “What can I
do for you?” and then responds to verbal input.
Virtual assistants can tremendously save you time. We spend hours in online research
and then making the report in our terms of understanding. JIA can do that for you. Provide a
topic for research and continue with your tasks while JIA does the research. Another difficult
task is to remember test dates, birthdates or anniversaries. It comes with a surprise when you
enter the class and realize it is class test today. Just tell JIA in advance about your tests and
she reminds you well in advance so you can prepare for the test.
One of the main advantages of voice searches is their rapidity. In fact, voice is reputed
to be four times faster than a written search: whereas we can write about 40 words per minute,
we are capable of speaking around 150 during the same period of time15. In this respect, the
ability of personal assistants to accurately recognize spoken words is a prerequisite for them to
be adopted by consumers.
5
1.3 PURPOSE, SCOPE AND APPILCABILITY
Purpose
Purpose of virtual assistant is to being capable of voice interaction, music playback,
making to-do lists, setting alarms, streaming podcasts, playing audiobooks, and providing
weather, traffic, sports, and other real-time information, such as news. Virtual assistants
enable users to speak natural language voice commands in order to operate the device and its
apps.
There is an increased overall awareness and a higher level of comfort demonstrated
specifically by millennial consumers. In this ever-evolving digital world where speed,
efficiency, and convenience are constantly being optimized, it’s clear that we are moving
towards less screen interaction.
Scope
Voice assistants will continue to offer more individualized experiences as they get
better at differentiating between voices. However, it’s not just developers that need to address
the complexity of developing for voice as brands also need to understand the capabilities of
each device and integration and if it makes sense for their specific brand. They will also need
to focus on maintaining a user experience that is consistent within the coming years as
complexity becomes more of a concern. This is because the visual interface with voice
assistants is missing. Users simply cannot see or touch a voice interface.
Applicability
The mass adoption of artificial intelligence in users’ everyday lives is also fueling the
shift towards voice. The number of IoT devices such as smart thermostats and speakers are
giving voice assistants more utility in a connected user’s life. Smart speakers are the number
one way we are seeing voice being used. Many industry experts even predict that nearly every
application will integrate voice technology in some way in the next 5 years.
The use of virtual assistants can also enhance the system of IoT (Internet of Things).
Twenty years from now, Microsoft and its competitors will be offering personal digital
assistants that will offer the services of a full-time employee usually reserved for the rich and
famous.
6
2. SURVEY OF TECHNOLOGY
Python
Python is an OOPs (Object Oriented Programming) based, high level, interpreted
programming language. It is a robust, highly useful language focused on rapid
application development (RAD). Python helps in easy writing and execution of codes. Python
can implement the same logic with as much as 1/5th code as compared to other OOPs
languages.
Python provides a huge list of benefits to all. The usage of Python is such that it cannot
be limited to only one activity. Its growing popularity has allowed it to enter into some of the
most popular and complex processes like Artificial Intelligence (AI), Machine Learning (ML),
natural language processing, data science etc. Python has a lot of libraries for every need of
this project. For JIA, libraries used are speechrecognition to recognize voice, Pyttsx for text to
speech, selenium for web automation etc.
Python is reasonably efficient. Efficiency is usually not a problem for small examples.
If your Python code is not efficient enough, a general procedure to improve it is to find out
what is taking most the time, and implement just that part more efficiently in some lower-level
language. This will result in much less programming and more efficient code (because you
will have more time to optimize) than writing everything in a low-level language.
DBpedia
Knowledge bases are playing an increasingly important role in enhancing the
intelligence of Web and enterprise search and in supporting information integration. The
DBpedia leverages this gigantic source of knowledge by extracting structured information
from Wikipedia and by making this information accessible on the Web. The DBpedia
knowledge base has several advantages over existing knowledge bases: it covers many
domains; it represents real community agreement; it automatically evolves as Wikipedia
changes, and it is truly multilingual. 
7
The DBpedia knowledge base allows you to ask quite surprising queries against
Wikipedia for instance “Give me all cities in New Jersey with more than 10,000 inhabitants”
or “Give me all Italian musicians from the 18th century”.
Quepy
Quepy is a python framework to transform natural language questions to queries in a
database query language. It can be easily customized to different kinds of questions in natural
language and database queries. So, with little coding you can build your own system for
natural language access to your database.
Pyttsx
Pyttsx stands for Python Text to Speech. It is a cross-platform Python wrapper for textto-speech synthesis. It is a Python package supporting common text-to-speech engines on Mac
OS X, Windows, and Linux. It works for both Python2.x and 3.x versions. Its main advantage
is that it works offline.
Speech Recognition
This is a library for performing speech recognition, with support for several engines
and APIs, online and offline. It supports APIs like Google Cloud Speech API, IBM Speech to
Text, Microsoft Bing Voice Recognition etc.
SQLite
SQLite is a capable library, providing an in-process relational database for efficient
storage of small-to-medium-sized data sets. It supports most of the common features of SQL
with few exceptions. Best of all, most Python users do not need to install anything to get
started working with SQLite, as the standard library in most distributions ships with the sqlite3
module.
SQLite runs embedded in memory alongside your application, allowing you to easily
extend SQLite with your own Python code. SQLite provides quite a few hooks, a reasonable
subset of which are implemented by the standard library database driver.
8
3. REQUIREMENT AND ANALYSIS
System Analysis is about complete understanding of existing systems and finding
where the existing system fails. The solution is determined to resolve issues in the proposed
system. It defines the system. The system is divided into smaller parts. Their functions and
inter relation of these modules are studied in system analysis. The complete analysis is
followed below.
3.1 Problem definition
Usually, user needs to manually manage multiple sets of applications to complete one
task. For example, a user trying to make a travel plan needs to check for airport codes for
nearby airports and then check travel sites for tickets between combinations of airports to
reach the destination. There is need of a system that can manage tasks effortlessly.
We already have multiple virtual assistants. But we hardly use it. There are number of
people who have issues in voice recognition. These systems can understand English phrases
but they fail to recognize in our accent. Our way of pronunciation is way distinct from theirs.
Also, they are easy to use on mobile devices than desktop systems. There is need of a virtual
assistant that can understand English in Indian accent and work on desktop system.
When a virtual assistant is not able to answer questions accurately, it’s because it lacks
the proper context or doesn’t understand the intent of the question. Its ability to answer
questions relevantly only happens with rigorous optimization, involving both humans and
machine learning. Continuously ensuring solid quality control strategies will also help manage
the risk of the virtual assistant learning undesired bad behaviors. They require large amount of
information to be fed in order for it to work efficiently.
Virtual assistant should be able to model complex task dependencies and use these
models to recommend optimized plans for the user. It needs to be tested for finding optimum
paths when a task has multiple sub-tasks and each sub-task can have its own sub-tasks. In such
a case there can be multiple solutions to paths, and the it should be able to consider user
preferences, other active tasks, priorities in order to recommend a particular plan.
9
3.2 REQUIREMENT SPECIFICATION
Personal assistant software is required to act as an interface into the digital world by
understanding user requests or commands and then translating into actions or
recommendations based on agent’s understanding of the world.
JIA focuses on relieving the user of entering text input and using voice as primary
means of user input. Agent then applies voice recognition algorithms to this input and records
the input. It then use this input to call one of the personal information management
applications such as task list or calendar to record a new entry or to search about it on search
engines like Google, Bing or Yahoo etc. Focus is on capturing the user input through voice,
recognizing the input and then executing the tasks if the agent understands the task. Software
takes this input in natural language, and so makes it easier for the user to input what he or she
desires to be done.
Voice recognition software enables hands free use of the applications, lets users to
query or command the agent through voice interface. This helps users to have access to the
agent while performing other tasks and thus enhances value of the system itself. JIA also have
ubiquitous connectivity through Wi-Fi or LAN connection, enabling distributed applications
that can leverage other APIs exposed on the web without a need to store them locally.
Virtual assistants must provide a wide variety of services. These include:
• Providing information such as weather, facts from e.g. Wikipedia etc.
• Set an alarm or make to-do lists and shopping lists.
• Remind you of birthdays and meetings.
• Play music from streaming services such as Saavn and Gaana.
• Play videos, TV shows or movies on televisions, streaming from e.g. Netflix or
Hotstar.
• Book tickets for shows, travel and movies.
10
Feasibility Study
Feasibility study can help you determine whether or not you should proceed with
your project. It is essential to evaluate cost and benefit. It is essential to evaluate cost and
benefit of the proposed system. Five types of feasibility study are taken into consideration.
1. Technical feasibility: It includes finding out technologies for the project, both
hardware and software. For virtual assistant, user must have microphone to convey
their message and a speaker to listen when system speaks. These are very cheap now a
days and everyone generally possess them. Besides, system needs internet connection.
While using JIA, make sure you have a steady internet connection. It is also not an
issue in this era where almost every home or office has Wi-Fi.
2. Operational feasibility: It is the ease and simplicity of operation of proposed system.
System does not require any special skill set for users to operate it. In fact, it is
designed to be used by almost everyone. Kids who still don’t know to write can read
out problems for system and get answers.
3. Economical feasibility: Here, we find the total cost and benefit of the proposed
system over current system. For this project, the main cost is documentation cost. User
also would have to pay for microphone and speakers. Again, they are cheap and
available. As far as maintenance is concerned, JIA won’t cost too much.
4. Organizational feasibility: This shows the management and organizational structure
of the project. This project is not built by a team. The management tasks are all to be
carried out by a single person. That won’t create any management issues and will
increase the feasibility of the project.
5. Cultural feasibility: It deals with compatibility of the project with cultural
environment. Virtual assistant is built in accordance with the general culture. The
project is named JIA so as to represent Indian culture without undermining local
beliefs.
This project is technically feasible with no external hardware requirements. Also it is
simple in operation and does not cost training or repairs. Overall feasibility study of the
project reveals that the goals of the proposed system are achievable. Decision is taken to
proceed with the project.
11
3.3 HARDWARE AND SOFTWARE REQUIREMENTS
The software is designed to be light-weighted so that it doesn’t be a burden on the
machine running it. This system is being build keeping in mind the generally available
hardware and software compatibility. Here are the minimum hardware and software
requirement for virtual assistant.
Hardware:
• Pentium-pro processor or later.
• RAM 512MB or more.
Software:
• Windows 7(32-bit) or above.
• Python 2.7 or later
• Chrome Driver
• Selenium Web Automation
• SQLite 
12
4. SYSTEM DESIGN
4.1 ER DIAGRAM
The above diagram shows entities and their relationship for a virtual assistant system.
We have a user of a system who can have their keys and values. It can be used to store any
information about the user. Say, for key “name” value can be “Jim”. For some keys user might
like to keep secure. There he can enable lock and set a password (voice clip).
Single user can ask multiple questions. Each question will be given ID to get
recognized along with the query and its corresponding answer. User can also be having n
number of tasks. These should have their own unique id and status i.e. their current state. A
task should also have a priority value and its category whether it is a parent task or child task
of an older task.
13
4.2 ACTIVITY DIAGRAM
Initially, the system is in idle mode. As it receives any wake up cal it begins execution.
The received command is identified whether it is a questionnaire or a task to be performed.
Specific action is taken accordingly. After the Question is being answered or the task is being
performed, the system waits for another command. This loop continues unless it receives quit
command. At that moment, it goes back to sleep.
14
4.3 CLASS DIAGRAM
The class user has 2 attributes command that it sends in audio and the response it
receives which is also audio. It performs function to listen the user command. Interpret it and
then reply or sends back response accordingly. Question class has the command in string form
as it is interpreted by interpret class. It sends it to general or about or search function based on
its identification.
The task class also has interpreted command in string format. It has various functions
like reminder, note, mimic, research and reader. 
15
4.4 USE CASE DIAGRAM
In this project there is only one user. The user queries command to the system. System
then interprets it and fetches answer. The response is sent back to the user. 
16
4.5 SEQUENCE DIAGRAM
4.5.1 Sequence diagram for Query-Response
The above sequence diagram shows how an answer asked by the user is being fetched
from internet. The audio query is interpreted and sent to Web scraper. The web scraper
searches and finds the answer. It is then sent back to speaker, where it speaks the answer to
user. 
17
4.5.2 Sequence diagram for Task Execution
The user sends command to virtual assistant in audio form. The command is passed to
the interpreter. It identifies what the user has asked and directs it to task executer. If the task is
missing some info, the virtual assistant asks user back about it. The received information is
sent back to task and it is accomplished. After execution feedback is sent back to user. 
18
4.6 DATA FLOW DIAGRAM
4.6.1 DFD Level 0 (Context Level Diagram)
4.6.2 DFD Level 1
19
4.6.3 DFD Level 2
 Data Flow in Assistance
Managing User Data
20
Data Flow in Kid Zone
Settings of virtual Assistant
21
4.7 COMPONENT DIAGRAM
The main component here is the Virtual Assistant. It provides two specific service,
executing Task or Answering your question. 
22
4.8 DEPLOYMENT DIAGRAM
The user interacts with SQLite database using SQLite connection in Python code. The
knowledge database DBPedia must be accessed via internet connection. This requires LAN or
WLAN / Ethernet network.
23
4.9 DATA DICTIONARY
User
Key Text
Value Text
Lock Boolean
Password Text
Question
Qid Integer PRIMARY KEY
Query Text
Answer Text
Task
Tid Integer PRIMARY KEY
Status Text (Active/Waiting/Stopped)
Level Text (Parent/Sub)
Priority Integer
Reminder
Rid Integer PRIMARY KEY
Tid Integer FOREIGN KEY
What Text
When Time
On Date
Notify before Time
Note
Nid Integer PRIMARY KEY
Tid Integer FOREIGN KEY
Data Text
Priority Integer
24
4.10 TEST CASE DESIGN
• Test Case 1
Test Title: Response Time
Test ID: T1
Test Priority: High
Test Objective: To make sure that the system respond back time is efficient.
Description:
Time is very critical in a voice based system. As we are not typing inputs, we are
speaking them. The system must also reply in a moment. User must get instant response of the
query made.
• Test Case 2
Test Title: Accuracy
Test ID: T2
Test Priority: High
Test Objective: To assure that answers retrieved by system are accurate as per gathered data.
Description:
A virtual assistant system is mainly used to get precise answers to any question asked.
Getting answer in a moment is of no use if the answer is not correct. Accuracy is of utmost
importance in a virtual assistant system.
25
• Test Case 3
Test Title: Approximation
Test ID: t3
Test priority: Moderate
Test Objective: To check approximate answers about calculations.
Description:
There are times when mathematical calculation requires approximate value. For
example, if someone asks for value of PI the system must respond with approximate value and
not the accurate value. Getting exact value in such cases is undesirable.
Note: There might include a few more test cases and these test cases are also subject to change
with the final software development.
26
REFERENCE AND BIBLIOGRAPHY
• Websites referred
 www.stackoverflow.com
 www.pythonprogramming.net
 www.codecademy.com
 www.tutorialspoint.com
 www.google.co.in
• Books referred
 Python Programming - Kiran Gurbani
 Learning Python - Mark Lutz
• YouTube Channels referred
 CS Dojo
 edureka!
• Documents referred
 Designing Personal Assistant Software for Task Management using Semantic
Web Technologies and Knowledge Databases
- Purushotham Botla
 Python code for Artificial Intelligence: Foundations of Computational Agents
- David L. Poole and Alan K. Mackworth
THANK YOUEXTRUDESIGN

HOME
About Us
Subscribe Here!
Site Map
MECHANICAL ENGINEERING
Machine Design
Engineering Calculators
Motor Torque
Section Modulus
Area Calculator
Shaft Diameter
Stiffness Calculator
Inertia Calculator
More
Metrology
Theory of Machines
Material Science
Advanced Composites
CAD/CAE/CAM
PTC CREO
SOLIDWORKS
CATIA V5
Unit Converters
Torque
Power
Force
Energy
Inertia
Area
How to?
Advanced Excel
Latest Apple news
PROJECTS LIBRARY
HOW TO PUBLISH?
Virtual Assistant Using Python
July 18, 2021 by University Student Leave a Comment

A final year project on “Virtual Assistant Using Python” was submitted by Kavya Damarla (from Chalapathi Institute Of Engineering And Technology, Guntur, Andhra Pradesh) to extrudesign.com.

Virtual Assistant Using Python
Abstract
In this modern era, day to day life became smarter and interlinked with technology. We already know some voice assistance like google, Siri. etc. Now in our voice assistance system, it can act as a basic medical prescriber, daily schedule reminder, note writer, calculator and a search tool. This project works on voice input and give output through voice and displays the text on the screen. The main agenda of our voice assistance makes people smart and give instant and computed results. The voice assistance takes the voice input through our microphone (Bluetooth and wired microphone) and it converts our voice into computer understandable language gives the required solutions and answers which are asked by the user. This assistance connects with the world wide web to provide results that the user has questioned. Natural Language Processing algorithm helps computer machines to engage in communication using natural human language in many forms.

I. Introduction
Today the development of artificial intelligence (AI) systems that can organize a natural human-machine interaction (through voice, communication, gestures, facial expressions, etc.) are gaining in popularity. One of the most studied and popular was the direction of interaction, based on the understanding of the machine by the machine of the natural human language. It is no longer a human who learns to communicate with a machine, but a machine learns to communicate with a human, exploring his actions, habits, behaviour and trying to become his personalized assistant.

Virtual assistants are software programs that help you ease your day to day tasks, such as showing weather reports, creating remainders, making shopping lists etc. They can take commands via text (online chatbots) or by voice. Voice-based intelligent assistants need an invoking word or wake word to activate the listener, followed by the command. We have so many virtual assistants, such as Apple’s Siri, Amazon’s Alexa and Microsoft’s Cortana.
This system is designed to be used efficiently on desktops. Personal assistants software improves user productivity by managing routine tasks of the user and by providing information from an online source to the user.

This project was started on the premise that there is a sufficient amount of openly available data and information on the web that can be utilized to build a virtual assistant that has access to making intelligent decisions for routine user activities.

Keywords: Virtual Assistant Using Python, AI, Digital assistance, Virtual Assistance, Python

II. Related Work
Each company developer of the intelligent assistant applies his own specific methods and approaches for development, which in turn affects the final product. One assistant can synthesize speech more qualitatively, another can more accurately and without additional explanations and corrections perform tasks, others can perform a narrower range of tasks, but most accurately and as the user wants. Obviously, there is no universal assistant who would perform all tasks equally well. The set of characteristics that an assistant has depends entirely on which area the developer has paid more attention to. Since all systems are based on machine learning methods and use for their creation huge amounts of data collected from various sources and then trained on them, an important role is played by the source of this data, be it search systems, various information sources or social networks. The amount of information from different sources determines the nature of the assistant, which can result as a result. Despite the different approaches to learning, different algorithms and techniques, the principle of building such systems remain approximately the same. Figure 1 shows the technologies that are used to create intelligent systems of interaction with a human by his natural language. The main technologies are voice activation, automatic speech recognition, Teach-To-Speech, voice biometrics, dialogue manager, natural language understanding and named entity recognition.

Voice Technology  	Brain Technology  
Voice Activation  	Voice Bio-metrics  
Automatic Speech Recognition (ASR)  	Dialog Management  
    (Teach-To-Speech (TTS)  	Natural Language Understanding (NLU)

Named Entity Recognition NER)  
Fig.1. Technologies for constructing intelligent systems of interaction with a human by natural language
III. Proposed Plan Of Work
The work started with analyzing the audio commands given by the user through the microphone. This can be anything like getting any information, operating a computer’s internal files, etc. This is an empirical qualitative study, based on reading above mentioned literature and testing their examples. Tests are made by programming according to books and online resources, with the explicit goal to find best practices and a more advanced understanding of Voice Assistant.

Virtual Assistant Using Python
Fig.2.  Basic Workflow
Fig.2 shows the workflow of the basic process of the voice assistant. Speech recognition is used to convert the speech input to text. This text is then fed to the central processor which determines the nature of the command and calls the relevant script for execution.

But, the complexities don’t stop there. Even with hundreds of hours of input, other factors can play a huge role in whether or not the software can understand you. Background noise can easily throw a speech recognition device off track. This is because it does not inherently have the ability to distinguish the ambient sounds it “hears” of a dog barking or a helicopter flying overhead, from your voice. Engineers have to program that ability into the device; they conduct data collection of these ambient sounds and “tell” the device to filter them out. Another factor is the way humans naturally shift the pitch of their voice to accommodate for noisy environments; speech recognition systems can be sensitive to these pitch changes.

IV. Methodology of Virtual Assistant Using Python
Virtual Assistant Using Python
Fig 3 Detailed workflow
Speech Recognition module
The system uses Google’s online speech recognition system for converting speech input to text. The speech input Users can obtain texts from the special corpora organized on the computer network server at the information centre from the microphone is temporarily stored in the system which is then sent to Google cloud for speech recognition. The equivalent text is then received and fed to the central processor.

Python Backend:
The python backend gets the output from the speech recognition module and then identifies whether the command or the speech output is an API Call and Context Extraction. The output is then sent back to the python backend to give the required output to the user.

API calls
API stands for Application Programming Interface. An API is a software intermediary that allows two applications to talk to each other. In other words, an API is a messenger that delivers your request to the provider that you’re requesting it from and then delivers the response back to you.

Content Extraction
Context extraction (CE) is the task of automatically extracting structured information from unstructured and/or semi-structured machine-readable documents. In most cases, this activity concerns processing human language texts using natural language processing (NLP). Recent activities in multimedia document processing like automatic annotation and content extraction out of images/audio/video could be seen as context extraction TEST RESULTS.

Text-to-speech module
Text-to-Speech (TTS) refers to the ability of computers to read text aloud. A TTS Engine converts written text to a phonemic representation, then converts the phonemic representation to waveforms that can be output as sound. TTS engines with different languages, dialects and specialized vocabularies are available through third-party publishers.

V. Conclusion
In this paper “Virtual Assistant Using Python” we discussed the design and implementation of Digital Assistance. The project is built using open source software modules with PyCharm community backing which can accommodate any updates shortly. The modular nature of this project makes it more flexible and easy to add additional features without disturbing current system functionalities.

It not only works on human commands but also give responses to the user based on the query being asked or the words spoken by the user such as opening tasks and operations. It is greeting the user the way the user feels more comfortable and feels free to interact with the voice assistant. The application should also eliminate any kind of unnecessary manual work required in the user life of performing every task. The entire system works on the verbal input rather than the next one.

References
[1] R. Belvin, R. Burns, and C. Hein, “Development of the HRL route navigation dialogue system,” in Proceedings of ACL-HLT, 2001
[2] V. Zue, S. Seneff, J. R. Glass, J. Polifroni, C. Pao, T.J.Hazen,and L.Hetherington, “JUPITER: A Telephone Based Conversational Interface for Weather Information,” IEEE Transactions on Speech and Audio Processing, vol. 8, no. 1, pp. 85–96, 2000.
[3] M. Kolss, D. Bernreuther, M. Paulik, S. St¨ucker, S. Vogel, and A. Waibel, “Open Domain Speech Recognition & Translation: Lectures and Speeches,” in Proceedings of ICASSP, 2006.
[4] D. R. S. Caon, T. Simonnet, P. Sendorek, J. Boudy, and G. Chollet, “vAssist: The Virtual Interactive Assistant for Daily Homer-Care,” in Proceedings of pHealth, 2011.
[5] Crevier, D. (1993). AI: The Tumultuous Search for Artificial Intelligence. New York, NY: Basic Books, ISBN 0-465-02997-3.
[6] Sadun, E., &Sande, S. (2014). Talking to Siri: Mastering the Language of Apple’s Intelligent Assistant.
Credit: This Project “Virtual Assistant Using Python” was completed by Damarla Kavya, Daddanala Suvarna, Javisetti Srinivas and Chintha Venkata Ramaiah from the  Department Of Electronics And Communication Engineering, Chalapathi Institute Of Engineering And Technology, Guntur, Andhra Pradesh.

Filed Under: Final year Project papers
Tagged With: AI, Digital assistance, Python, Virtual Assistance, Virtual Assistant Using Python

RECENT POSTS
What is TIG Welding Process? November 1, 2021
Different Interferometers in Metrology October 29, 2021
What are Electric Arc Welding Types? October 26, 2021
What are the Gas Welding Types, Flame types, and Equipment? October 23, 2021

About University Student
This site uses Akismet to reduce spam. Learn how your comment data is processed.

EXTRUDESIGN.COM
Home
About us
Privacy Policy
Terms & Conditions
Submit Content
Site Map
WE ALWAYS CARE ABOUT YOUR PRIVACY!
Name
Your name

Email address
Your email address


EXTRUDESIGN- EXPRESS WITH DESIGN
Our motive is to help students and working professionals with basic and advanced Engineering topics.

We also help students to publish their Articles and research papers.

DMCA.com Protection Status

Copyright ©2021 · ExtruDesign.com - All Rights Reserved ·